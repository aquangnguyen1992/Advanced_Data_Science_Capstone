{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquangnguyen1992/Advanced_Data_Science_Capstone/blob/master/Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE4qbNACq5vY",
        "colab_type": "text"
      },
      "source": [
        "# ***Get the dataset from Kaggle***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28TmZY-0q4mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "74abfe23-51cd-4cce-bec4-eec730650e48"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0mVq898tzNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "9965d386-ba32-42f0-e29c-e3eaddba1ec3"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 61% 32.0M/52.2M [00:00<00:00, 161MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 175MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 65% 38.0M/58.3M [00:00<00:00, 30.4MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 91.9MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 214MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 165MB/s]\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 221MB/s]\n",
            "Archive:  train_transaction.csv.zip\n",
            "replace train_transaction.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "\n",
            "Archive:  test_transaction.csv.zip\n",
            "\n",
            "Archive:  sample_submission.csv.zip\n",
            "\n",
            "Archive:  test_identity.csv.zip\n",
            "\n",
            "Archive:  train_identity.csv.zip\n",
            "\n",
            "5 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-VLOPU9zZii",
        "colab_type": "text"
      },
      "source": [
        "# ***Analyzing the dataset and doing the cleansing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYzy-sxDzdFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a578e222-2bc2-444c-9e74-5811db5c4bc9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBOSTwRzj4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "ad62426a-0ab8-4ef3-b769-0c465af80d1a"
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "dataset_transaction = pd.read_csv('train_transaction.csv')\n",
        "dataset_transaction.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoApMJ8vz3IF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "ef22e55e-d0f8-480a-a179-a6c49b0a4b57"
      },
      "source": [
        "dataset_identity = pd.read_csv('train_identity.csv')\n",
        "dataset_identity.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70787.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-480.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>Android 7.0</td>\n",
              "      <td>samsung browser 6.2</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2220x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987008</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>98945.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>621.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>iOS 11.1.2</td>\n",
              "      <td>mobile safari 11.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1334x750</td>\n",
              "      <td>match_status:1</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>iOS Device</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987010</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>191631.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>121.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>410.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Windows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987011</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>221832.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>176.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987016</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7460.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>529.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Mac OS X 10_11_6</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1280x800</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>MacOS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  id_01  ...  DeviceType                     DeviceInfo\n",
              "0        2987004    0.0  ...      mobile  SAMSUNG SM-G892A Build/NRD90M\n",
              "1        2987008   -5.0  ...      mobile                     iOS Device\n",
              "2        2987010   -5.0  ...     desktop                        Windows\n",
              "3        2987011   -5.0  ...     desktop                            NaN\n",
              "4        2987016    0.0  ...     desktop                          MacOS\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmudmokF4Ath",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f69348be-32d0-4449-df6e-dc3e321d868b"
      },
      "source": [
        "dataset_identity.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06',\n",
              "       'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14',\n",
              "       'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22',\n",
              "       'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30',\n",
              "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
              "       'DeviceType', 'DeviceInfo'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NesEY-44N6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a09dbfb4-8cae-4d09-af18-d12574034495"
      },
      "source": [
        "dataset_transaction.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
              "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
              "       ...\n",
              "       'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338',\n",
              "       'V339'],\n",
              "      dtype='object', length=394)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDu1rWAkUafP",
        "colab_type": "text"
      },
      "source": [
        "**Check NaN, Null, and OneHotEncoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtNPHQ2NCbGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "float_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "int_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('int64'))].to_list()\n",
        "obj_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "skip_int_columns = ['TransactionID', 'isFraud']\n",
        "for column in skip_int_columns:\n",
        "  int_columns.remove(column)\n",
        "\n",
        "skip_obj_colums = ['']\n",
        "cache = dict()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4AzwRzqEfth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization_data(X, indices):\n",
        "  X_out = copy.copy(X)\n",
        "  X_temp = X[indices]\n",
        "  X_out.iloc[indices] = (X_temp-np.mean(X_temp))/(np.max(X_temp)-np.min(X_temp))\n",
        "  X_out.iloc[np.where(np.isnan(X_out))[0]] = 0\n",
        "  return np.min(X_temp), np.max(X_temp), np.mean(X_temp), X_out.astype('float16')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-sce8WEFqWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "5e2359a5-760e-4d52-b586-17838f660496"
      },
      "source": [
        "data_backup = copy.copy(dataset_transaction)\n",
        "data_backup.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIIYOrO74QbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1: Detect the columns with NaN and code it with an extra features\n",
        "# Task 2: Apply normalizationn\n",
        "# Task 3: Remove the irrelevant columns\n",
        "\n",
        "dataset_transaction = copy.copy(data_backup)\n",
        "\n",
        "for column in float_columns:\n",
        "  # Set to float 16\n",
        "  dataset_transaction[column].astype('float16')\n",
        "\n",
        "  # Code the NaN column for every features\n",
        "  dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(dataset_transaction[column]) == False)[0]\n",
        "  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], dataset_transaction[column] = normalization_data(X, indices)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZY_88yeGGSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a42b252e-1c5c-42ed-ae72-36249c7718aa"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300_NaN_Code</th>\n",
              "      <th>V301_NaN_Code</th>\n",
              "      <th>V302_NaN_Code</th>\n",
              "      <th>V303_NaN_Code</th>\n",
              "      <th>V304_NaN_Code</th>\n",
              "      <th>V305_NaN_Code</th>\n",
              "      <th>V306_NaN_Code</th>\n",
              "      <th>V307_NaN_Code</th>\n",
              "      <th>V308_NaN_Code</th>\n",
              "      <th>V309_NaN_Code</th>\n",
              "      <th>V310_NaN_Code</th>\n",
              "      <th>V311_NaN_Code</th>\n",
              "      <th>V312_NaN_Code</th>\n",
              "      <th>V313_NaN_Code</th>\n",
              "      <th>V314_NaN_Code</th>\n",
              "      <th>V315_NaN_Code</th>\n",
              "      <th>V316_NaN_Code</th>\n",
              "      <th>V317_NaN_Code</th>\n",
              "      <th>V318_NaN_Code</th>\n",
              "      <th>V319_NaN_Code</th>\n",
              "      <th>V320_NaN_Code</th>\n",
              "      <th>V321_NaN_Code</th>\n",
              "      <th>V322_NaN_Code</th>\n",
              "      <th>V323_NaN_Code</th>\n",
              "      <th>V324_NaN_Code</th>\n",
              "      <th>V325_NaN_Code</th>\n",
              "      <th>V326_NaN_Code</th>\n",
              "      <th>V327_NaN_Code</th>\n",
              "      <th>V328_NaN_Code</th>\n",
              "      <th>V329_NaN_Code</th>\n",
              "      <th>V330_NaN_Code</th>\n",
              "      <th>V331_NaN_Code</th>\n",
              "      <th>V332_NaN_Code</th>\n",
              "      <th>V333_NaN_Code</th>\n",
              "      <th>V334_NaN_Code</th>\n",
              "      <th>V335_NaN_Code</th>\n",
              "      <th>V336_NaN_Code</th>\n",
              "      <th>V337_NaN_Code</th>\n",
              "      <th>V338_NaN_Code</th>\n",
              "      <th>V339_NaN_Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>discover</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.055145</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>-0.002380</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>visa</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.089233</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.016388</td>\n",
              "      <td>0.0</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>0.408936</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.600586</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.089966</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>0.302979</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.293701</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 770 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  V338_NaN_Code  V339_NaN_Code\n",
              "0        2987000        0  ...              1              1\n",
              "1        2987001        0  ...              1              1\n",
              "2        2987002        0  ...              1              1\n",
              "3        2987003        0  ...              1              1\n",
              "4        2987004        0  ...              0              0\n",
              "\n",
              "[5 rows x 770 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43g5UKZPg32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in int_columns:\n",
        "  # Set to int 32\n",
        "  dataset_transaction[column].astype('int32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  #if np.any(np.isnan(dataset_transaction[column].values)):\n",
        "  #  dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(dataset_transaction[column]) == False)[0]\n",
        "  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], dataset_transaction[column] = normalization_data(X, indices)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW7scgn0-mD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "7b299db5-67ce-4cdd-d3fd-a46267ba5cbd"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300_NaN_Code</th>\n",
              "      <th>V301_NaN_Code</th>\n",
              "      <th>V302_NaN_Code</th>\n",
              "      <th>V303_NaN_Code</th>\n",
              "      <th>V304_NaN_Code</th>\n",
              "      <th>V305_NaN_Code</th>\n",
              "      <th>V306_NaN_Code</th>\n",
              "      <th>V307_NaN_Code</th>\n",
              "      <th>V308_NaN_Code</th>\n",
              "      <th>V309_NaN_Code</th>\n",
              "      <th>V310_NaN_Code</th>\n",
              "      <th>V311_NaN_Code</th>\n",
              "      <th>V312_NaN_Code</th>\n",
              "      <th>V313_NaN_Code</th>\n",
              "      <th>V314_NaN_Code</th>\n",
              "      <th>V315_NaN_Code</th>\n",
              "      <th>V316_NaN_Code</th>\n",
              "      <th>V317_NaN_Code</th>\n",
              "      <th>V318_NaN_Code</th>\n",
              "      <th>V319_NaN_Code</th>\n",
              "      <th>V320_NaN_Code</th>\n",
              "      <th>V321_NaN_Code</th>\n",
              "      <th>V322_NaN_Code</th>\n",
              "      <th>V323_NaN_Code</th>\n",
              "      <th>V324_NaN_Code</th>\n",
              "      <th>V325_NaN_Code</th>\n",
              "      <th>V326_NaN_Code</th>\n",
              "      <th>V327_NaN_Code</th>\n",
              "      <th>V328_NaN_Code</th>\n",
              "      <th>V329_NaN_Code</th>\n",
              "      <th>V330_NaN_Code</th>\n",
              "      <th>V331_NaN_Code</th>\n",
              "      <th>V332_NaN_Code</th>\n",
              "      <th>V333_NaN_Code</th>\n",
              "      <th>V334_NaN_Code</th>\n",
              "      <th>V335_NaN_Code</th>\n",
              "      <th>V336_NaN_Code</th>\n",
              "      <th>V337_NaN_Code</th>\n",
              "      <th>V338_NaN_Code</th>\n",
              "      <th>V339_NaN_Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>W</td>\n",
              "      <td>0.231445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>discover</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.055145</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>W</td>\n",
              "      <td>-0.410645</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002380</td>\n",
              "      <td>W</td>\n",
              "      <td>-0.301025</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>visa</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.089233</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.016388</td>\n",
              "      <td>0.0</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>W</td>\n",
              "      <td>0.473389</td>\n",
              "      <td>0.408936</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.600586</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.089966</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>H</td>\n",
              "      <td>-0.310547</td>\n",
              "      <td>0.302979</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.293701</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 770 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  V338_NaN_Code  V339_NaN_Code\n",
              "0        2987000        0  ...              1              1\n",
              "1        2987001        0  ...              1              1\n",
              "2        2987002        0  ...              1              1\n",
              "3        2987003        0  ...              1              1\n",
              "4        2987004        0  ...              0              0\n",
              "\n",
              "[5 rows x 770 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDGnSj678SaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd19edec-3efa-47b2-9ef3-4784611ff04b"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoded_column = 0\n",
        "for column in obj_columns:\n",
        "  ohc = OneHotEncoder()\n",
        "  dataset_transaction.loc[np.where(dataset_transaction[column].isnull())[0], column] = 'Null'\n",
        "  encoded = ohc.fit_transform(dataset_transaction[column].values.reshape(-1,1)).toarray()    \n",
        "  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(dataset_transaction[column].astype('str'))))])\n",
        "  dataset_transaction = pd.concat([dataset_transaction, pd_encoded], axis=1)\n",
        "  cache[column] = dataset_transaction[column].values.reshape(-1,1)\n",
        "  encoded_column += len(pd_encoded.columns)\n",
        "\n",
        "print(\"Encoded columns: \" + str(encoded_column))\n",
        "for column in obj_columns:\n",
        "  try:\n",
        "    dataset_transaction.pop(column)\n",
        "  except KeyError:\n",
        "    pass\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded columns: 164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuvQmMmLRnM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "9ffc7325-1560-4cb4-82ee-cd3257fc33ae"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>...</th>\n",
              "      <th>R_emaildomain_49</th>\n",
              "      <th>R_emaildomain_50</th>\n",
              "      <th>R_emaildomain_51</th>\n",
              "      <th>R_emaildomain_52</th>\n",
              "      <th>R_emaildomain_53</th>\n",
              "      <th>R_emaildomain_54</th>\n",
              "      <th>R_emaildomain_55</th>\n",
              "      <th>R_emaildomain_56</th>\n",
              "      <th>R_emaildomain_57</th>\n",
              "      <th>R_emaildomain_58</th>\n",
              "      <th>R_emaildomain_59</th>\n",
              "      <th>R_emaildomain_60</th>\n",
              "      <th>M1_0</th>\n",
              "      <th>M1_1</th>\n",
              "      <th>M1_2</th>\n",
              "      <th>M2_0</th>\n",
              "      <th>M2_1</th>\n",
              "      <th>M2_2</th>\n",
              "      <th>M3_0</th>\n",
              "      <th>M3_1</th>\n",
              "      <th>M3_2</th>\n",
              "      <th>M4_0</th>\n",
              "      <th>M4_1</th>\n",
              "      <th>M4_2</th>\n",
              "      <th>M4_3</th>\n",
              "      <th>M5_0</th>\n",
              "      <th>M5_1</th>\n",
              "      <th>M5_2</th>\n",
              "      <th>M6_0</th>\n",
              "      <th>M6_1</th>\n",
              "      <th>M6_2</th>\n",
              "      <th>M7_0</th>\n",
              "      <th>M7_1</th>\n",
              "      <th>M7_2</th>\n",
              "      <th>M8_0</th>\n",
              "      <th>M8_1</th>\n",
              "      <th>M8_2</th>\n",
              "      <th>M9_0</th>\n",
              "      <th>M9_1</th>\n",
              "      <th>M9_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>0.231445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>0.055145</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.126709</td>\n",
              "      <td>-0.184814</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>-0.410645</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002380</td>\n",
              "      <td>-0.301025</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>0.089233</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.016388</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>0.232910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>0.473389</td>\n",
              "      <td>0.408936</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.600586</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.089966</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.045654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>-0.310547</td>\n",
              "      <td>0.302979</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>0.293701</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 920 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  M9_0  M9_1  M9_2\n",
              "0        2987000        0      -0.463379  ...     0     1     0\n",
              "1        2987001        0      -0.463379  ...     0     1     0\n",
              "2        2987002        0      -0.463379  ...     1     0     0\n",
              "3        2987003        0      -0.463379  ...     0     1     0\n",
              "4        2987004        0      -0.463379  ...     0     1     0\n",
              "\n",
              "[5 rows x 920 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e626putLzCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96371fe8-96da-44ba-dd47-9b101e97dd43"
      },
      "source": [
        "print(np.any(np.isnan(dataset_transaction)), np.any(dataset_transaction.isnull()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2H9ryz7bHU",
        "colab_type": "text"
      },
      "source": [
        "**Apply Seaborn to preliminary analyze the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9BKg6gZ8qS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colums_to_analyze = ['isFraud', 'TransactionDT', 'TransactionAmt', 'P_emaildomain_0', 'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'P_emaildomain_4', 'addr1', 'addr2', 'dist1', 'dist2']\n",
        "analyzing_data = dataset_transaction[colums_to_analyze]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtWkHi4N7kKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "a3230911-150e-4e91-8557-d3eae94d6553"
      },
      "source": [
        "corr = analyzing_data.corr()\n",
        "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff90c116550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rf6--7Dn6PZ",
        "colab_type": "text"
      },
      "source": [
        "# ***Creat the train/val dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV-8fmFWoOnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "778c51fa-e8d3-4a90-9aff-39f86baece02"
      },
      "source": [
        "# Create a copy\n",
        "dataset = copy.copy(dataset_transaction)\n",
        "\n",
        "# Remove the irrelevant columns\n",
        "dataset.pop('TransactionID')\n",
        "dataset.head(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>...</th>\n",
              "      <th>R_emaildomain_49</th>\n",
              "      <th>R_emaildomain_50</th>\n",
              "      <th>R_emaildomain_51</th>\n",
              "      <th>R_emaildomain_52</th>\n",
              "      <th>R_emaildomain_53</th>\n",
              "      <th>R_emaildomain_54</th>\n",
              "      <th>R_emaildomain_55</th>\n",
              "      <th>R_emaildomain_56</th>\n",
              "      <th>R_emaildomain_57</th>\n",
              "      <th>R_emaildomain_58</th>\n",
              "      <th>R_emaildomain_59</th>\n",
              "      <th>R_emaildomain_60</th>\n",
              "      <th>M1_0</th>\n",
              "      <th>M1_1</th>\n",
              "      <th>M1_2</th>\n",
              "      <th>M2_0</th>\n",
              "      <th>M2_1</th>\n",
              "      <th>M2_2</th>\n",
              "      <th>M3_0</th>\n",
              "      <th>M3_1</th>\n",
              "      <th>M3_2</th>\n",
              "      <th>M4_0</th>\n",
              "      <th>M4_1</th>\n",
              "      <th>M4_2</th>\n",
              "      <th>M4_3</th>\n",
              "      <th>M5_0</th>\n",
              "      <th>M5_1</th>\n",
              "      <th>M5_2</th>\n",
              "      <th>M6_0</th>\n",
              "      <th>M6_1</th>\n",
              "      <th>M6_2</th>\n",
              "      <th>M7_0</th>\n",
              "      <th>M7_1</th>\n",
              "      <th>M7_2</th>\n",
              "      <th>M8_0</th>\n",
              "      <th>M8_1</th>\n",
              "      <th>M8_2</th>\n",
              "      <th>M9_0</th>\n",
              "      <th>M9_1</th>\n",
              "      <th>M9_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>0.231445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>0.055145</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.126709</td>\n",
              "      <td>-0.184814</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.170166</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>-0.410645</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.170166</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002380</td>\n",
              "      <td>-0.301025</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>0.089233</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.016388</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>0.232910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157227</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>0.473389</td>\n",
              "      <td>0.408936</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.600586</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.089966</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.045654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>-0.310547</td>\n",
              "      <td>0.302979</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>0.293701</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 919 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   isFraud  TransactionDT  TransactionAmt     card1  ...  M8_2  M9_0  M9_1  M9_2\n",
              "0        0      -0.463379       -0.002083  0.231445  ...     0     0     1     0\n",
              "1        0      -0.463379       -0.003321 -0.410645  ...     0     0     1     0\n",
              "2        0      -0.463379       -0.002380 -0.301025  ...     0     1     0     0\n",
              "3        0      -0.463379       -0.002663  0.473389  ...     0     0     1     0\n",
              "4        0      -0.463379       -0.002663 -0.310547  ...     0     0     1     0\n",
              "\n",
              "[5 rows x 919 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7KODCOzZbOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3f0b80f-578a-4721-cfe2-7e821972034a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = dataset['isFraud']\n",
        "dataset.pop('isFraud')\n",
        "X = dataset\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(472432, 918) (472432,) (118108, 918)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyHSb5S3bDdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e610e52d-33b9-4906-cbb1-f90deb211fd5"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.hist(Y_train, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist(Y_train, bins=[0,1,2])\n",
        "\n",
        "fraud_count = np.unique(Y_train, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 3.5%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FZY_7rXajHM",
        "colab_type": "text"
      },
      "source": [
        "**Downsampling and upsampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_kQE1U9amFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "66dd0c0a-e0a4-4aae-b44d-6308fb6dbf26"
      },
      "source": [
        "downsampling_factor = 1\n",
        "indices_1 = np.argwhere(np.array(Y_train)==1)\n",
        "indices_0_new = np.argwhere(np.array(Y_train)==0)\n",
        "indices = np.arange(0,len(indices_0_new),downsampling_factor)\n",
        "indices_0_new = indices_0_new[indices]\n",
        "\n",
        "print(indices_0_new.shape)\n",
        "\n",
        "upsampling_factor = 10\n",
        "indices_1_new = indices_1\n",
        "for i in range(upsampling_factor):\n",
        "  indices_1_new = np.concatenate((indices_1_new, indices_1), axis=0)\n",
        "\n",
        "indices_0_new = np.concatenate((indices_1_new, indices_0_new), axis=0)\n",
        "\n",
        "print(indices_0_new.shape)\n",
        "\n",
        "indices_0_new = tf.random.shuffle(indices_0_new)\n",
        "\n",
        "X_to_train = np.array(X_train)[indices_0_new]\n",
        "Y_to_train = np.array(Y_train)[indices_0_new]\n",
        "\n",
        "\n",
        "X_to_train = np.reshape(X_to_train, (X_to_train.shape[0], X_to_train.shape[2]))\n",
        "Y_to_train = np.squeeze(Y_to_train, axis=1)\n",
        "print(X_to_train.shape, Y_to_train.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455893, 1)\n",
            "(637822, 1)\n",
            "(637822, 918) (637822,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC9Foj6lbEvL",
        "colab_type": "text"
      },
      "source": [
        "**Check the imbalane of the train/test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvCbtngmd6iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "85eb7e38-7e84-4a46-8175-5865274bca21"
      },
      "source": [
        "plt.hist(Y_to_train, bins=[0,1,2])\n",
        "\n",
        "fraud_count = np.unique(Y_to_train, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 28.52%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geeGh4HLc0Xg",
        "colab_type": "text"
      },
      "source": [
        "# ***The model using NN***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3MD1cOJcye2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import F1Score"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrkPujj1hlrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(dense1=128, dense2=64, dropout_rate=0.4, l1_rate=0.001, l2_rate=0.001, init_std=0.01, lr=0.001):\n",
        "  out_model = Sequential()\n",
        "  out_model.add(Dense(dense1, activation=\"relu\", input_shape=(X_train.shape[1],),\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dense(dense1, activation=\"relu\", \n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(dense2, activation=\"relu\", \n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dense(dense2, activation=\"relu\", \n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  '''out_model.add(Dense(dense1, activation=\"relu\", \n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(Dense(dense1, activation=\"relu\", \n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())'''\n",
        "\n",
        "  out_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  out_model.compile(\n",
        "            optimizer=Adam(learning_rate=lr),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=[tfa.metrics.F1Score(num_classes=2, average=\"micro\", threshold=0.9)])\n",
        "  \n",
        "  return out_model"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B8icGb9id1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "9624736c-7ab6-491a-b6d5-2d30724fdab8"
      },
      "source": [
        "my_model = create_model(dense1=128, dense2=64, dropout_rate=0.4, l1_rate=1e-4, l2_rate=1e-3, init_std=0.05, lr=0.00003)\n",
        "my_model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 128)               117632    \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 172,801\n",
            "Trainable params: 172,161\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UTsRGUjjzpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91392ed5-f270-4364-d519-0f79ec06b0ba"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "NB_EPOCH = 2000\n",
        "PATIENCE = 100\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_f1_score', patience=PATIENCE, verbose=0, mode='max',\n",
        "    baseline=None)\n",
        "\n",
        "best_model_hold = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/best_model', monitor='val_f1_score', verbose=1, save_best_only=True,\n",
        "    save_weights_only=True, mode='max')\n",
        "\n",
        "history = my_model.fit(X_to_train, Y_to_train, \n",
        "             batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "             validation_split=0.2, shuffle=True,\n",
        "             callbacks=[early_stop, best_model_hold])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.8873 - f1_score: 0.3009\n",
            "Epoch 00001: val_f1_score improved from -inf to 0.34562, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.8872 - f1_score: 0.3010 - val_loss: 0.7248 - val_f1_score: 0.3456\n",
            "Epoch 2/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.6934 - f1_score: 0.4037\n",
            "Epoch 00002: val_f1_score did not improve from 0.34562\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.6934 - f1_score: 0.4037 - val_loss: 0.6470 - val_f1_score: 0.3354\n",
            "Epoch 3/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.6322 - f1_score: 0.4058\n",
            "Epoch 00003: val_f1_score did not improve from 0.34562\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.6322 - f1_score: 0.4059 - val_loss: 0.6008 - val_f1_score: 0.3222\n",
            "Epoch 4/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.5917 - f1_score: 0.4126\n",
            "Epoch 00004: val_f1_score did not improve from 0.34562\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.5917 - f1_score: 0.4126 - val_loss: 0.5678 - val_f1_score: 0.3260\n",
            "Epoch 5/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.5595 - f1_score: 0.4276\n",
            "Epoch 00005: val_f1_score did not improve from 0.34562\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.5594 - f1_score: 0.4276 - val_loss: 0.5429 - val_f1_score: 0.3129\n",
            "Epoch 6/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.5341 - f1_score: 0.4430\n",
            "Epoch 00006: val_f1_score improved from 0.34562 to 0.40108, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.5341 - f1_score: 0.4430 - val_loss: 0.5120 - val_f1_score: 0.4011\n",
            "Epoch 7/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.5149 - f1_score: 0.4575\n",
            "Epoch 00007: val_f1_score did not improve from 0.40108\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.5149 - f1_score: 0.4575 - val_loss: 0.4969 - val_f1_score: 0.3818\n",
            "Epoch 8/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.5006 - f1_score: 0.4649\n",
            "Epoch 00008: val_f1_score improved from 0.40108 to 0.40545, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.5006 - f1_score: 0.4649 - val_loss: 0.4811 - val_f1_score: 0.4054\n",
            "Epoch 9/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.4881 - f1_score: 0.4760\n",
            "Epoch 00009: val_f1_score improved from 0.40545 to 0.42667, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4881 - f1_score: 0.4760 - val_loss: 0.4671 - val_f1_score: 0.4267\n",
            "Epoch 10/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.4772 - f1_score: 0.4869\n",
            "Epoch 00010: val_f1_score improved from 0.42667 to 0.42752, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4772 - f1_score: 0.4869 - val_loss: 0.4592 - val_f1_score: 0.4275\n",
            "Epoch 11/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.4683 - f1_score: 0.4922\n",
            "Epoch 00011: val_f1_score improved from 0.42752 to 0.48423, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4682 - f1_score: 0.4923 - val_loss: 0.4504 - val_f1_score: 0.4842\n",
            "Epoch 12/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.4593 - f1_score: 0.5045\n",
            "Epoch 00012: val_f1_score did not improve from 0.48423\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4593 - f1_score: 0.5045 - val_loss: 0.4421 - val_f1_score: 0.4651\n",
            "Epoch 13/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.4524 - f1_score: 0.5117\n",
            "Epoch 00013: val_f1_score did not improve from 0.48423\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4524 - f1_score: 0.5117 - val_loss: 0.4368 - val_f1_score: 0.4757\n",
            "Epoch 14/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.4459 - f1_score: 0.5193\n",
            "Epoch 00014: val_f1_score improved from 0.48423 to 0.49025, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4459 - f1_score: 0.5194 - val_loss: 0.4235 - val_f1_score: 0.4902\n",
            "Epoch 15/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.4400 - f1_score: 0.5248\n",
            "Epoch 00015: val_f1_score improved from 0.49025 to 0.51217, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4401 - f1_score: 0.5247 - val_loss: 0.4187 - val_f1_score: 0.5122\n",
            "Epoch 16/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.4342 - f1_score: 0.5325\n",
            "Epoch 00016: val_f1_score improved from 0.51217 to 0.52216, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4342 - f1_score: 0.5325 - val_loss: 0.4267 - val_f1_score: 0.5222\n",
            "Epoch 17/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.4286 - f1_score: 0.5384\n",
            "Epoch 00017: val_f1_score did not improve from 0.52216\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4286 - f1_score: 0.5384 - val_loss: 0.4090 - val_f1_score: 0.4912\n",
            "Epoch 18/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.4242 - f1_score: 0.5422\n",
            "Epoch 00018: val_f1_score improved from 0.52216 to 0.55917, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4242 - f1_score: 0.5422 - val_loss: 0.3998 - val_f1_score: 0.5592\n",
            "Epoch 19/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.4200 - f1_score: 0.5475\n",
            "Epoch 00019: val_f1_score did not improve from 0.55917\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4200 - f1_score: 0.5476 - val_loss: 0.3994 - val_f1_score: 0.5150\n",
            "Epoch 20/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.4153 - f1_score: 0.5539\n",
            "Epoch 00020: val_f1_score improved from 0.55917 to 0.55933, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4153 - f1_score: 0.5539 - val_loss: 0.3914 - val_f1_score: 0.5593\n",
            "Epoch 21/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.4121 - f1_score: 0.5585\n",
            "Epoch 00021: val_f1_score did not improve from 0.55933\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4121 - f1_score: 0.5585 - val_loss: 0.3917 - val_f1_score: 0.5312\n",
            "Epoch 22/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.4082 - f1_score: 0.5634\n",
            "Epoch 00022: val_f1_score improved from 0.55933 to 0.57902, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4082 - f1_score: 0.5634 - val_loss: 0.3892 - val_f1_score: 0.5790\n",
            "Epoch 23/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.4046 - f1_score: 0.5701\n",
            "Epoch 00023: val_f1_score did not improve from 0.57902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4047 - f1_score: 0.5700 - val_loss: 0.3794 - val_f1_score: 0.5706\n",
            "Epoch 24/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.4013 - f1_score: 0.5716\n",
            "Epoch 00024: val_f1_score improved from 0.57902 to 0.60065, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.4013 - f1_score: 0.5716 - val_loss: 0.3856 - val_f1_score: 0.6007\n",
            "Epoch 25/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.3983 - f1_score: 0.5762\n",
            "Epoch 00025: val_f1_score did not improve from 0.60065\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3983 - f1_score: 0.5762 - val_loss: 0.3800 - val_f1_score: 0.5412\n",
            "Epoch 26/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3955 - f1_score: 0.5806\n",
            "Epoch 00026: val_f1_score improved from 0.60065 to 0.60902, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3955 - f1_score: 0.5806 - val_loss: 0.3687 - val_f1_score: 0.6090\n",
            "Epoch 27/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.3927 - f1_score: 0.5824\n",
            "Epoch 00027: val_f1_score did not improve from 0.60902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3927 - f1_score: 0.5824 - val_loss: 0.3845 - val_f1_score: 0.5614\n",
            "Epoch 28/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3899 - f1_score: 0.5895\n",
            "Epoch 00028: val_f1_score did not improve from 0.60902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3899 - f1_score: 0.5895 - val_loss: 0.3729 - val_f1_score: 0.5894\n",
            "Epoch 29/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3879 - f1_score: 0.5909\n",
            "Epoch 00029: val_f1_score did not improve from 0.60902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3879 - f1_score: 0.5909 - val_loss: 0.3679 - val_f1_score: 0.5744\n",
            "Epoch 30/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.3854 - f1_score: 0.5935\n",
            "Epoch 00030: val_f1_score did not improve from 0.60902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3854 - f1_score: 0.5935 - val_loss: 0.3656 - val_f1_score: 0.5841\n",
            "Epoch 31/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3834 - f1_score: 0.5957\n",
            "Epoch 00031: val_f1_score did not improve from 0.60902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3834 - f1_score: 0.5958 - val_loss: 0.3598 - val_f1_score: 0.5686\n",
            "Epoch 32/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3805 - f1_score: 0.6009\n",
            "Epoch 00032: val_f1_score did not improve from 0.60902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3804 - f1_score: 0.6010 - val_loss: 0.3530 - val_f1_score: 0.5959\n",
            "Epoch 33/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3787 - f1_score: 0.6030\n",
            "Epoch 00033: val_f1_score did not improve from 0.60902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3787 - f1_score: 0.6030 - val_loss: 0.3662 - val_f1_score: 0.5763\n",
            "Epoch 34/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3763 - f1_score: 0.6064\n",
            "Epoch 00034: val_f1_score did not improve from 0.60902\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3763 - f1_score: 0.6065 - val_loss: 0.3527 - val_f1_score: 0.5954\n",
            "Epoch 35/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.3743 - f1_score: 0.6092\n",
            "Epoch 00035: val_f1_score improved from 0.60902 to 0.61276, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3743 - f1_score: 0.6091 - val_loss: 0.3466 - val_f1_score: 0.6128\n",
            "Epoch 36/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.3730 - f1_score: 0.6110\n",
            "Epoch 00036: val_f1_score improved from 0.61276 to 0.64368, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3729 - f1_score: 0.6110 - val_loss: 0.3511 - val_f1_score: 0.6437\n",
            "Epoch 37/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3705 - f1_score: 0.6170\n",
            "Epoch 00037: val_f1_score did not improve from 0.64368\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3705 - f1_score: 0.6170 - val_loss: 0.3456 - val_f1_score: 0.5984\n",
            "Epoch 38/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.3687 - f1_score: 0.6169\n",
            "Epoch 00038: val_f1_score did not improve from 0.64368\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3687 - f1_score: 0.6168 - val_loss: 0.3506 - val_f1_score: 0.5711\n",
            "Epoch 39/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.3668 - f1_score: 0.6195\n",
            "Epoch 00039: val_f1_score did not improve from 0.64368\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3669 - f1_score: 0.6195 - val_loss: 0.3529 - val_f1_score: 0.5497\n",
            "Epoch 40/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3657 - f1_score: 0.6210\n",
            "Epoch 00040: val_f1_score did not improve from 0.64368\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3657 - f1_score: 0.6210 - val_loss: 0.3482 - val_f1_score: 0.6270\n",
            "Epoch 41/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.3630 - f1_score: 0.6249\n",
            "Epoch 00041: val_f1_score did not improve from 0.64368\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3630 - f1_score: 0.6249 - val_loss: 0.3423 - val_f1_score: 0.6241\n",
            "Epoch 42/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3624 - f1_score: 0.6257\n",
            "Epoch 00042: val_f1_score did not improve from 0.64368\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3624 - f1_score: 0.6257 - val_loss: 0.3370 - val_f1_score: 0.6207\n",
            "Epoch 43/2000\n",
            "1987/1994 [============================>.] - ETA: 0s - loss: 0.3604 - f1_score: 0.6280\n",
            "Epoch 00043: val_f1_score improved from 0.64368 to 0.64701, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3604 - f1_score: 0.6281 - val_loss: 0.3367 - val_f1_score: 0.6470\n",
            "Epoch 44/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3590 - f1_score: 0.6288\n",
            "Epoch 00044: val_f1_score did not improve from 0.64701\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3590 - f1_score: 0.6288 - val_loss: 0.3410 - val_f1_score: 0.6203\n",
            "Epoch 45/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3574 - f1_score: 0.6306\n",
            "Epoch 00045: val_f1_score improved from 0.64701 to 0.65928, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3574 - f1_score: 0.6306 - val_loss: 0.3358 - val_f1_score: 0.6593\n",
            "Epoch 46/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.3566 - f1_score: 0.6341\n",
            "Epoch 00046: val_f1_score improved from 0.65928 to 0.67539, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3566 - f1_score: 0.6341 - val_loss: 0.3290 - val_f1_score: 0.6754\n",
            "Epoch 47/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.3555 - f1_score: 0.6364\n",
            "Epoch 00047: val_f1_score did not improve from 0.67539\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3555 - f1_score: 0.6364 - val_loss: 0.3336 - val_f1_score: 0.6094\n",
            "Epoch 48/2000\n",
            "1987/1994 [============================>.] - ETA: 0s - loss: 0.3542 - f1_score: 0.6363\n",
            "Epoch 00048: val_f1_score improved from 0.67539 to 0.68027, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3542 - f1_score: 0.6363 - val_loss: 0.3296 - val_f1_score: 0.6803\n",
            "Epoch 49/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.3520 - f1_score: 0.6385\n",
            "Epoch 00049: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3520 - f1_score: 0.6384 - val_loss: 0.3300 - val_f1_score: 0.6481\n",
            "Epoch 50/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.3504 - f1_score: 0.6399\n",
            "Epoch 00050: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3504 - f1_score: 0.6399 - val_loss: 0.3529 - val_f1_score: 0.5502\n",
            "Epoch 51/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.3495 - f1_score: 0.6422\n",
            "Epoch 00051: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3495 - f1_score: 0.6421 - val_loss: 0.3304 - val_f1_score: 0.6460\n",
            "Epoch 52/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.3486 - f1_score: 0.6430\n",
            "Epoch 00052: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3486 - f1_score: 0.6430 - val_loss: 0.3450 - val_f1_score: 0.5765\n",
            "Epoch 53/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3474 - f1_score: 0.6466\n",
            "Epoch 00053: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3474 - f1_score: 0.6467 - val_loss: 0.3453 - val_f1_score: 0.6263\n",
            "Epoch 54/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3454 - f1_score: 0.6497\n",
            "Epoch 00054: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3454 - f1_score: 0.6497 - val_loss: 0.3465 - val_f1_score: 0.5942\n",
            "Epoch 55/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.3446 - f1_score: 0.6511\n",
            "Epoch 00055: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3446 - f1_score: 0.6511 - val_loss: 0.3230 - val_f1_score: 0.6222\n",
            "Epoch 56/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.3431 - f1_score: 0.6528\n",
            "Epoch 00056: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3431 - f1_score: 0.6528 - val_loss: 0.3168 - val_f1_score: 0.6291\n",
            "Epoch 57/2000\n",
            "1987/1994 [============================>.] - ETA: 0s - loss: 0.3427 - f1_score: 0.6540\n",
            "Epoch 00057: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3428 - f1_score: 0.6541 - val_loss: 0.3264 - val_f1_score: 0.6095\n",
            "Epoch 58/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3412 - f1_score: 0.6565\n",
            "Epoch 00058: val_f1_score did not improve from 0.68027\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3412 - f1_score: 0.6565 - val_loss: 0.3197 - val_f1_score: 0.6250\n",
            "Epoch 59/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3409 - f1_score: 0.6557\n",
            "Epoch 00059: val_f1_score improved from 0.68027 to 0.69052, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3408 - f1_score: 0.6557 - val_loss: 0.3152 - val_f1_score: 0.6905\n",
            "Epoch 60/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.3392 - f1_score: 0.6594\n",
            "Epoch 00060: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3392 - f1_score: 0.6594 - val_loss: 0.3174 - val_f1_score: 0.6596\n",
            "Epoch 61/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3381 - f1_score: 0.6579\n",
            "Epoch 00061: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3381 - f1_score: 0.6579 - val_loss: 0.3125 - val_f1_score: 0.6672\n",
            "Epoch 62/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3371 - f1_score: 0.6620\n",
            "Epoch 00062: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3370 - f1_score: 0.6621 - val_loss: 0.3162 - val_f1_score: 0.6413\n",
            "Epoch 63/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3364 - f1_score: 0.6607\n",
            "Epoch 00063: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3364 - f1_score: 0.6607 - val_loss: 0.3187 - val_f1_score: 0.6068\n",
            "Epoch 64/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3353 - f1_score: 0.6625\n",
            "Epoch 00064: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3353 - f1_score: 0.6625 - val_loss: 0.3088 - val_f1_score: 0.6711\n",
            "Epoch 65/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3347 - f1_score: 0.6615\n",
            "Epoch 00065: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3347 - f1_score: 0.6615 - val_loss: 0.3033 - val_f1_score: 0.6707\n",
            "Epoch 66/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.3333 - f1_score: 0.6648\n",
            "Epoch 00066: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3333 - f1_score: 0.6648 - val_loss: 0.3128 - val_f1_score: 0.6536\n",
            "Epoch 67/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3316 - f1_score: 0.6659\n",
            "Epoch 00067: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3316 - f1_score: 0.6659 - val_loss: 0.3082 - val_f1_score: 0.6657\n",
            "Epoch 68/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.3326 - f1_score: 0.6634\n",
            "Epoch 00068: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3326 - f1_score: 0.6634 - val_loss: 0.3053 - val_f1_score: 0.6708\n",
            "Epoch 69/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3306 - f1_score: 0.6679\n",
            "Epoch 00069: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3306 - f1_score: 0.6679 - val_loss: 0.3053 - val_f1_score: 0.6659\n",
            "Epoch 70/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.3293 - f1_score: 0.6695\n",
            "Epoch 00070: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3294 - f1_score: 0.6695 - val_loss: 0.3037 - val_f1_score: 0.6407\n",
            "Epoch 71/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.3298 - f1_score: 0.6696\n",
            "Epoch 00071: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3298 - f1_score: 0.6697 - val_loss: 0.2983 - val_f1_score: 0.6617\n",
            "Epoch 72/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3283 - f1_score: 0.6710\n",
            "Epoch 00072: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3283 - f1_score: 0.6709 - val_loss: 0.3049 - val_f1_score: 0.6221\n",
            "Epoch 73/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3274 - f1_score: 0.6715\n",
            "Epoch 00073: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3274 - f1_score: 0.6715 - val_loss: 0.3051 - val_f1_score: 0.6566\n",
            "Epoch 74/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.3271 - f1_score: 0.6743\n",
            "Epoch 00074: val_f1_score did not improve from 0.69052\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3271 - f1_score: 0.6743 - val_loss: 0.3113 - val_f1_score: 0.6450\n",
            "Epoch 75/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.3259 - f1_score: 0.6736\n",
            "Epoch 00075: val_f1_score improved from 0.69052 to 0.70178, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3259 - f1_score: 0.6736 - val_loss: 0.3059 - val_f1_score: 0.7018\n",
            "Epoch 76/2000\n",
            "1987/1994 [============================>.] - ETA: 0s - loss: 0.3251 - f1_score: 0.6760\n",
            "Epoch 00076: val_f1_score did not improve from 0.70178\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3251 - f1_score: 0.6759 - val_loss: 0.2961 - val_f1_score: 0.6651\n",
            "Epoch 77/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3240 - f1_score: 0.6759\n",
            "Epoch 00077: val_f1_score did not improve from 0.70178\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3241 - f1_score: 0.6759 - val_loss: 0.3001 - val_f1_score: 0.6826\n",
            "Epoch 78/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3231 - f1_score: 0.6787\n",
            "Epoch 00078: val_f1_score improved from 0.70178 to 0.71642, saving model to /content/best_model\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3231 - f1_score: 0.6787 - val_loss: 0.2953 - val_f1_score: 0.7164\n",
            "Epoch 79/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.3228 - f1_score: 0.6756\n",
            "Epoch 00079: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3228 - f1_score: 0.6756 - val_loss: 0.2991 - val_f1_score: 0.6648\n",
            "Epoch 80/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.3214 - f1_score: 0.6804\n",
            "Epoch 00080: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3214 - f1_score: 0.6804 - val_loss: 0.3011 - val_f1_score: 0.6362\n",
            "Epoch 81/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3218 - f1_score: 0.6784\n",
            "Epoch 00081: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3218 - f1_score: 0.6784 - val_loss: 0.3103 - val_f1_score: 0.6260\n",
            "Epoch 82/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3210 - f1_score: 0.6808\n",
            "Epoch 00082: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3210 - f1_score: 0.6808 - val_loss: 0.2997 - val_f1_score: 0.6471\n",
            "Epoch 83/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3210 - f1_score: 0.6806\n",
            "Epoch 00083: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3209 - f1_score: 0.6807 - val_loss: 0.3029 - val_f1_score: 0.6179\n",
            "Epoch 84/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.3189 - f1_score: 0.6843\n",
            "Epoch 00084: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3189 - f1_score: 0.6843 - val_loss: 0.2940 - val_f1_score: 0.6454\n",
            "Epoch 85/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.3181 - f1_score: 0.6847\n",
            "Epoch 00085: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3181 - f1_score: 0.6846 - val_loss: 0.2943 - val_f1_score: 0.6705\n",
            "Epoch 86/2000\n",
            "1989/1994 [============================>.] - ETA: 0s - loss: 0.3184 - f1_score: 0.6834\n",
            "Epoch 00086: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3184 - f1_score: 0.6834 - val_loss: 0.3010 - val_f1_score: 0.6535\n",
            "Epoch 87/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3174 - f1_score: 0.6854\n",
            "Epoch 00087: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3174 - f1_score: 0.6854 - val_loss: 0.2958 - val_f1_score: 0.6429\n",
            "Epoch 88/2000\n",
            "1993/1994 [============================>.] - ETA: 0s - loss: 0.3176 - f1_score: 0.6858\n",
            "Epoch 00088: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3176 - f1_score: 0.6858 - val_loss: 0.3092 - val_f1_score: 0.6342\n",
            "Epoch 89/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3172 - f1_score: 0.6860\n",
            "Epoch 00089: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3172 - f1_score: 0.6860 - val_loss: 0.3013 - val_f1_score: 0.6417\n",
            "Epoch 90/2000\n",
            "1992/1994 [============================>.] - ETA: 0s - loss: 0.3160 - f1_score: 0.6872\n",
            "Epoch 00090: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3160 - f1_score: 0.6872 - val_loss: 0.2963 - val_f1_score: 0.6268\n",
            "Epoch 91/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3149 - f1_score: 0.6898\n",
            "Epoch 00091: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3149 - f1_score: 0.6898 - val_loss: 0.2848 - val_f1_score: 0.6852\n",
            "Epoch 92/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3145 - f1_score: 0.6874\n",
            "Epoch 00092: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3145 - f1_score: 0.6874 - val_loss: 0.2935 - val_f1_score: 0.6307\n",
            "Epoch 93/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3132 - f1_score: 0.6888\n",
            "Epoch 00093: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3132 - f1_score: 0.6888 - val_loss: 0.2849 - val_f1_score: 0.6774\n",
            "Epoch 94/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3133 - f1_score: 0.6901\n",
            "Epoch 00094: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3133 - f1_score: 0.6901 - val_loss: 0.3004 - val_f1_score: 0.6353\n",
            "Epoch 95/2000\n",
            "1990/1994 [============================>.] - ETA: 0s - loss: 0.3131 - f1_score: 0.6892\n",
            "Epoch 00095: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3131 - f1_score: 0.6892 - val_loss: 0.2962 - val_f1_score: 0.6606\n",
            "Epoch 96/2000\n",
            "1991/1994 [============================>.] - ETA: 0s - loss: 0.3127 - f1_score: 0.6900\n",
            "Epoch 00096: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3127 - f1_score: 0.6899 - val_loss: 0.2877 - val_f1_score: 0.6702\n",
            "Epoch 97/2000\n",
            "1994/1994 [==============================] - ETA: 0s - loss: 0.3113 - f1_score: 0.6929\n",
            "Epoch 00097: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3113 - f1_score: 0.6929 - val_loss: 0.2884 - val_f1_score: 0.6694\n",
            "Epoch 98/2000\n",
            "1988/1994 [============================>.] - ETA: 0s - loss: 0.3111 - f1_score: 0.6925\n",
            "Epoch 00098: val_f1_score did not improve from 0.71642\n",
            "1994/1994 [==============================] - 16s 8ms/step - loss: 0.3111 - f1_score: 0.6924 - val_loss: 0.2924 - val_f1_score: 0.6419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsIE6_stkBAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "95fbbe79-0e88-4f9f-e2e9-81b915887da3"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.plot(history.history[\"loss\"], '-b')\n",
        "plt.plot(history.history[\"val_loss\"], '-r')\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(history.history[\"f1_score\"], '-b')\n",
        "plt.plot(history.history[\"val_f1_score\"], '-r')\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff90c3d9438>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3hUxfrHP5MEEkhogdBCCQgooEgJxY6IBVTAcrlgb2C9Yrlewfazol7r5cpFsXdRREBAEJBioasUUSHSe+g1pOz7++PdZVPJJiRsdvN+nuc8u+ecOefM7Em+884778w4EcEwDMMILyKCnQHDMAyj5DFxNwzDCENM3A3DMMIQE3fDMIwwxMTdMAwjDIkK1oNr1aolSUlJwXq8YRhGSLJo0aLtIpJQWLqgiXtSUhILFy4M1uMNwzBCEufc2kDSmVvGMAwjDDFxNwzDCENCTtyHD4eEBMjICHZODMMwyi4hJ+4VK8L27bB5c7BzYhiGUXYJOXFv0EA/N24Mbj4MwzDKMiEn7omJ+rlhQ3DzYRiGUZYJOXH3We4m7oZhGAUTcuJeowZUqmTibhiGcTRCTtydU+vdfO6GYRgFE3LiDiruZrkbhmEUTEiKe2KiibthGMbRCElx97llPJ5g58QwDKNsErLinpkJ27YFOyeGYRhlk4DE3Tl3kXPuT+dcinNucD7nGznnZjjnfnHOLXHO9Sz5rPqxgUyGYRhHp1Bxd85FAsOBHkAroL9zrlWuZI8An4tIO6Af8L+Szmh2bCCTYRjG0QnEcu8EpIjIKhFJBz4DeudKI0BV7/dqwKaSy2JebCCTYRjG0QlE3BOB9dn2N3iPZedx4Brn3AZgEvCP/G7knBvonFvonFuYmppajOwqtWtDVJSJu2EYRkGUVIdqf+A9EWkA9AQ+dM7lubeIjBSRZBFJTkgodJWoAomIsHBIwzCMoxGIuG8EGmbbb+A9lp2bgc8BRGQOEAPUKokMFoSNUjUMwyiYQMR9AdDcOdfEOVcR7TAdnyvNOuA8AOdcS1Tci+93CQCz3A3DMAqmUHEXkUzgLmAK8DsaFfObc+5J51wvb7L7gQHOucXAp8ANIiKllWnwT0FQuk8xDMMITaICSSQik9CO0uzHHsv2fTlwRslm7eg0aACHDsGuXRAffzyfbBiGUfYJyRGqYOGQhmEYRyNkxd03kMk6VQ3DMPISsuJulrthGEbBhKy416unC3eYuBuGYeQl9MR93Djo1YsKkR7q1jVxNwzDyI/QE/fdu+Hrr2HpUluRyTAMowBCT9y7d9fPqVNJTLQOVcMwjPwIPXFPTIRWrWDqVLPcDcMwCiD0xB3g/PNh9mwa10ljzx7Yty/YGTIMwyhbhK64p6XR7sAPAKxZE9zsGIZhlDVCU9zPOQcqVKDj7qkATJgQ5PwYhmGUMUJT3OPi4PTTqTpvKqefDp99FuwMGYZhlC1CU9xBXTO//MINF6eyZAksXx7sDBmGYZQdQlvcgb/VmEZEhFnvhmEY2Qldce/QAWrUoPqCqXTtquJuc7sbhmEooSvukZHQrRtMnUq/vwsrV8IvvwQ7U4ZhGGWD0BV3gAsugA0b+FuLxURFmWvGMAzDR2iL+5VXQuXKVH/vVS64AEaNAo8n2JkyDMMIPqEt7vHxcPPN8Mkn3HjBRtatgx9+CHamDMMwgk9oizvAvfdCVha91gyjVi146qlgZ8gwDCP4hL64N2kCV15JxXde57F79jJtGsycGexMGYZhBJeAxN05d5Fz7k/nXIpzbnABafo655Y7535zzn1SstkshAcegL17uS3qLerXh4cftrBIwzDKN4WKu3MuEhgO9ABaAf2dc61ypWkODAHOEJHWwD2lkNeCSU6Gc86hwvBXeWxIBj/9BJMnH9ccGIZhlCkCsdw7ASkiskpE0oHPgN650gwAhovILgAR2Vay2QyABx6A9eu52fMmSUnwyCNmvRuGUX4JRNwTgfXZ9jd4j2WnBdDCOfejc26uc+6i/G7knBvonFvonFuYmppavBwXRM+e0L07UY8M5t+DNvLzz/D55yX7CMMwjFChpDpUo4DmQFegP/Cmc6567kQiMlJEkkUkOSEhoYQe7cU5eP11yMzkypl30bYt3HMP7NpVso8xDMMIBQIR941Aw2z7DbzHsrMBGC8iGSKyGliBiv3x5YQT4PHHcePG8uXVY0hNhfvuO+65MAzDCDqBiPsCoLlzrolzriLQDxifK81Y1GrHOVcLddOsKsF8Bs5990HbtjR9+S7+b9Bu3nvPOlcNwyh/FCruIpIJ3AVMAX4HPheR35xzTzrnenmTTQF2OOeWAzOAB0RkR2ll+qhERcFbb8HWrTy08kZanujh1lttnVXDMMoXToIUUpKcnCwLFy4svQcMGwaDBrHxmgdp+PFzXHcdvPuuuuYNwzBCFefcIhFJLixd6I9QLYh//ANuv53Ej55nzKXv8v778PLLwc6UYRjG8SF8xd05+M9/oHt3en9zK4+eM5sHHoCJE4OdMcMwjNInfMUdoEIF+OILXJMmPJ5yNWedspv+/WHZsmBnzDAMo3QJb3EHqF4dPvqIiC2bmdRiEHFxuvzqkiXBzphhGEbpEf7iDtCxIzz0ELGjP2DekLFERsLZZ8P33wc7Y4ZhGKVD+RB30Mlm2rWj4VMDmft1KnXr6ip948YFO2OGYRglT/kR94oV4YMPYM8eGtx9OT+N3sQpp0CfPnDnnbB/f7AzaBiGUXKUH3EHOPlkeO89+Pln4ru24ft/fc1998GIEXDqqeamMQwjfChf4g7Qvz8sWgQNGxL9t168lP4PZn+bBqgf/sYbYevWIOfRMAzjGCl/4g5w0kkwd67OQ/Paa5z54Bks+eovHnwQPv4YTjxRQ+TT04OdUcMwjOJRPsUdIDoaXnoJxo+H1auJPas9z3X4gqVLoXNnnS74xBPVi5OZGezMGoZhFI3yK+4+Lr0UfvkFWraEvn058YmrmPzxDr75BmrWVDfNySfDyJFw4ECwM2sYhhEYJu4AjRtrb+oTT+iI1tatuGj/aBbM8/DVV1C5Mtx6KzRoAP/8J6wKzmTGhmEYAWPi7qNCBXjsMVi4EBIT4W9/wzVvRp/FT7DoyzV8/73Gxb/6KjRrBr16wZQp4PEEO+OGYRh5MXHPzamnwrx52rN6wgnwxBO4pk0485kejLp2AmtXZfHII5rkoougUSMYNAh++MGE3jCMskP4zudeUqxbB++8o073zZshKQkGDODwVTcyZk49Ro3SlZ4OH4Y6ddSi79MHunWDmJhgZ94wjHAj0PncTdwDJSMDxo6F//0PZs6EyEjtjL3ySvYnd+XrnxMZOxYmTdLRrpUqQdeu6sq58EKNvrSFQgzDOFZM3EuTFSt0Kb/334dt2/RYs2Zw7bUcHvQvZsyJYdIk+PZb+PNPPd2wobpxLrxQrfoaNYKXfcMwQhcT9+NBVpbOHTxzpvauTpmiwfEjR+pwV2DNGhX5KVNg1tR0IvftYntEHZKToXt36NIFkpOhXr2glsQwjBDBxD0YfPst3HYbrF6tjvdzz4XTT9dFu997D/n4Y9z27Xx37lM8mvYw8+Y7srL00sREFfkOHXTr1Alq1QpucQzDKHuUqLg75y4C/gNEAm+JyHMFpLsCGA10FJGjKndYijvoSKenntJomw0b/McrVoTevfX7F1/AVVdxYNjb/PJ7DAsWwIIFOuXNihX+S5o317qhXTttEJx4okbnREYe3yIZhlF2KDFxd85FAiuA84ENwAKgv4gsz5WuCjARqAjcVW7FPTvr18OcObB3L1x2mQ55FYFnn4WHH1afzLBhupiIl7174eefNdTyp5/08tRU/y0rV4ZTTtGIzTZtoHVr3RISglA+wzCOOyUp7qcBj4vIhd79IQAi8myudK8CU4EHgH+auBfCl1/CTTepmp9xBtx9t5rmFSqolZ+UBFFRiKi4//mnbsuWweLFuu3a5b9dQoLOoODbmjfXLSlJb2kYRngQqLhHBXCvRGB9tv0NQOdcD2sPNBSRic65B4qU0/LKFVfoYq7vvqtTUP797znP160L112Hu/FGap90ErVrw1ln+U+LwKZN8NtvKvjLl8Pvv8Pnn+cU/chInV2hadOcW5Mm+hkff3yKaxjG8SUQy/1K4CIRucW7fy3QWUTu8u5HAN8BN4jIGufcTAqw3J1zA4GBAI0aNeqwdu3akixL6JKVBbNnqypnZKjfftw4mDhRz1WurJ+Zmfq9USNV7FNPhTvu0ElvvIjAtnVppGyIYeVKWLlS+3dXrYK//oLt23M+unp1HYjbuLEOwqpTB+rX9z+iUSN9pGEYZYPj5pZxzlUD/gJ8C9XVBXYCvY7mmin3bplA2LIFPv0UNm7UiJuoKNi3T0fNrl2rYZgREXDNNdoS+P57mDBBzflWreC88zTeskePI76Zfftg4+y/qPWvm9gZmcAnJw9lzo4WbNigi5Ts2JE3G1WrakOifn2tCJo108+6ddUdlJCgLQAbpGUYpU9JinsU2qF6HrAR7VC9SkR+KyD9TMznfnxYs0bnpH/rLUhLU/E/5xydkH7RIm0NHDqkzvehQ7UCGDNGff0REdoSSEvT8M0hQ6B+fTIydJaFtWt1W79e65gtWzT456+/8l+pKjpaB2o1bKiVQL16Kv61aumArRo1tBJo2BBiY4/7L2UYYUNJh0L2BF5FQyHfEZFnnHNPAgtFZHyutDMxcT++bNumc9J36QLVqvmPHz4M33wDjzyi1nzz5uqn6dRJnfMxMfD44/Dmm+r2ad5cHfvJyarCDRqocz77PVHrf9UqfWxqKuxfuZm/9iawdmMU69dr5bB5s9Yb+REfr7euUwdq19bN9z0hQV1F1arpVreu9i8bhqHYICbDT1YWfPABPPccXHyxfmZXzBUrdEWq77/X6S137vSfc07F3jdJzumn+wPt9+7ViuO11zQY/6239BP1/e/dqz7+Xbt027pVWwLr16unads23bZuLXghlIgIfx1To4a2EKKjtQKoU8fvGvK1DuLjNeLUKgQjXDFxN4qHx6Nm98aN6odZuhSmTtU1Z7OyVEn79IG2bdXVs2kTXH01TJumZvz996vgV6lSpMce2Odhx+/b2P3XDlKrnsCuQzHs3q3dC6tXqwdq715tjBw+rJXFnj0F369KFRX72FjtEK5cWfsOfFu1alpB+CqJ+vV1lHDt2lp5cOCAuq1ytVoMI9iYuBsly+7dOr3CmDEaxbN/v46iGjlSffy7dsEDD8Dbb6vZfPbZ0LOnquu8eTB/vqpy1646c1qTJjpC6/vvdYGUTZv8i9VWrKgtgNNO007hc8/N11GflqZWf2qqPn7nTt127NBt1y7V6IMH9XPfPq0g9u7V4hS0AHpS5W1MSz+LKuzj9pN/YE/NpsTGQlycblUrZRAfl0612ExqxKZTL24fdWL2ULOGh5jT2lE5LoKoQIKMDaMYmLgbpUdamlr0bdvmHSE1f75OrzBxogbeg/pJOnXSDt9Zs1RdfTRpoiKelKTmc/XqOkJrzhwV/bQ0FfuzztLIn3POUTdR7udu2aLpd+3SQWFNmhQavpOWpiK/ZYs2VDZuhN3r9tL/zXOpveN30iNi2BdVg9ta/8Da9Hq4fXt5cMs9/P3Qe0SQ///NGwzkNl6nYkVHtWrqJoqP15aDL+ApNlZ/kvh4bUVUqKBbpUp6PCFBP6tU0S0uTt1ThgEm7kZZYO1atcabNvULbWamzq+wfr12ACcmFnx9Wpr2AUyerNNqLlumx2NjNQjfp5Zbt6oyZ6dBA20l9Omjcy37LP/NmzWENDFRJ9nPbmKnpWlrY/ZsHWeQkKAth6QkeOYZHUW8fj3cdhtZDRuTllWBQxkV2OWpyo70qsTOn8EpM4Yx89wnmNzpMfbs8bck0tK06L5hDDt26LlAV++Ki9OKoEoV7QePjtbP2Fh/JVC5sr9PIi7O3wcRH+8PWa1aVVsy+/drIFXNmhrRZPMVhQ4m7kb4sW2bCu+sWSrSmZnaD1Ctmlrzycn6/fvvNc306aqilSppRZKSouLsIyYGTj5ZFS8jQyuJFSvgww917ADAd9+p4B8+rMH9H36oLY38EIEbb9R5/t98E265JW+azZv1XklJeDwqsBkZuh08qNndvl0/9+5VV1L2be9erSh8fQ8HDvjTHTyox9LSNCuBEhGhfQ01avgjlSIi1G2VkaE/U3y8nq9WTSuU2Fj9WSMjdatY0d+PUa2aVjQxMZomLs46uEsSE3fDyMxUoR8zRlsAJ56oIt+2rVr6v/yiLiDfGIEKFbRz+Prrc95n6lStLAYPVqU6GhkZOvvnlClq6ffqBWeeqfNDvPACfPaZVkht2sDll8Mll+j3ok4AJKI+papV85jdIlpp+KKUfJVFaqp2Qvv6D6KjtfXgG8fg66Tes0fv4XMXpaX5+zP27OHINNVFITo6p5spNlaPRUZqRVK5sr+lERurP2NmpuYjJsa/RUToFhmpLY66dXXzVSiVK+t534DuqCh9TjgNsDNxN4xgceCAWvDjxqn5Gxurx+LiYMAAdRl99RX8+KNfvTp00HEGW7dq5/LevdqpfOaZ0L69VkZLl6pryhc+dOCAurz+9S+tkPJbtPfgQXWPNW9OSfTyimiRDh7UCiQrS7fDh/0d1bt367m0NL8LyNfy2L/fv5+ertd6PFoUX2V04IC/YgG9T3EqFB8REf7Wgy+/4J+jz1fxVKuWM6KqShU958tLXJx//EV0tP4WPvn0VTiRkf70MTHakvG1eEqq38TE3TCCzf796hqaMkUn6bn11pzrK27Zoqt4zZun29q1aoYmJqo/Y8ECFXIfFSpoP4FvMqB69XR20QUL9LqbbtI+gtNPV4V97TUYMUJN7thYnVq6Y0cV+hNO0L4En78kIsJv/hZk5no8qsoej25r1mjH+YQJ2nneubNGQnXvrs85FnM5JQX++19tWd16KxmX9SUtIxIRfXRWlrZEfK2Offu0UvCNl/AJbWamHtu/XyuTyAihw6ovaL7+OxYn9WZJnfM5lBF1JIpqz56cUVWHDx9bxZKdiAj9SSIiYPhwreeLg4m7YYQDmzbBr79q5dCiRV7ntYj2Czz/vH5mZfnNSp+L6JJLVCTnztV7ZWQU/LyYGPV3tGmjIajnnqt+na++0pbIli050zunot6mjd5/yRI93r69urEuv1zVbMsWbXnUq6fzHvlcSSJ67q+/9HPzZnWDTZigLY0GDbSCa9kSBg3SpsCKFToG44ILtMVStWrecuzbpx3xhw9rWG6jRjpo4o47tEKqUEF/h3r11BXXvbtWivmMz/B4/B3hPreVL4w2etNqKq1axoHm7UirmUhmljvSh3LokNaxPneXr5Uioq+lc+c8jwoIE3fDKG/s3at9DNOn6/7tt6uVnp3MTBXGVatU7HyObY9HlWjHDnUNzZvnX90d1PLv0UMVKSpKxblmTZ22OvtKMampMHYsvPiiinCjRupX8S0kDyrGp52mard4cc7VaEDvd9ttmv86dbR18sQTOoUGaOunZk217uPi4LrrtD/F5x/64QetILIPZGjcWMvm8ehKabfdpuL/3nswaZJeGxGh7rF779UpuH1+FI9Hf4+6dTXEFvQ3e+89uOsurXBAe6XPPFNdcj165B+ClJWlv6svfKkYmLgbhnFsbNqk0UlVqqi7Jz+ffkFkZanIv/uuiljbtrqE2MaN2tcwZ45az6eeqluLFv4Z52rWzOug9nhU3OvX1/OgYyqGD9dO6txCfvnlulWpop3hs2Zpq2foUL9A+9i/3z+gbuxYbWF06KAVyooV6tpauVLTXnih+lO++kqX0jz3XB2RvXy5Ttb3zTdaOTZsqBVEdLRWbnv26H2XLFGTfsQIrWCKgYm7YRjlgwMHVEAjI/2jxIrr7/d4VLQfftgfNnv66TBwoPaJjBypFVREhE6699BDOS30jAydp+mNN3RKDue0/6RyZXVHtWunW9eu2qopBibuhmEYxSUtTa3zVq20ZeEjM1NFu06dI5PkFYjHUypDi0tymT3DMIzyRUwM9O+f93hUlI54DoQgzxlhM1YYhmGEISbuhmEYYUjQfO7OuVSguCtk1wK2F5oqPLGyl0/Ka9nLa7mh4LI3FpFC4yiDJu7HgnNuYSAdCuGIld3KXp4or+WGYy+7uWUMwzDCEBN3wzCMMCRUxX1ksDMQRKzs5ZPyWvbyWm44xrKHpM/dMAzDODqharkbhmEYR8HE3TAMIwwJOXF3zl3knPvTOZfinBsc7PyUFs65hs65Gc655c6535xzg7zH451zU51zK72fNQq7V6jinIt0zv3inJvg3W/inJvnffejnHNhuTKnc666c260c+4P59zvzrnTyst7d87d6/17X+ac+9Q5FxOu7905945zbptzblm2Y/m+Z6cM8/4GS5xz7Qu7f0iJu3MuEhgO9ABaAf2dc62Cm6tSIxO4X0RaAV2AO71lHQxMF5HmwHTvfrgyCPg92/7zwCsi0gzYBdwclFyVPv8BJovIScCp6G8Q9u/dOZcI3A0ki8jJQCTQj/B97+8BuSeqKeg99wCae7eBwIjCbh5S4g50AlJEZJWIpAOfAb2DnKdSQUQ2i8jP3u/70H/wRLS873uTvQ/0CU4OSxfnXAPgYuAt774DugGjvUnCsuzOuWrA2cDbACKSLiK7KSfvHZ3MsJJzLgqoDGwmTN+7iMwGduY6XNB77g18IMpcoLpzrt7R7h9q4p4IrM+2v8F7LKxxziUB7YB5QB0R2ew9tQWoE6RslTavAv8CPN79msBuEcn07ofru28CpALvel1SbznnYikH711ENgIvAutQUd8DLKJ8vHcfBb3nImtfqIl7ucM5Fwd8CdwjInuznxONYw27WFbn3CXANhFZFOy8BIEooD0wQkTaAQfI5YIJ4/deA7VQmwD1gVjyui3KDcf6nkNN3DcCDbPtN/AeC0uccxVQYf9YRMZ4D2/1Nce8n9sKuj6EOQPo5Zxbg7reuqF+6Ore5jqE77vfAGwQkXne/dGo2JeH994dWC0iqSKSAYxB/xbKw3v3UdB7LrL2hZq4LwCae3vPK6KdLeODnKdSwetjfhv4XUReznZqPHC99/v1wLjjnbfSRkSGiEgDEUlC3/F3InI1MAO40pssXMu+BVjvnDvRe+g8YDnl4L2j7pguzrnK3r9/X9nD/r1no6D3PB64zhs10wXYk819kz8iElIb0BNYAfwFPBzs/JRiOc9Em2RLgF+9W0/U9zwdWAlMA+KDnddS/h26AhO835sC84EU4AsgOtj5K6UytwUWet/9WKBGeXnvwBPAH8Ay4EMgOlzfO/Ap2reQgbbYbi7oPQMOjRT8C1iKRhQd9f42/YBhGEYYEmpuGcMwDCMATNwNwzDCEBN3wzCMMCSq8CSlQ61atSQpKSlYjzcMwwhJFi1atF0CWEM1aOKelJTEwoULg/V4wzCMkMQ5tzaQdOaWMQzDCENM3A3DOP6sXQs7dgQ7F2GNibthGMeXw4ehSxcYMCDYOQlrTNwNwzi+jBoFW7bAt99CenqwcxO2mLgbhlGyHDhQ8DkRGDYMoqM13Y8/Hr98lTNM3A3DKDnmzYPq1WHOnPzPz50LixbBk09ChQowefLxzV85wsTdMIySY8IEyMyE4cPzP//f/0K1anDHHXDmmeVC3A8dgl9/hSVLYMUKWL8eDh4s/ecGLc7dMIxsLF4MH38Mzz0HESFsc333nX6OHq3ul/h4/7lNm+CLL+Af/4C4OLjoInjwQT1ev35w8puLrCxYuVKFePlySEiA1q11A+0q2LxZP7du1c/Dh6FqVa2zYmLU27R/v55ftAiWLdP7Zud//4Pbby/dspi4G0ZZ4I03YMQIOO00uOyyYOemeOzfD/PnQ8+eMGkSfPghDBrkP//666pyd96p+z5xnzIFbryxWI/cuRN++kk/09N1i42FOnWgdm0V3pQU3bZuhbQ0PZaeDhkZuh0+rFGZO3ZAaqqvj1e4mbcZSU82U3DFU6mSbnv25BTwqCioUQPatoXBg+HUUyEyUp+flqavubQJ2pS/ycnJYiNUjaDz9dfQrh00aBDcfLRrp233jh3Vb+1ccPNTHCZPhh49NArm4YfV97B0qZZl82Zo00ZDIL/+ml27ILqiULl5Ipx1FowaxcGD8M03KsRNm0KzZiqQf/wBv/0Gq1Zpf2xkpIry3LlqYQciYRERUKuWWtbR0VCxorr8K1TQ7/Hxer5WLWjVCjpV/YNWV7Rk38D7mHPFSyxfrs+tWzfnFhenxRPR4h4+rMcqViy9n9k5t0hEkgtLZ5a7Ef4cPqwiftll+h/qY+9e6NMHLr4YxgdxQa8DB1SlmjaFBQtgxgzo1i14+SkiBw7omKT6X82gWoUK7DzpDPaeP5AmQwfw1s1zWBPfnoGfXEbd3Qf5575nGNcY1q2DyEjH6GoXcf64sdzyt0zGT4o6qi+6Rg19fVlZKqjt2sFTT8E556hXxyfY+/bBtm1qqVeoAM2bQ1KSinrAvD4TgCrzpnPBG3DBBdnOPfywKviQIUcOOacthtjYovxypYtZ7kZ4k5UF/fqpD3jCBBVyHzNnwrnn6vc//oATT8z3FqWOLx9jxmhH4ymnqPVbFGbNgtmzVcFiYqBTJ7WSC2LdOk3fpYuayF4yM9XIPnBAv2dmqsshNVUFc/dutVAPHNB0v/6qnYQiMJ+OHKIS5zCbWPazmXqM4QqiIzLo5/mEvlFjWHLCZbRrp+6KffsgZvznPLL07/Ss/hON/n4afftC+/awZo1a8Dt36mtp3Vqt6kJZvlwT1q5dtN8vN/37w2ef6fetW/33279f7x8drcdjYvK//tAh/X0rVVJnfL16x54nL4Fa7kFbYqpDhw5iGKWKxyNy550iqj0iDz2U8/wLL+jxihVFbr01OHkUERk6VPOxY4fI88/r94UL9dzPP4vcd5/I5s1Hv0fz5v5ygkhUlMj06ZKeLrJypcicOSITvzwki24eLvvanpEj7ab67eV/Sc9J07oHJCIi523y2yIiRKpUEWnSRKRPH5HHHxf5fOQuyXIRMr/HY/LKKyJjx4rs6jvQf9Ezz+Sf7x07xBMRIZ5HHzv233H9epHKlTVj26jysbcAAB/zSURBVLYV/z4ej0jduiInnqh5//RT/7kvv/SX6auv8r/+xx9FWrTI+z4mTy5+nrIBLJRAlvELJFFpbCbuRqnjE8377xdp316kW7ec5/v2FWncWGTAAJGYmGMThGOhVy8VEhGRPXtEqlUT6d5d5Morj4hDVv+r5YcfRJ58Uov1zjsiEyeKfPaZyH8e2SYC8mXyUHlo0H757+ANsqVmK9kbVV3aRP8hIFKXTTKXTiIgS2ktD7unpXu1+XIvL8kcOouAzDjxVnnsMZE33hD55BORzz8XmfXULJk7crEsXqz1S1qaal8exo3TvM6Y4T+2aJGIcyJXX13ARV5OO02kVSuRrKxj+x2vukokOlrf5emnixw6VLz7/PmnluV//xOpXl3kppv85669VqRGDZGEBP37yc7BgyL33qtlbtRI5IsvRKZNExk9WqRpU5E2bY69jGLibpR3Jk3SP++rr9Z/qDvvFImLE8nM9Kdp2lQF9PffNe3jjx+37O3YIfL99yJfjfHI4eoJsq3n9TJ9usj//Z/Ihw2HiIDsc3HybuPHZFzS3SIgycwX5/Ja0peiwtor/nuJjtZjzaNWyY6oBNlW7QSZcv8UOVQzUTIrxcqql8fIqFEijz0mcsMNKuQbN4rI3XerSf7rr/5M/vabimWbNnkLsHu3yIIF/v177lFRzS2of/whkpFx9B/jo4800198UdyfU+SHH/Qejzyi9wGR/v2PXqkUxBtv6PV//ily+eUiDRvqfTIyVNivu07k9ttFKlUS2bfPf90tt+h1t98usndvznt+/LGe+/jj4pfRi4m7Ub65+GKRxESRw4d1/8MP9c99yRLd37FD9597TvcvuUSkVi21vo4Bj0f/r1esEJk+XeS999Tavv12kcsuU4Oybl2/MDclRQRkIK8fcXmc1W6ffHjWGzLgslQ5+2yRTiftkd0xtSX1pDNl106PHDwosnq1ulqWLhVJu/dBkQoVjuT94EG1sOWnn+SI2jdqlFO4c7Njh0h8vEjXrlqI9HSRDh38Gc19bf/+evyBB7TCPPXUvC2jQMnMFDnpJLXes1e+gZKVpXlNTBTZv1+PPfus5u/eewuvXHJz1VX6kjwetd5BX+h33+n3L78UmTVLv3/yiV7z889qsd9/f8F5bNNGDQrf32QxMXE3ygd794ps2ZLz2ObNIpGRIoMH+4+tXKl/7m+8oftTpuj+9Om6P3NmzvMBcOiQyOzZIi++qC30Zs3UmMvPT12rlkjr1qp/N9yg7v6JE0VWPaVW6+z//iqTJ4vs2lXAw3zW5Jdf5j131lkinTvnf93YsSrEuX+j/HjtNf8zHntMv48cqf7i7KK1ebNWJk2aaJquXfXz6acLf0ZBfPaZ5PFvZ8fjEVm+PP9z77yj1370Uc70vv6Ws84SWbcusHx4PCL164v066f7K1bIERfNoEHaOtm/X8U6MVFdah6PPiMhQVs0BTFhgv9ex4CJu1G2mDv32Jrd+ZGVJdKxo0i9ejmbxy++qH/av//uP+bxqMLeeKPuP/OMpvGpqcejfu+LL87xiMxMkdTBL8q+E06VsV955P33RZ56SkU6JsYv3o0bi1xxhWrgv/8t8v77auilpHit6ILIz12UHxkZWjuccELOG6ana0buuafQn6tQfM+oW1crx+uu0+O9e+sxnwX85JN+a/att7RDGrQjsbhkZemzTzwx/9/iiSck307MfftE6tTRJlF+LpgPPhCJjdVWyZgxec97PDkF2WcEvP66/3zjxtrsatxYW3g+7rtPK7mRIwMzDDwekTPO0L/XAweOnvYomLgbZYfMTI3mqFTJ32wuCXx+TNB/fhH9BzrllPwt2UsuEWnZUr/36SPSvLl4PGqIzp4tsir5b7I9vrkMHKhJW7dW3fqai0VAGrDuyONOPVX1dNw4ka1bj6EM+XX0FsTkyfrw117zH5s/X499/vkxZCIbU6fq/Ro29Fd8vgiRyZO1MqlfX+TCC/3XzJunv39xXCrZGT1an/PhhzmPL1igrQcQads2p4g/9ZQenzOn4PuuWKG/M+iLTUnR47NmqcUdEeF/5ptv5jUMbr7Z//y33vIf9/32kZHqcgmk/N9/r9e88ELhaQvAxN0oO3z+uV+E83MrFIdDh9SSattWraq4OHU9/PyzZG/67tkj8s036mX45OSnRUDqxuySdTSQj91VEhnpz9pTPCwZREr9hHRp21Zb3A88ILK7joYZpjw/WlauPIrrpKgcOKDCkDtE82h07qzWrU/gXn1VM79+fQllSlTAFi/276elaUfiVVf5OyvHjy+55/nIytJaMzFRKwwR7UBo2VKP+co6dqye275dpGpVbVkURnq6tuji4rQforNGCEm9eiLJySrwo0ZpB3ydOjkrkE8/1bTO5XRveTzakgJtpgXK++8f3X1TCCbuRtnA41GrqXlzkZo19Z+nJPDGqG/9ZJr8/NmfkhURKSkX3iFLut0tGZEVZcAVO6R9ezkStx0RIXJt/WkiIB9f+L4IyITuL8tDD4kMG6YVwNZ/vydHoiR8HD4sR2qABx8sej6zsvTmq1blPefrlPv668Dv98EHes3Uqbrft69a2aXNbbdpy6tTJ5GkpGO30gti4UItT2SkWuV3a6SQfPutuoVOOEGkXTv9u3rgARXcpUsDv//GjSLXXKMdJC+9pJXH/v0iZ56pz6xSJW+I49atmoczzsh7v88+U8vhOGLibpQNvv1WjjRnb7pJLa1AogUOHBA5+WTxdOgg268YKN/+baS8cO1iGXBTptzYa7vsiawukyN7HLG6h3O7pBMlO6kuX3ClJCWJnHee/t9Nnep1ye/Zo2LQsaNeNHt2zmf+9FNesfWFSYLIuefmTL9mjcill+bfWZmerhZay5Z6bdOmea01X0RHampAP6WIaIslIUHdSiIqhH//e+DXFxffbwM60Ko02blTOzR9z7vzTv+5d9+VIz7xmBiNOy8J9uzxW/P5dXg++qhW0mUAE3ejbNCtm/po09L80QL5/JNkZqqOfv65yCuviLzWX+OWl0W1kV1UO/KPvsdVlVUVWkgmETL0qqUyYoSGtM8dt0UyK8WKgGSOm1Bwfk4+2W/KZ++EFdFmPqhF52PsWD3WoYNaddkHofj8vdmjckS0YmrdWs+dcoqKeGSkirCvub9okVZ0HTsW8QcVkSFDNP++2O7//Kfo9ygqHo9auzEx+jsdj+d99JGKd/Z+mowMrShBOzPzaxEVl127tOLK/XdRxjBxN4LPvHn6J/bii7p/6JBkxVaROacMkI4dRbp00dZwx446ajx76ODdkRqWd0fvDfLuOx7Z/P1KdUncdpv6ZYcMyfu8l15SH/zR4poHDNAHtG6d//n4eH2GD990AK+8op/Zw/G6dNFj1avnFATfNR995Bdzn5U+cqTWYrVqaex5oCF62Vm7VsXd1yrIPpioNJk6tUQG4Rwzb7+d16IvR5SouAMXAX8CKcDgAtL0BZYDvwGfFHZPE/cg4PEUb8ReccjKkszuF0hmleoyadReGTZMAyw+oZ9sJUHO65opF1ygno7u3TWE+N13tT90xw4Rz823qACWdH59wnD99fmf79IlZ/TKTTeJ1K6tozVBXS0iOlWBcyI9e+a0nnfv1gqiR488v4dccIFavvXra6fdihXFL0efPvrcSpXUBVSeyMhQ10mJ9WyHFiUm7kAk8BfQFKgILAZa5UrTHPgFqOHdr13YfU3cjzOHD2vEQREG6RSFtDT1Ejz7rPZHvRE/WATkdoYfscYTE0U+7+uNnJk16+g3TE5W1S9p/vhDcsQx5+a660QaNPDvn3mmhstlZmqkhc9a9I14XbBAO9qSklR0Hn9cj/sm/srOli0aL169+tFHiwbCNO0clrPPPrb7GCFHSYr7acCUbPtDgCG50vwbuCWQB/o2E/dSwuPJGaPrwxeTm1+PfxHZt0/HgwwdqobtmWfmHNBzf4JGo8zvcJt88rFH5sxRXfN4vBdHR6upXhAZGZrmn/885rzmyw8/FNyp+7SGSx7x8yYk6JwhIjoS0+cj79dPre+sLB1Y4+uIq1JF5yMpiLVrde6AY8Xj0c7ckSOP/V5GSFGS4n4l8Fa2/WuB13KlGesV+B+BucBFhd3XxL2UeF+FVebOzXn8v/+VI7G6xZj9cPt2HS5/9dXqH6/HRgGP1K2r9cW996rg7/z6Bx35061bwe6CXr3UOi4onG7ZMjnisz7e+GLyf/1VozZAh5yKaOhdxYraYVq9us4jIOIfpBURob/vsmXHP99GuSFQcS+plXijvK6ZrkB/4E3nXPXciZxzA51zC51zC1NTU0vo0cYRsrLg6af1+7RpOc/Nm6fL0ojAxIn5Xu7x6KIM8+bByJG6bsTZZ+siwbVq6ToXkybBM12/ZROJpD3yDJs3ww8/wMsvw2WdN1Hj5suhcWNdCLlChfzzecMNsGGDrrGZH7/+qp9t2xb9NzhWWrTQzxUr4M8/9btvEY9OnXSBzTfe0FUrfAt/REbCvffqD3jVVf7VlA0jmBSm/gTmlnkduDHb/nSg49Hua5Z7KeAbSRcdrZ132WnRwm8xX3bZkcMLF4q8f/Lz8t/Yf0lURFaOiJWqVdXlMmCABqJMniySdjBLB5H4wgl9vvOMDPX/Vq6snY9Hw+NR90bDhvnPuf3Pf2oZijqbX0mwf7+W7emndUpHUD+9iMa1g7pjoqJyxq0fOiTyr3+JbNhw/PNslCsoQbdMFLAKaIK/Q7V1rjQXAe97v9cC1gM1j3ZfE/cSJitLY7hbtdJQvthYvzj63AtDh0rGrXdIVqXK8s1Xh+Tii0WasUIy0BGY89sNlGH/8cjYseoW9nw9QYU2uwCPGuX3Lzdrpr2kqaka653fvCAFMX26pn/55bznunfXDtVg0aCBdqwOGaIi7nMveTwaOQPqfzeMIFBi4q73oiewAo2aedh77Emgl/e7A15GQyGXAv0Ku6eJ+zGyZInGXvviq32deh995BfgefMkLU1kwdM64VS/2tPlQr4RAenBRImPF1l66lXiqVzZPz3q3XdrZXDddX4TvlcvFbj0dPUtn3KK+pkXLVIfdJs2mm7gwKKV4fzzdUqC7Bawb/ZGXydmMOjWTUMir7hCWzzZuVgnETuWiZ8M41goUXEvjc3E/Ri55BJ9ffXrq7WcnKwj9zIyZN/KzSIgH7R5QeLiRB7lCcnCyVWX7JGh/5cm6TFxsvHSW+XAvKXaATh4sIrqfffpPePidETlo4/6J2u65hqRESP0e/ZJo4YN02Nt2xZ9WbOFC/XaRx/1H9uwQY9ln/nweHPrrRqrfvLJGpGSHd90twXNLW4YpYyJezizf7/GHl58sXiSOx6xsJ9r9qYkJakn4Q9ayJSKl8iAASJbk3tKVstW/uuvuEIrhd691bG+Y4ce93jUDdOli1rlPnzhgZGReefN9ni0cimur7lvX3Uh+WY19E1R8MMPxbtfSfDSS/7y5l5ZZ+fOghdGNozjQKDiXlLRMsbxZNo0SEtjXNN7abFzLjfwLh9WHsi0+tdxxhnw4INQ7ZKzOb/S94wckUXtNfOJ6NLZf32vXrBpE4wbB/ffD/Hxetw5eOEFmDMH2rf3p3/oIfjnP/X7c89pOh/OwTXXQGJi8cry7LNaNd1yi376ImXatCne/UoCX8RMVpY/UsZHjRrQp8/xz5NhFJVAaoDS2Mxyz8WyZfnHfaekHJl1cP9+DcOelnSz7KKaRJEunTrpGgd5LvWNoBwzRvKMyExN1UiX+HidDS9QfBZ+SeOLwR85UhesbtasdJ4TKH/+eaQ1VOhIWsM4zhCg5R4V7MrFAFavhlNOgWHD4K67/Mc9HrLO7srO6HrccvI8vp3qOJzmYWvE16Q078HMdytw+uk5DekjnH22fv773/rZqZP/XK1a8PjjcNJJULVq4Pn0WfglzR13wJgxcN99EBsLZ51VOs8JlCZNNHY9P8vdMEIEc8uUBX76Se3EUaOOHFq2DJ7rPYfITRtIWL2AWnO+ZuBAWDh8PgmebSQ/filnnFGAsAM0agRJSTB3LlSqpJVHdh59FP72t1IrUpGIiIB33tHvW7cGZ/BSdipUgKZNoVo1qF07uHkxjGJi4l4WmDcPAPnxR8a8tonzzlMtjv1mNBmR0aQlNuWt+o/yn1c8tN8wXq3KHj0Kv6/Peu/QAaLKeCMtKUmHuULOVkaw6NxZtwJrT8Mo25i4B5nUVNjxzXx2xDbEifDdP8awahUMfUa4o+6XVOh5ATH/fgq3ZIkO6f/6axXtGjUKv/k55+hn585HT1dWuOUWbbJ07x7snMDbb2uHs2GEKCbuQWDnTnjlFWjXDhrUPkxcyi98lNGPjdVb8fSpo/nrLxjSfQGRG9fDlVfC3/+u85Xcf7+KX69egT2oe3d1yVx4YekWqKRwTstZFqzlihUhJibYuTCMYmPifhxZvlznzEpM1L7D6Gh4/fYlRJPOXR90IvHuK6m+ZDYRqVth9Gj1/V56qbphnnoKNm7UG116aWAPbNRIJ7g6//xSK5NhGGUTE/fjwLp1cOON6kf/8kv9/uuv2td5Yyv1t0ee3lmtdBGNHBk9Wi1vn/ulTx/o2FHjv084IfCHV6xYCiUyDKOsU8Z72UIXjwdmzYL334dPP1VPw/13HWZIv9XUOO0kf8J586BePWjQQLcWLXSg0Lp18Mgj/nTOweTJkJl5/AtjGEbIYZZ7CXPwIDz/vIZKd+umRviNN8Lqr37l398lU+OMVrBggf+C+fM1OsQ53a68UoU9MhJ698558/h4C80zDCMgTNxLiIwMGDFCPSaDB6sB/sknsGVDJq83Gkq93p1gxw6oUkXVH2DXLl0UIns0y5VX6me3blCz5vEviGEYYYG5ZY6RjAz44AMYOhRWrYIzz1R3+RlneBPccbeqft++8L//aSz3s8+qqK9erWmyi3vbtjpi8/LLj3tZDMMIH8xyLyYi6k9v3lzDs+PjYcIEmD07m7BPn67Cfu+9Ovq0Zk24+24Nk3nhBXXJOAfJyf4bOwfDh8N55wWlXIZhhAdmuReDjAz4xz90Kc2OHdUg79EjV3j2/v2q+i1awDPP+I/XqQM33QRvvqmRLy1bFm1+F8MwjAAwy72I7N4NPXuqsA8erOGMPXvmM+5m8GBYu1bnTKlUKee5++/XSakWLQqd0aOGYYQUJu4BsnUrvPqqelBmzYJ331XXeUR+v+DMmepaGTQom48mG02b6qhTKBvzqBiGEXaYW6YQUlLUZf7NN2psd2qfyTvToo7MyZWHxYvhiiugWbOc7pjcPPqoDlm96KJSybdhGOUbs9yPwhdf6IJEP/4IDzwAv/+0i3mrEjh7zvP5X7B4sYYwxsbClClQuXLBN2/ZUoepJiWVSt4NwyjfmLjnw+HDumZG3746j9Wvv6oL5qQtM9Xp/tBDMGNGzosWL9YIl8qV9VzTpkHJu2EYBpi452HNGo1VHz5cJ/eaNUvn3wLgu+9UvFu0gP79YfNmPf7hh3pRpUrqby/K3C+GYRilgIl7NiZOVDfMypXw1Vfw0ku55t2aMUOXgBs9GvbuVYG/9lq47jqdv/enn0zYDcMoE5i4o9b6zTfDJZdA48YaoZhngfutW+G33+Dcc9VX8/rratZ/8gk88YQKf8OGwci+YRhGHsp1tMyWLarLb7+tIY333QdPP503LB1QdwtohymotS6iLprTTjteWTYMwwiIcivua9aoEb5xow4kfeghnXG3QL77TkeStmvnP3b99aWdTcMwjGJRLsXdJ+y7d6ubPPvULgUyY4auSVrWF5o2DMOgHPrcswv7tGkBCvuGDdrLeu65pZ09wzCMEqFcifvGjeoy9wl7hw4BXuiLaff52w3DMMo45cbHkJqq60Snpqr7PGBhB72gZk1dBNUwDCMEKBfivmePTuGyerUuQ9qxYxEuFlFx79q1gFnCDMMwyh5hL+4HDmj8+pIlMG6c9okWyrp18OSTGtu+a5fuP/hgqefVMAyjpAhrcT90CHr10oiYTz/VedcLJSsLrrpKRzK1bAnVqukkM1dcUer5NQzDKCnCVtwPH9ZlSGfM0OXw+vYN8MKXX9ZpID/4QKcWMAzDCEHC0om8erUK++TJMHJkETR62TJ45BG9+JprSjWPhmEYpUlA4u6cu8g596dzLsU5N/go6a5wzolzLpDo8RIlKwt+/hmuvloXrZ46Vdc2veWWAG+Qnq5TClSvrvPG5Fk3zzAMI3Qo1C3jnIsEhgPnAxuABc658SKyPFe6KsAgYF5pZDQ/Nm+Gu+/WBY1SUlSf4+J05aR77oHExHwuysrSCJjcI02few5++QXGjoWEhOOSf8MwjNIiEJ97JyBFRFYBOOc+A3oDy3Olewp4HnigRHN4FCZN0tl3e/aEiy+GE09Uj0qNGke56IorYPt2DW/0zeebkgJDh0K/ftC793HJu2EYRmkSiLgnAuuz7W8AOmdP4JxrDzQUkYnOuQLF3Tk3EBgI0OjIChjFJyUFKlSA8eMhMjLAi378UcV98GDtPBWBO++E6GjdNwzDCAOOOVrGORcBvAzcUFhaERkJjARITk6WY332ypW6ml3Awp6aqsKemAivvKJB74cPw7ffwrBhUK/esWbJMAyjTBCIuG8Esq9C0cB7zEcV4GRgptNOyLrAeOdcLxFZWFIZzY+UFGjWrAgXLPd6kkaM0EFKN9wAMTG6/NIdd5RGFg3DMIJCINEyC4DmzrkmzrmKQD9gvO+kiOwRkVoikiQiScBcoNSFXeQYxL1dOxg1Sm+ydatGxwRs/huGYZR9CrXcRSTTOXcXMAWIBN4Rkd+cc08CC0Vk/NHvUDps3apTCxRJ3H/7TRfcSEzUUMfJk2Ht2iJONmMYhlH2CcjnLiKTgEm5jj1WQNqux56twklJ0c8iW+6tWvlj2Lt00c0wDCPMCNkRqj5xb968CBf5xN0wDCPMCWlxj4qCxo0DvGDHDvXlmLgbhlEOCFlxX7kSkpKKsKTp77/rp4m7YRjlgJAV92JHypi4G4ZRDgg9cU9PR/5cUTxxj42Fhg0LT2sYhhHihJ64P/cctD2Va/YOp9kJRRjkuny5Lr5hS+UZhlEOCD2lGzCA3W27Mpy76P/xJdpJGggWKWMYRjki9MS9Xj0m3D6Ju/gvtZZ+B6ecAnPmHP2a3bth40YTd8Mwyg2hJ+5Ayl+OERF3kTV3oY44Pe88mDix4AssUsYwjHJGSIr7ypUa316hbWudwrdlS52HfeRIGDcOBg2Cs86Cd97RC3yRMq1bBy/ThmEYx5GQXCA7R6RMnTowc6au0nHrrXqsUiWoXx9uvhk2bFC3TKVKRRjxZBiGEdqErLj365ftQJUq6pb54gsNdezcWaNiBgyA//s/FfaTTrKZHw3DKDeEnLjv3Am7duUT416xoq6OnZ1339UFOJ57zlwyhmGUK0JO3Is0G6Rz8Oyz0LWrWu6GYRjlhJAV9yLNBnnhhaWSF8MwjLJKyEXLrFqlBnmTJsHOiWEYRtkl5MT94YdhyxZd+tQwDMPIn5ATd+egdu1g58IwDKNsE3LibhiGYRSOibthGEYY4kSKMG1uST7YuVRgbTEvrwVsL8HshBJW9vJJeS17eS03FFz2xiKSUNjFQRP3Y8E5t1BEkoOdj2BgZbeylyfKa7nh2MtubhnDMIwwxMTdMAwjDAlVcR8Z7AwEESt7+aS8lr28lhuOsewh6XM3DMMwjk6oWu6GYRjGUTBxNwzDCENCTtydcxc55/50zqU45wYHOz+lhXOuoXNuhnNuuXPuN+fcIO/xeOfcVOfcSu9njWDntbRwzkU6535xzk3w7jdxzs3zvvtRzrmKwc5jaeCcq+6cG+2c+8M597tz7rTy8t6dc/d6/96XOec+dc7FhOt7d86945zb5pxblu1Yvu/ZKcO8v8ES51z7wu4fUuLunIsEhgM9gFZAf+dcuK56nQncLyKtgC7And6yDgami0hzYLp3P1wZBPyebf954BURaQbsAm4OSq5Kn/8Ak0XkJOBU9DcI+/funEsE7gaSReRkIBLoR/i+9/eAi3IdK+g99wCae7eBwIjCbh5S4g50AlJEZJWIpAOfAb2DnKdSQUQ2i8jP3u/70H/wRLS873uTvQ/0CU4OSxfnXAPgYuAt774DugGjvUnCsuzOuWrA2cDbACKSLiK7KSfvHV1jopJzLgqoDGwmTN+7iMwGduY6XNB77g18IMpcoLpzrt7R7h9q4p4IrM+2v8F7LKxxziUB7YB5QB0R2ew9tQWoE6RslTavAv8CPN79msBuEcn07ofru28CpALvel1SbznnYikH711ENgIvAutQUd8DLKJ8vHcfBb3nImtfqIl7ucM5Fwd8CdwjInuznxONYw27WFbn3CXANhFZFOy8BIEooD0wQkTaAQfI5YIJ4/deA7VQmwD1gVjyui3KDcf6nkNN3DcCDbPtN/AeC0uccxVQYf9YRMZ4D2/1Nce8n9uClb9S5Aygl3NuDep664b6oat7m+sQvu9+A7BBROZ590ejYl8e3nt3YLWIpIpIBjAG/VsoD+/dR0HvucjaF2rivgBo7u09r4h2towPcp5KBa+P+W3gdxF5Odup8cD13u/XA+OOd95KGxEZIiINRCQJfcfficjVwAzgSm+ycC37FmC9c+5E76HzgOWUg/eOumO6OOcqe//+fWUP+/eejYLe83jgOm/UTBdgTzb3Tf6ISEhtQE9gBfAX8HCw81OK5TwTbZItAX71bj1R3/N0YCUwDYgPdl5L+XfoCkzwfm8KzAdSgC+A6GDnr5TK3BZY6H33Y4Ea5eW9A08AfwDLgA+B6HB978CnaN9CBtpiu7mg9ww4NFLwL2ApGlF01Pvb9AOGYRhhSKi5ZQzDMIwAMHE3DMMIQ0zcDcMwwhATd8MwjDDExN0wDCMMMXE3DMMIQ0zcDcMwwpD/B+tq58yhPZXXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ9tGRoYmd4y",
        "colab_type": "text"
      },
      "source": [
        "**F1 validation (From https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKjbrzEe2ISI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "a6e48c5e-6a44-41ef-d723-2b2d66e67f50"
      },
      "source": [
        "# Save model weights to drive\n",
        "!cp best_model* '/content/gdrive/My Drive/Kaggle'\n",
        "\n",
        "new_model = create_model(dense1=128, dense2=64, dropout_rate=0.4, l1_rate=1e-4, l2_rate=5e-4, init_std=0.05, lr=0.00001)\n",
        "new_model.load_weights('/content/gdrive/My Drive/Kaggle/best_model')\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_28 (Dense)             (None, 128)               117632    \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 172,801\n",
            "Trainable params: 172,161\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BAzqpDLIS0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Empty some RAM space\n",
        "indices_0_new = None\n",
        "data_backup = None\n",
        "dataset_transaction = None\n",
        "X_to_train = None\n",
        "Y_to_train = None"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIe0Q-5JmbVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f05c4c5-7907-4810-f168-5fa99ec52328"
      },
      "source": [
        "def precision_cal(y_pred, y_ref):\n",
        "  pre = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    if true_pos == len(indices_positive):\n",
        "      false_pos = 0\n",
        "    else:\n",
        "      false_pos = len(indices_positive) - true_pos\n",
        "\n",
        "    pre = true_pos/(true_pos + false_pos)\n",
        "  return pre\n",
        "\n",
        "def recall_cal(y_pred, y_ref):\n",
        "  recall = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    fals_neg = np.sum(y_ref[np.argwhere(y_pred == 0)])\n",
        "       \n",
        "    recall = true_pos/(true_pos + fals_neg)\n",
        "\n",
        "  return recall\n",
        "\n",
        "def F1_score(model, X_test, y_ref, test_size, threshold=0.5):\n",
        "  test_size = len(Y_test)\n",
        "  y_pred = (model.predict(X_test[:test_size], batch_size=128)>threshold).astype(int)\n",
        "  y_pred = np.squeeze(y_pred, axis=1)\n",
        " \n",
        "  precision = precision_cal(y_pred, np.array(Y_test[:test_size]))\n",
        "  recall = recall_cal(y_pred, np.array(Y_test[:test_size]))\n",
        "\n",
        "  return precision, recall, 2*precision*recall/(precision+recall)\n",
        "\n",
        "pre, re, f1 = F1_score(new_model, X_test, Y_test, test_size=len(Y_test), threshold=0.9)\n",
        "print(pre, re, f1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7780337941628265 0.49127061105722597 0.6022592152199763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhwhX0d2C_c6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9fa71af1-3e52-4156-f480-80829ee1deb6"
      },
      "source": [
        "new_model.evaluate(X_test, Y_test)\n",
        "prediction = new_model.predict(X_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3691/3691 [==============================] - 13s 4ms/step - loss: 0.3226 - f1_score: 0.5799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3226056396961212, 0.5799042582511902]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHZq7LSf4cWE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea920f33-a12d-4d88-9d63-449031a59980"
      },
      "source": [
        "try:\n",
        "  new_model.evaluate(X_train, Y_train, batch_size=BATCH_SIZE)\n",
        "except NameError:\n",
        "  BATCH_SIZE = 256\n",
        "  new_model.evaluate(X_train, Y_train, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1846/1846 [==============================] - 8s 4ms/step - loss: 0.0697 - f1_score: 0.7809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI3GaND0T5HF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "27f02cf3-feff-4db4-d45c-d9754eddfa9c"
      },
      "source": [
        "prediction = np.squeeze(prediction, axis=1)\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.hist(Y_test, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist((prediction>0.9).astype('int'), bins=[0,1,2])\n",
        "\n",
        "\n",
        "\n",
        "fraud_predict = np.unique((prediction>0.9).astype('int'), return_counts=True)\n",
        "fraud_real = np.unique(Y_test, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_predict[1][1]/np.sum(fraud_predict[1])*100,2)) + \"% \" + str(round(fraud_real[1][1]/np.sum(fraud_real[1])*100,2)) + \"%\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 3.08% 3.54%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw9zr52D5agr",
        "colab_type": "text"
      },
      "source": [
        "# ***Output the result into a file for a validation with Kaggle***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tvlyv5V5fsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "test_transaction = pd.read_csv('test_transaction.csv')\n",
        "test_transaction.head(5)\n",
        "\n",
        "# Remove transaction ID\n",
        "TransactionID = test_transaction.pop('TransactionID')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkoViKsx6cZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "float_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "int_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('int64'))].to_list()\n",
        "obj_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "skip_int_columns = []\n",
        "for column in skip_int_columns:\n",
        "  int_columns_test.remove(column)\n",
        "\n",
        "skip_obj_colums = ['']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrzQZ6nR6wOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_normalization(X, indices, cache_min, cache_max, cache_mean):\n",
        "  X_out = copy.copy(X)\n",
        "  #print(cache_mean, cache_max, cache_min)\n",
        "  X_out[indices] = (X_out[indices] - cache_mean)/(cache_max - cache_min)\n",
        "  X_out[np.where(np.isnan(X_out))[0]] = 0\n",
        "  return X_out.astype('float16')  \n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXM75lh_6lhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in float_columns:\n",
        "  # Set to float 16\n",
        "  test_transaction[column].astype('float16')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  test_transaction[column + \"_NaN_Code\"] = np.isnan(test_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = test_transaction[column]\n",
        "  indices = np.where(np.isnan(test_transaction[column]) == False)[0]\n",
        "  test_transaction[column] = apply_normalization(X.to_numpy(), indices, cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjog0oM7p4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in int_columns:\n",
        "  # Set to int 32\n",
        "  test_transaction[column].astype('int32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  if np.any(np.isnan(test_transaction[column].values)):\n",
        "    test_transaction[column + \"_NaN_Code\"] = np.isnan(test_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = test_transaction[column]\n",
        "  indices = np.where(np.isnan(test_transaction[column]) == False)[0]\n",
        "  test_transaction[column] = apply_normalization(X.to_numpy(), indices, cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egMTT8KB74NL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "726edfc7-9a21-4387-89c6-49b4b78a3241"
      },
      "source": [
        "encoded_column = 0\n",
        "for column in obj_columns_test:\n",
        "  ohc = OneHotEncoder(handle_unknown='ignore')\n",
        "  ohc.fit(cache[column])\n",
        "  test_transaction.loc[np.where(test_transaction[column].isnull())[0], column] = 'Null'\n",
        "  encoded = ohc.transform(test_transaction[column].values.reshape(-1,1)).toarray()    \n",
        "  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(cache[column])))])\n",
        "  test_transaction = pd.concat([test_transaction, pd_encoded], axis=1)\n",
        "  encoded_column += len(pd_encoded.columns)\n",
        "\n",
        "print(\"Encoded columns: \" + str(encoded_column))\n",
        "\n",
        "\n",
        "for column in obj_columns_test:\n",
        "  try:\n",
        "    test_transaction.pop(column)\n",
        "  except KeyError:\n",
        "    pass"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded columns: 164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC_OOqFi8HrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be86afaa-103e-4e61-cfe3-90b8a9fe044a"
      },
      "source": [
        "# Check if we have the same shape with the X_train\n",
        "print(test_transaction.shape, X_train.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506691, 918) (472432, 918)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY9vDvpDZdpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make the prediction and submit the output\n",
        "result = (new_model.predict(test_transaction)>0.9).astype('int8')\n",
        "result_pd = pd.DataFrame(result, columns=['isFraud'])\n",
        "data_to_file = pd.concat([TransactionID, result_pd], axis=1)\n",
        "data_to_file.head(5)\n",
        "data_to_file.to_csv(\"./submission.csv\", index=False)\n",
        "data_to_file.to_csv('/content/gdrive/My Drive/Kaggle/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9099XTi4s2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3dc8e117-8d8f-4013-d95b-bc0d2804ef2d"
      },
      "source": [
        "!kaggle competitions submit -c ieee-fraud-detection -f submission.csv -m \"A test submission\""
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 8.11M/8.11M [00:04<00:00, 2.04MB/s]\n",
            "Successfully submitted to IEEE-CIS Fraud Detection"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGezGr2PkCbt",
        "colab_type": "text"
      },
      "source": [
        "# ***Debug zone***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1J7VBfnUmND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47e00e92-3284-4de2-bb93-bc5ebabd26e6"
      },
      "source": [
        "indices = np.where(np.isnan(a) == False)[0]\n",
        "min_value, max_value, mean_value, normalized_data = normalization_data(a, indices)\n",
        "print(min_value, max_value, mean_value, np.mean(normalized_data), np.min(normalized_data), np.max(normalized_data))\n",
        "dataset_transaction['V331'] = normalized_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 160000.0 721.7418829164045 -2.2733716828843707e-16 -0.004510886768227528 0.9954891132317726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gICp4sPm6brq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3e2nvzrHir4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fe4ae314-d9e2-483a-9baa-e8b9302f14bf"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohc = OneHotEncoder()\n",
        "a = {'a': ['Null', 'A', 'B', 'C', 'D']}\n",
        "df = pd.DataFrame(a)\n",
        "df\n",
        "encoded = ohc.fit_transform(df['a'].values.reshape(-1,1)).toarray()    \n",
        "pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[\"a\"+\"_\"+str(i) for i in range(len(np.unique(df['a'].astype('str'))))])\n",
        "pd_encoded\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a_0</th>\n",
              "      <th>a_1</th>\n",
              "      <th>a_2</th>\n",
              "      <th>a_3</th>\n",
              "      <th>a_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a_0  a_1  a_2  a_3  a_4\n",
              "0    0    0    0    0    1\n",
              "1    1    0    0    0    0\n",
              "2    0    1    0    0    0\n",
              "3    0    0    1    0    0\n",
              "4    0    0    0    1    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vsaGKlzMUlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "69213f3a-42cb-4edc-cbc8-5bc6c0bb5a7e"
      },
      "source": [
        "b = {'a': ['Null', 'A', 'B', 'C', 'E']}\n",
        "df_b = pd.DataFrame(b)\n",
        "ohc_b = OneHotEncoder(handle_unknown='ignore')\n",
        "ohc_b.fit(df['a'].values.reshape(-1,1))\n",
        "encoded_b = ohc_b.transform(df_b['a'].values.reshape(-1,1)).toarray()    \n",
        "pd_encoded_b = pd.DataFrame(encoded_b.astype('int8'), columns=[\"a\"+\"_\"+str(i) for i in range(len(np.unique(df['a'].astype('str'))))])\n",
        "pd_encoded_b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a_0</th>\n",
              "      <th>a_1</th>\n",
              "      <th>a_2</th>\n",
              "      <th>a_3</th>\n",
              "      <th>a_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a_0  a_1  a_2  a_3  a_4\n",
              "0    0    0    0    0    1\n",
              "1    1    0    0    0    0\n",
              "2    0    1    0    0    0\n",
              "3    0    0    1    0    0\n",
              "4    0    0    0    0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvykuaRPMpZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "20c01d2a-8a3b-41b6-a7ae-b6d7a36f327f"
      },
      "source": [
        "for column in obj_columns:\n",
        "  dataset_transaction.loc[np.where(dataset_transaction[column].isnull())[0], column] = 'Null'\n",
        "  print(column, len(np.unique(dataset_transaction[column].astype(\"str\"))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ProductCD 5\n",
            "card4 5\n",
            "card6 5\n",
            "P_emaildomain 60\n",
            "R_emaildomain 61\n",
            "M1 3\n",
            "M2 3\n",
            "M3 3\n",
            "M4 4\n",
            "M5 3\n",
            "M6 3\n",
            "M7 3\n",
            "M8 3\n",
            "M9 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj_RMIz3NTTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2e5b2844-8bdd-45ee-f5ec-83cd54c9cba7"
      },
      "source": [
        "for column in obj_columns_test:\n",
        "  test_transaction.loc[np.where(test_transaction[column].isnull())[0], column] = 'Null'\n",
        "  print(column, len(np.unique(test_transaction[column].astype(\"str\"))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ProductCD 5\n",
            "card4 5\n",
            "card6 4\n",
            "P_emaildomain 61\n",
            "R_emaildomain 61\n",
            "M1 3\n",
            "M2 3\n",
            "M3 3\n",
            "M4 4\n",
            "M5 3\n",
            "M6 3\n",
            "M7 3\n",
            "M8 3\n",
            "M9 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvnTtZ-WUmWS",
        "colab_type": "text"
      },
      "source": [
        "**Train val dataset**"
      ]
    }
  ]
}