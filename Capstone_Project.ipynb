{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquangnguyen1992/Advanced_Data_Science_Capstone/blob/master/Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE4qbNACq5vY",
        "colab_type": "text"
      },
      "source": [
        "# ***Get the dataset from Kaggle***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28TmZY-0q4mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "65bce31f-ca12-4870-c732-9ff24271f7c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0mVq898tzNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-VLOPU9zZii",
        "colab_type": "text"
      },
      "source": [
        "# ***Analyzing the dataset and doing the cleansing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYzy-sxDzdFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "67dc1b98-e157-4863-e3d5-85d102f5a5f9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBOSTwRzj4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "3ae4ac89-8b3e-425f-9848-fc9f76755813"
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "dataset_transaction = pd.read_csv('train_transaction.csv')\n",
        "dataset_transaction.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoApMJ8vz3IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_identity = pd.read_csv('train_identity.csv')\n",
        "dataset_identity.head(5)\n",
        "saved_columns= np.array(dataset_identity.columns)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmudmokF4Ath",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "75b80361-28ab-4349-8dc8-49d25316f5d6"
      },
      "source": [
        "dataset_identity.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06',\n",
              "       'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14',\n",
              "       'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22',\n",
              "       'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30',\n",
              "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
              "       'DeviceType', 'DeviceInfo'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NesEY-44N6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fe487e80-ac1b-4b38-89f1-501167351676"
      },
      "source": [
        "dataset_transaction.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
              "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
              "       ...\n",
              "       'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338',\n",
              "       'V339'],\n",
              "      dtype='object', length=394)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsvf-Mk5_i_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b706392-01a9-48d5-e6e5-7a2bd7b6e2c8"
      },
      "source": [
        "#Data transaction\n",
        "float_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "to_remove_NaN_dataset_transaction = []\n",
        "removed = 0\n",
        "for column in float_columns:\n",
        "  count_NaN = np.sum(np.isnan(dataset_transaction[column].values))\n",
        "  if count_NaN/len(dataset_transaction[column].values) > 0.9:\n",
        "    to_remove_NaN_dataset_transaction.append(column)\n",
        "    dataset_transaction.pop(column)\n",
        "    removed += 1\n",
        "print(\"Removed: \" + str(removed))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8KDqiGwlzq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "0188a68b-55de-49ef-9a56-82fd42af0b2a"
      },
      "source": [
        "float_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "to_remove_NaN_dataset_transaction = []\n",
        "removed = 0\n",
        "for column in float_columns:\n",
        "  count_NaN = np.sum(np.isnan(dataset_transaction[column].values))\n",
        "  if count_NaN/len(dataset_transaction[column].values) > 0.9:\n",
        "    to_remove_NaN_dataset_transaction.append(column)\n",
        "\n",
        "for column in to_remove_NaN_dataset_transaction:\n",
        "  print(column)\n",
        "  data_test = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(data_test) == False)[0]\n",
        "  data_b = dataset_transaction.iloc[indices]\n",
        "  indices_fraud = np.where(data_b['isFraud'] == 1)[0]\n",
        "  print(\"Not NaN:\" + str(len(indices)) + \"; \" + str(len(indices_fraud)) + \"; \" + str(len(indices_fraud)/len(indices)*100))\n",
        "\n",
        "  indices = np.where(np.isnan(data_test) == True)[0]\n",
        "  data_b = dataset_transaction.iloc[indices]\n",
        "  indices_fraud = np.where(data_b['isFraud'] == 1)[0]\n",
        "  print(\"% NaN: \" + str(len(indices)/len(data_test)*100))\n",
        "  print(\"NaN:\" + str(len(indices)) + \"; \" + str(len(indices_fraud)) + \"; \" + str(len(indices_fraud)/len(indices)*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dist2\n",
            "Not NaN:37627; 3731; 9.915751986605363\n",
            "% NaN: 93.62837403054831\n",
            "NaN:552913; 16932; 3.0623262610935176\n",
            "D7\n",
            "Not NaN:38917; 5790; 14.877816892360665\n",
            "% NaN: 93.40992989467267\n",
            "NaN:551623; 14873; 2.6962255018373056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUG2UY-KB_Uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset Identity\n",
        "float_columns = dataset_identity.columns[np.where(dataset_identity.dtypes == np.dtype('float64'))].to_list()\n",
        "to_remove_NaN_dataset_identity = []\n",
        "removed = 0\n",
        "for column in float_columns:\n",
        "  count_NaN = np.sum(np.isnan(dataset_identity[column].values))\n",
        "  if count_NaN/len(dataset_identity[column]) > 0.75:\n",
        "    to_remove_NaN_dataset_identity.append(column)\n",
        "    dataset_identity.pop(column)\n",
        "    removed += 1\n",
        "print(\"Removed: \" + str(removed))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4MWdmZ8wBEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_remove_id = ['DeviceInfo', 'id_30', 'id_31', 'id_33']\n",
        "for column in to_remove_id:\n",
        "  dataset_identity.pop(column)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS60VEEMwgHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89b72faf-59cd-4ff1-a2c3-64380448660a"
      },
      "source": [
        "merged_data = pd.merge(left=dataset_transaction, right=dataset_identity, how='left', left_on='TransactionID', right_on='TransactionID')\n",
        "\n",
        "dataset_transaction = None\n",
        "dataset_identity = None\n",
        "merged_data.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 430)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa6FhtemGMc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40ef2ee7-028b-4fc4-c941-81baa7c4b18d"
      },
      "source": [
        "################################# Test ##########################################\n",
        "test_transaction = pd.read_csv('test_transaction.csv')\n",
        "test_identity = pd.read_csv('test_identity.csv', names=saved_columns, header=0)\n",
        "\n",
        "for column in to_remove_id:\n",
        "  test_identity.pop(column)\n",
        "\n",
        "test_merged_data = pd.merge(left=test_transaction, right=test_identity, how='left', left_on='TransactionID', right_on='TransactionID')\n",
        "\n",
        "TransactionID = test_merged_data.pop('TransactionID')\n",
        "test_transaction = None\n",
        "test_identity = None\n",
        "test_merged_data.shape\n",
        "\n",
        "################################################################################"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506691, 428)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIAS8CbdwwET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "cd9a5bad-b7be-4996-994e-c5d69e1c1004"
      },
      "source": [
        "merged_data.tail(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>590535</th>\n",
              "      <td>3577535</td>\n",
              "      <td>0</td>\n",
              "      <td>15811047</td>\n",
              "      <td>49.00</td>\n",
              "      <td>W</td>\n",
              "      <td>6550</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>272.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590536</th>\n",
              "      <td>3577536</td>\n",
              "      <td>0</td>\n",
              "      <td>15811049</td>\n",
              "      <td>39.50</td>\n",
              "      <td>W</td>\n",
              "      <td>10444</td>\n",
              "      <td>225.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>204.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590537</th>\n",
              "      <td>3577537</td>\n",
              "      <td>0</td>\n",
              "      <td>15811079</td>\n",
              "      <td>30.95</td>\n",
              "      <td>W</td>\n",
              "      <td>12037</td>\n",
              "      <td>595.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>231.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590538</th>\n",
              "      <td>3577538</td>\n",
              "      <td>0</td>\n",
              "      <td>15811088</td>\n",
              "      <td>117.00</td>\n",
              "      <td>W</td>\n",
              "      <td>7826</td>\n",
              "      <td>481.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>387.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aol.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590539</th>\n",
              "      <td>3577539</td>\n",
              "      <td>0</td>\n",
              "      <td>15811131</td>\n",
              "      <td>279.95</td>\n",
              "      <td>W</td>\n",
              "      <td>15066</td>\n",
              "      <td>170.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>299.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        TransactionID  isFraud  TransactionDT  ...  id_37 id_38  DeviceType\n",
              "590535        3577535        0       15811047  ...    NaN   NaN         NaN\n",
              "590536        3577536        0       15811049  ...    NaN   NaN         NaN\n",
              "590537        3577537        0       15811079  ...    NaN   NaN         NaN\n",
              "590538        3577538        0       15811088  ...    NaN   NaN         NaN\n",
              "590539        3577539        0       15811131  ...    NaN   NaN         NaN\n",
              "\n",
              "[5 rows x 430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDu1rWAkUafP",
        "colab_type": "text"
      },
      "source": [
        "**Check NaN, Null, and OneHotEncoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtNPHQ2NCbGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdb056d6-5af7-46bd-cb21-c27230308080"
      },
      "source": [
        "dataset_transaction = copy.copy(merged_data)\n",
        "merged_data = None\n",
        "dataset_identity = None\n",
        "\n",
        "float_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "int_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('int64'))].to_list()\n",
        "obj_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "skip_int_columns = ['TransactionID', 'isFraud']\n",
        "for column in skip_int_columns:\n",
        "  int_columns.remove(column)\n",
        "\n",
        "skip_obj_colums = ['']\n",
        "cache = dict()\n",
        "print(len(float_columns), len(int_columns), len(obj_columns))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "399 2 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4AzwRzqEfth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization_data(X, indices, max_test, min_test):\n",
        "  X_out = copy.copy(X)\n",
        "  X_temp = X[indices]\n",
        "  max_X = np.max([np.max(X_temp), max_test])\n",
        "  min_X = np.min([np.min(X_temp), min_test])\n",
        "  mean_X = np.mean(X_temp)\n",
        "  median_X = np.median(X_temp)\n",
        "  #X_out.iloc[indices] = (X_temp - min_X)/(max_X - min_X)\n",
        "  X_out.iloc[np.where(np.isnan(X_out))[0]] = median_X\n",
        "  X_out = (X_out - min_X)/(max_X - min_X) # So from 0 to 1\n",
        "\n",
        "  return min_X, max_X, mean_X, median_X, X_out.astype('float16')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-sce8WEFqWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "96601e49-ca4d-4cdb-af3e-abd14c516f8a"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70787.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-480.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>32.0</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  id_37 id_38  DeviceType\n",
              "0        2987000        0          86400  ...    NaN   NaN         NaN\n",
              "1        2987001        0          86401  ...    NaN   NaN         NaN\n",
              "2        2987002        0          86469  ...    NaN   NaN         NaN\n",
              "3        2987003        0          86499  ...    NaN   NaN         NaN\n",
              "4        2987004        0          86506  ...      T     T      mobile\n",
              "\n",
              "[5 rows x 430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIIYOrO74QbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1: Detect the columns with NaN and code it with an extra features\n",
        "# Task 2: Apply normalizationn\n",
        "# Task 3: Remove the irrelevant columns\n",
        "for column in float_columns:\n",
        "  # Set to float 16\n",
        "  dataset_transaction[column].astype('float32')\n",
        "\n",
        "  # Code the NaN column for every features\n",
        "  dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(X) == False)[0]\n",
        "  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], cache[column+'_median'], dataset_transaction[column] = normalization_data(X, indices, np.max(test_merged_data[column]), np.min(test_merged_data[column]))\n",
        "  dataset_transaction[column].astype('float16')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZY_88yeGGSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "49dbf47e-e3fa-4499-c660-67b0a91cd077"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>discover</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>visa</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.070801</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.166626</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.773926</td>\n",
              "      <td>0.078430</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.666504</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  id_37 id_38  DeviceType\n",
              "0        2987000        0          86400  ...    NaN   NaN         NaN\n",
              "1        2987001        0          86401  ...    NaN   NaN         NaN\n",
              "2        2987002        0          86469  ...    NaN   NaN         NaN\n",
              "3        2987003        0          86499  ...    NaN   NaN         NaN\n",
              "4        2987004        0          86506  ...      T     T      mobile\n",
              "\n",
              "[5 rows x 430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43g5UKZPg32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in int_columns:\n",
        "  # Set to int 32\n",
        "  dataset_transaction[column].astype('float32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(dataset_transaction[column]) == False)[0]\n",
        "  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], cache[column+'_median'], dataset_transaction[column] = normalization_data(X, indices, np.max(test_merged_data[column]), np.min(test_merged_data[column]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW7scgn0-mD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "f121e636-0558-4a3c-8334-493f6e250e48"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>0.070496</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.100891</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.210571</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.393066</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.984863</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.076965</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 610 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  DeviceType_1  DeviceType_2\n",
              "0        2987000        0  ...             0             0\n",
              "1        2987001        0  ...             0             0\n",
              "2        2987002        0  ...             0             0\n",
              "3        2987003        0  ...             0             0\n",
              "4        2987004        0  ...             0             1\n",
              "\n",
              "[5 rows x 610 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDGnSj678SaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1f636d1-dddf-4fc0-952f-1b28b858a981"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoded_column = 0\n",
        "for column in obj_columns:\n",
        "  ohc = OneHotEncoder()\n",
        "  dataset_transaction.loc[np.where(dataset_transaction[column].isnull())[0], column] = 'Null'\n",
        "  encoded = ohc.fit_transform(dataset_transaction[column].values.reshape(-1,1)).toarray()    \n",
        "  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(dataset_transaction[column].astype('str'))))])\n",
        "  dataset_transaction = pd.concat([dataset_transaction, pd_encoded], axis=1)\n",
        "  cache[column] = dataset_transaction[column].values.reshape(-1,1)\n",
        "  encoded_column += len(pd_encoded.columns)\n",
        "\n",
        "print(\"Encoded columns: \" + str(encoded_column))\n",
        "for column in obj_columns:\n",
        "  try:\n",
        "    dataset_transaction.pop(column)\n",
        "  except KeyError:\n",
        "    pass\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded columns: 207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuvQmMmLRnM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "f1a47e23-7487-4fb7-a85d-f02abcbc973a"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>0.070496</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.100891</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.210571</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.393066</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.984863</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.076965</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 610 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  DeviceType_1  DeviceType_2\n",
              "0        2987000        0  ...             0             0\n",
              "1        2987001        0  ...             0             0\n",
              "2        2987002        0  ...             0             0\n",
              "3        2987003        0  ...             0             0\n",
              "4        2987004        0  ...             0             1\n",
              "\n",
              "[5 rows x 610 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e626putLzCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b6cbefb-ac4d-4863-a139-fbbd2274e642"
      },
      "source": [
        "print(np.any(np.isnan(dataset_transaction)), np.any(dataset_transaction.isnull()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2H9ryz7bHU",
        "colab_type": "text"
      },
      "source": [
        "**Apply Seaborn to preliminary analyze the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoc4TuIx1zoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8ac64e9a-144f-4b81-8eb1-998c86136164"
      },
      "source": [
        "out = ['isFraud']\n",
        "for column in dataset_transaction.columns:\n",
        "  if column.find('R_emaildomain') != -1:\n",
        "    out.append(column)\n",
        "  if column.find('P_emaildomain') != -1:\n",
        "    out.append(column)\n",
        "print(out)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['isFraud', 'P_emaildomain_0', 'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'P_emaildomain_4', 'P_emaildomain_5', 'P_emaildomain_6', 'P_emaildomain_7', 'P_emaildomain_8', 'P_emaildomain_9', 'P_emaildomain_10', 'P_emaildomain_11', 'P_emaildomain_12', 'P_emaildomain_13', 'P_emaildomain_14', 'P_emaildomain_15', 'P_emaildomain_16', 'P_emaildomain_17', 'P_emaildomain_18', 'P_emaildomain_19', 'P_emaildomain_20', 'P_emaildomain_21', 'P_emaildomain_22', 'P_emaildomain_23', 'P_emaildomain_24', 'P_emaildomain_25', 'P_emaildomain_26', 'P_emaildomain_27', 'P_emaildomain_28', 'P_emaildomain_29', 'P_emaildomain_30', 'P_emaildomain_31', 'P_emaildomain_32', 'P_emaildomain_33', 'P_emaildomain_34', 'P_emaildomain_35', 'P_emaildomain_36', 'P_emaildomain_37', 'P_emaildomain_38', 'P_emaildomain_39', 'P_emaildomain_40', 'P_emaildomain_41', 'P_emaildomain_42', 'P_emaildomain_43', 'P_emaildomain_44', 'P_emaildomain_45', 'P_emaildomain_46', 'P_emaildomain_47', 'P_emaildomain_48', 'P_emaildomain_49', 'P_emaildomain_50', 'P_emaildomain_51', 'P_emaildomain_52', 'P_emaildomain_53', 'P_emaildomain_54', 'P_emaildomain_55', 'P_emaildomain_56', 'P_emaildomain_57', 'P_emaildomain_58', 'P_emaildomain_59', 'R_emaildomain_0', 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3', 'R_emaildomain_4', 'R_emaildomain_5', 'R_emaildomain_6', 'R_emaildomain_7', 'R_emaildomain_8', 'R_emaildomain_9', 'R_emaildomain_10', 'R_emaildomain_11', 'R_emaildomain_12', 'R_emaildomain_13', 'R_emaildomain_14', 'R_emaildomain_15', 'R_emaildomain_16', 'R_emaildomain_17', 'R_emaildomain_18', 'R_emaildomain_19', 'R_emaildomain_20', 'R_emaildomain_21', 'R_emaildomain_22', 'R_emaildomain_23', 'R_emaildomain_24', 'R_emaildomain_25', 'R_emaildomain_26', 'R_emaildomain_27', 'R_emaildomain_28', 'R_emaildomain_29', 'R_emaildomain_30', 'R_emaildomain_31', 'R_emaildomain_32', 'R_emaildomain_33', 'R_emaildomain_34', 'R_emaildomain_35', 'R_emaildomain_36', 'R_emaildomain_37', 'R_emaildomain_38', 'R_emaildomain_39', 'R_emaildomain_40', 'R_emaildomain_41', 'R_emaildomain_42', 'R_emaildomain_43', 'R_emaildomain_44', 'R_emaildomain_45', 'R_emaildomain_46', 'R_emaildomain_47', 'R_emaildomain_48', 'R_emaildomain_49', 'R_emaildomain_50', 'R_emaildomain_51', 'R_emaildomain_52', 'R_emaildomain_53', 'R_emaildomain_54', 'R_emaildomain_55', 'R_emaildomain_56', 'R_emaildomain_57', 'R_emaildomain_58', 'R_emaildomain_59', 'R_emaildomain_60']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9BKg6gZ8qS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#columns_to_analyze = ['isFraud', 'DeviceType_0', 'DeviceType_1', 'DeviceType_2', 'id_15_0', 'id_15_1', 'id_15_2', 'id_15_3']#, 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3', 'P_emaildomain_4', 'addr1', 'addr2', 'dist1', 'dist2', 'card1', 'card2', 'card3']\n",
        "columns_to_analyze = out\n",
        "\n",
        "analyzing_data = dataset_transaction[columns_to_analyze]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtWkHi4N7kKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = analyzing_data.corr()\n",
        "to_display = False\n",
        "\n",
        "if to_display:\n",
        "  mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
        "  # Set up the matplotlib figure\n",
        "  f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "  # Generate a custom diverging colormap\n",
        "  cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "  # Draw the heatmap with the mask and correct aspect ratio\n",
        "  sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "              square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD5CKASq2rzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "adbd3dc7-0c3e-47ea-bd2c-19656e24e120"
      },
      "source": [
        "# Remove the weak correlation features\n",
        "col = corr.columns\n",
        "is_fraud = np.where(col=='isFraud')[0][0]\n",
        "col = col.to_list()\n",
        "col.pop(is_fraud)\n",
        "to_remove = []\n",
        "for each_col in col:\n",
        "  if abs(corr['isFraud'][each_col]) < 0.005: # Weak correlation\n",
        "    to_remove.append(each_col)\n",
        "    a = dataset_transaction.pop(each_col)\n",
        "print(len(to_remove))\n",
        "analyzing_data = None\n",
        "\n",
        "\n",
        "dataset_transaction.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>0.070496</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.100891</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.210571</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.393066</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.984863</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.076965</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.013748</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 522 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  DeviceType_1  DeviceType_2\n",
              "0        2987000        0  ...             0             0\n",
              "1        2987001        0  ...             0             0\n",
              "2        2987002        0  ...             0             0\n",
              "3        2987003        0  ...             0             0\n",
              "4        2987004        0  ...             0             1\n",
              "\n",
              "[5 rows x 522 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rf6--7Dn6PZ",
        "colab_type": "text"
      },
      "source": [
        "# ***Creat the train/val dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV-8fmFWoOnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "279ba40c-127e-43ac-b9b5-ae29fce6e24e"
      },
      "source": [
        "# Create a copy\n",
        "dataset = copy.copy(dataset_transaction)\n",
        "\n",
        "# Remove the irrelevant columns\n",
        "dataset.pop('TransactionID')\n",
        "dataset.head(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>0.070496</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.100891</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.210571</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.393066</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.339111</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.984863</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.076965</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.165283</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.013748</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.114990</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 1010 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   isFraud  TransactionDT  ...  DeviceType_1  DeviceType_2\n",
              "0        0       0.000000  ...             0             0\n",
              "1        0       0.000000  ...             0             0\n",
              "2        0       0.000002  ...             0             0\n",
              "3        0       0.000003  ...             0             0\n",
              "4        0       0.000003  ...             0             1\n",
              "\n",
              "[5 rows x 1010 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7KODCOzZbOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = dataset['isFraud']\n",
        "dataset.pop('isFraud')\n",
        "X = dataset\n",
        "X_train = X\n",
        "Y_train = Y"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyHSb5S3bDdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9a893305-068c-497d-c3da-1cfcd7b6b917"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.hist(Y_train, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist(Y_train, bins=[0,1,2])\n",
        "\n",
        "fraud_count = np.unique(Y_train, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 3.5%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FZY_7rXajHM",
        "colab_type": "text"
      },
      "source": [
        "**Downsampling and upsampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYnuyBs27aRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c959f172-17f4-42a8-f8a4-e810923846a6"
      },
      "source": [
        "downsampling_factor = 1\n",
        "indices_1 = np.argwhere(np.array(Y_train)==1)\n",
        "indices_0_new = np.argwhere(np.array(Y_train)==0)\n",
        "indices = np.arange(0,len(indices_0_new),downsampling_factor)\n",
        "#indices_test = [i for i in range(len(indices_0_new)) if i not in indices]\n",
        "indices_0_train = indices_0_new[indices]\n",
        "#indices_0_test = indices_0_new[indices_test]\n",
        "indices_0_test = np.delete(indices_0_new, indices)\n",
        "print(indices_0_train.shape, indices_0_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569877, 1) (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_kQE1U9amFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''downsampling_factor = 2\n",
        "indices_1 = np.argwhere(np.array(Y_train)==1)\n",
        "indices_0_new = np.argwhere(np.array(Y_train)==0)\n",
        "indices = np.arange(0,len(indices_0_new),downsampling_factor)\n",
        "indices_0_new = indices_0_new[indices]\n",
        "\n",
        "print(indices_0_new.shape)'''\n",
        "\n",
        "upsampling_factor = 1\n",
        "indices_1_new = indices_1\n",
        "for i in range(upsampling_factor):\n",
        "  indices_1_new = np.concatenate((indices_1_new, indices_1), axis=0)\n",
        "\n",
        "indices_0_new = np.concatenate((indices_1_new, indices_0_train), axis=0)\n",
        "\n",
        "indices_0_new = tf.random.shuffle(indices_0_new)\n",
        "\n",
        "X_new = np.array(X_train)[indices_0_new]\n",
        "Y_new = np.array(Y_train)[indices_0_new]\n",
        "\n",
        "X_test_2 = np.array(X_train)[indices_0_test]\n",
        "Y_test_2 = np.array(Y_train)[indices_0_test]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y_new, test_size=0.01)\n",
        "\n",
        "X_to_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[2]))\n",
        "Y_to_train = np.squeeze(Y_train, axis=1)\n",
        "\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[2]))\n",
        "Y_test = np.squeeze(Y_test, axis=1)\n",
        "\n",
        "#X_test_2 = np.squeeze(X_test_2, axis=1)\n",
        "#Y_test_2 = np.squeeze(Y_test_2, axis=1)\n",
        "\n",
        "print(X_to_train.shape, X_test.shape, X_test_2.shape, Y_test_2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_bjB3XUXfu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "69902365-ed4b-4856-893f-104276778823"
      },
      "source": [
        "# New train_test split, the points is to have all of the 1 labels in training\n",
        "# Split some of the 0 labels in train/test\n",
        "\n",
        "train_test_split_factor = 0.01\n",
        "test_0_indices = np.arange(0,len(indices_0_train), int(1/train_test_split_factor))\n",
        "test_indices = indices_0_new[test_0_indices]\n",
        "test_indices = np.squeeze(test_indices, axis=1)\n",
        "train_indices = np.delete(indices_0_new, test_0_indices)\n",
        "\n",
        "print(test_indices.shape, train_indices.shape)\n",
        "\n",
        "test_1_indices = np.arange(0, len(indices_1), int(1*10.0/train_test_split_factor))\n",
        "test_indices = np.concatenate((test_indices, np.squeeze(indices_1[test_1_indices], axis=1)), axis=0)\n",
        "train_indices = np.concatenate((train_indices, np.squeeze(indices_1, axis=1)), axis=0)\n",
        "\n",
        "train_indices = tf.random.shuffle(train_indices)\n",
        "test_indices = tf.random.shuffle(test_indices)\n",
        "\n",
        "# Create the X_train, X_test, Y_train, Y_test\n",
        "X_to_train = X_train.iloc[train_indices]\n",
        "Y_to_train = Y_train.iloc[train_indices]\n",
        "\n",
        "X_test = X_train.iloc[test_indices]\n",
        "Y_test = Y_train.iloc[test_indices]\n",
        "\n",
        "print(X_to_train.shape, Y_to_train.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5699,) (564178,)\n",
            "(584841, 1009) (584841,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKovy1ORazIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "162bdd29-51bf-431a-ea14-62d887afec82"
      },
      "source": [
        "print(X_to_train.shape, Y_to_train.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(584841, 1009) (584841,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC9Foj6lbEvL",
        "colab_type": "text"
      },
      "source": [
        "**Check the imbalane of the train/test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvCbtngmd6iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "94ab8495-4621-4341-9d34-be10b4c89aed"
      },
      "source": [
        "X_new = None\n",
        "Y_new = None\n",
        "test_merged_data = None\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.hist(Y_to_train, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist(Y_test, bins=[0,1,2])\n",
        "\n",
        "X_train = None\n",
        "Y_train = None\n",
        "X = None\n",
        "Y = None\n",
        "\n",
        "fraud_count = np.unique(Y_to_train, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 3.53%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrhLRRCb6fLl",
        "colab_type": "text"
      },
      "source": [
        "# ***XGBoost***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb8DlzmI6hoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "#import joblib\n",
        "\t\n",
        "# fit model no training data\n",
        "param_dist = {'objective':'binary:logistic', 'n_estimators':5000, 'max_depth': 20,\n",
        "              'learning_rate':0.1, 'alpha': 0.0005, 'gamma': 0,\n",
        "              'eval_metric': 'auc', 'max_delta_step': 0,\n",
        "              'scale_pos_weight': 33}\n",
        "model = XGBClassifier(**param_dist)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G06XxGJ4832M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "d51ccf68-3041-4855-a9cb-bc5ef580c6e9"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(alpha=0.0005, base_score=0.5, booster='gbtree',\n",
            "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
            "              eval_metric='auc', gamma=0, learning_rate=0.1, max_delta_step=0,\n",
            "              max_depth=20, min_child_weight=1, missing=None, n_estimators=5000,\n",
            "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
            "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=33,\n",
            "              seed=None, silent=None, subsample=1, verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1qYg2ccLs4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "57509054-4c99-43c1-b794-f2f8190c1e5c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "batch_size = 32768 #115200\n",
        "subset = np.floor(len(X_to_train)/batch_size).astype('int')\n",
        "print(\"Batch_size and number of subset: \", batch_size, subset)\n",
        "pre_list = []\n",
        "re_list = []\n",
        "f1_list = []\n",
        "try:\n",
        "  !mkdir models\n",
        "except:\n",
        "  pass\n",
        "\n",
        "XGB_MODEL_FILE = \"./models/saved_model.pkl.z\"\n",
        "#dvalid = xgboost.DMatrix(X_test.values, label=Y_test.values, missing=np.nan)\n",
        "\n",
        "early_stop = 30\n",
        "verbose_eval = False\n",
        "rounds = 100\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "\n",
        "for i in range(subset+1):\n",
        "  if i < subset + 1:\n",
        "    X = X_to_train.iloc[batch_size*i:batch_size*(i+1)].values\n",
        "    Y = Y_to_train.iloc[batch_size*i:batch_size*(i+1)].values\n",
        "  else:\n",
        "    X = X_to_train.iloc[batch_size*i:len(X_to_train)].values\n",
        "    Y = Y_to_train.iloc[batch_size*i:len(X_to_train)].values    \n",
        "  kf.get_n_splits(X)\n",
        "  KFold(n_splits=10, random_state=None, shuffle=False)\n",
        "  count = 0\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    print(\"Subset and count: \", i, count)\n",
        "    X_train, X_to_test = X[train_index], X[test_index]\n",
        "    y_train, y_to_test = y[train_index], y[test_index]\n",
        "\n",
        "    dtrain = xgboost.DMatrix(X_train, label = y_train)\n",
        "    dvalid = xgboost.DMatrix(X_to_test, label = y_to_test)\n",
        "\n",
        "    if i==0 and count==0:  \n",
        "      my_model = xgboost.train(param_dist, \n",
        "                            dtrain = dtrain, \n",
        "                            num_boost_round=rounds,\n",
        "                            evals=[(dvalid,'valid'), (dtrain,'train')], \n",
        "                            early_stopping_rounds=early_stop, \n",
        "                            verbose_eval=verbose_eval)\n",
        "    else:\n",
        "      my_model = xgboost.train(param_dist, \n",
        "                              dtrain = dtrain,\n",
        "                              num_boost_round=rounds,\n",
        "                              evals=[(dvalid,'valid'), (dtrain,'train')], \n",
        "                              early_stopping_rounds=early_stop, \n",
        "                              verbose_eval=verbose_eval,\n",
        "                              xgb_model=XGB_MODEL_FILE)    \n",
        "\n",
        "    my_model.save_model(XGB_MODEL_FILE)\n",
        "  \n",
        "    # Evaluate the performance after each subset\n",
        "    predictions = (my_model.predict(dvalid)>0.5).astype('int')\n",
        "    actuals = Y_test\n",
        "    tn, fp, fn, tp = confusion_matrix(actuals, predictions).ravel()\n",
        "\n",
        "    train_predictions = (my_model.predict(dtrain)>0.5).astype('int')\n",
        "    tn_t, fp_t, fn_t, tp_t = confusion_matrix(dtrain.get_label(), train_predictions).ravel()\n",
        "    \n",
        "    pre = tp*1.0/(tp + fp)\n",
        "    re = tp*1.0/(tp + fn)\n",
        "    f1 = 2.0*pre*re/(pre+re)\n",
        "\n",
        "    pre_t = tp_t*1.0/(tp_t + fp_t)\n",
        "    re_t = tp_t*1.0/(tp_t + fn_t)\n",
        "    f1_t = 2.0*pre_t*re_t/(pre_t + re_t)\n",
        "\n",
        "    print(\"Test \", tn, fp, fn, tp, f1, \"Train \", tn_t, fp_t, fn_t, tp_t, f1_t)\n",
        "    pre_list.append(pre)\n",
        "    re_list.append(re)\n",
        "    f1_list.append(f1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch_size and number of subset:  32768 17\n",
            "Subset:  0\n",
            "Test  5663 36 10 11 0.3235294117647059 Train  31537 18 0 1213 0.9926350245499183\n",
            "Subset:  1\n",
            "Test  5638 61 9 12 0.2553191489361702 Train  31552 26 0 1190 0.9891936824605154\n",
            "Subset:  2\n",
            "Test  5579 120 8 13 0.1688311688311688 Train  31488 87 0 1193 0.9648200566114031\n",
            "Subset:  3\n",
            "Test  5541 158 7 14 0.14507772020725387 Train  31471 148 0 1149 0.9394930498773507\n",
            "Subset:  4\n",
            "Test  5513 186 7 14 0.12669683257918554 Train  31340 267 0 1161 0.8968713789107764\n",
            "Subset:  5\n",
            "Test  5451 248 6 15 0.10563380281690142 Train  31089 536 0 1143 0.8100637845499645\n",
            "Subset:  6\n",
            "Test  5481 218 6 15 0.11811023622047244 Train  31221 391 0 1156 0.8553459119496856\n",
            "Subset:  7\n",
            "Test  5491 208 5 16 0.13061224489795917 Train  31202 406 0 1160 0.851063829787234\n",
            "Subset:  8\n",
            "Test  5432 267 8 13 0.08637873754152824 Train  30905 698 0 1165 0.7694848084544254\n",
            "Subset:  9\n",
            "Test  5442 257 8 13 0.08934707903780068 Train  30918 694 0 1156 0.7691284098469727\n",
            "Subset:  10\n",
            "Test  5428 271 9 12 0.07894736842105264 Train  30839 800 0 1129 0.7383911052975801\n",
            "Subset:  11\n",
            "Test  5387 312 8 13 0.07514450867052022 Train  30667 903 0 1198 0.7262806911185208\n",
            "Subset:  12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-26fbef2d33c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m                             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                             xgb_model=XGB_MODEL_FILE)    \n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGB_MODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KXVRSmDml44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "1e928181-0a76-4858-ad6e-2512082e92ec"
      },
      "source": [
        "plt.plot(f1_list)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f67624a0ba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh8RewOYA1Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation solutions\n",
        "def precision_cal(y_pred, y_ref):\n",
        "  pre = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    if true_pos == len(indices_positive):\n",
        "      false_pos = 0\n",
        "    else:\n",
        "      false_pos = len(indices_positive) - true_pos\n",
        "\n",
        "    pre = true_pos/(true_pos + false_pos)\n",
        "  return pre\n",
        "\n",
        "def recall_cal(y_pred, y_ref):\n",
        "  recall = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    fals_neg = np.sum(y_ref[np.argwhere(y_pred == 0)])\n",
        "       \n",
        "    recall = true_pos/(true_pos + fals_neg)\n",
        "\n",
        "  return recall\n",
        "\n",
        "def F1_score(model, X_test, y_ref, test_size, threshold=0.5):\n",
        "  test_size = test_size\n",
        "  dtest = xgboost.DMatrix(X_test)\n",
        "  y_pred = (model.predict(dtest)>threshold).astype(int)\n",
        "  \n",
        "  precision = precision_cal(y_pred, y_ref)\n",
        "  recall = recall_cal(y_pred, y_ref)\n",
        "  \n",
        "  return precision, recall, 2*precision*recall/(precision+recall)\n",
        "  #return 0, 0, 0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edl7rXGkA9K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre = []\n",
        "re = []\n",
        "f1 = []\n",
        "\n",
        "pre_train = []\n",
        "re_train = []\n",
        "f1_train = []\n",
        "\n",
        "new_model = xgboost.Booster({'nthread': 1})\n",
        "new_model.load_model(XGB_MODEL_FILE)\n",
        "\n",
        "threshold_value = []\n",
        "indices = np.random.randint(0, len(X_to_train), size=(len(Y_test),))\n",
        "\n",
        "for i in range(90):\n",
        "  threshold_value.append(0.1+i*0.01)\n",
        "  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_test, Y_test, test_size=len(Y_test), threshold=threshold_value[-1])\n",
        "  \n",
        "  pre.append(temp_pre)\n",
        "  re.append(temp_re)\n",
        "  f1.append(temp_f1)\n",
        "\n",
        "  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_to_train[indices], Y_to_train[indices], test_size=len(Y_to_train[indices]), threshold=threshold_value[-1])\n",
        "\n",
        "  pre_train.append(temp_pre)\n",
        "  re_train.append(temp_re)\n",
        "  f1_train.append(temp_f1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKobGaRwGBAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "6050fe7c-212e-4a28-e1c6-408c68b040e0"
      },
      "source": [
        "plt.plot(threshold_value, f1, 'b')\n",
        "plt.plot(threshold_value, pre, 'r')\n",
        "plt.plot(threshold_value, re, 'g')\n",
        "\n",
        "plt.plot(threshold_value, f1_train, '--b')\n",
        "plt.plot(threshold_value, pre_train, '--r')\n",
        "plt.plot(threshold_value, re_train, '--g')\n",
        "\n",
        "max_f1_indices = np.where(f1==np.max(f1))[0][0]\n",
        "max_f1_train_indices = np.where(f1_train==np.max(f1_train))[0][0]\n",
        "print(max_f1_indices, 0.1+max_f1_indices*0.01, \n",
        "      max_f1_train_indices, 0.1+max_f1_train_indices*0.01,\n",
        "      f1[max_f1_indices],\n",
        "      f1_train[max_f1_train_indices])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69 0.79 78 0.88 0.8018648018648018 0.8636363636363635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3zN5xfHP98sMmwShJBEjIgdmxgxa5cqrVKUUlT5mUUbe5baapVaoUWN2onYkQQhQoLsJSEhe9/z++PIkp3cm5sbz/v1ui+53+/3Ps+5V3Lu8z3POZ8jEREEAoFAoPqoKdsAgUAgEMgH4dAFAoGgjCAcukAgEJQRhEMXCASCMoJw6AKBQFBGEA5dIBAIygj5OnRJkvZLkhQmSdLTXM5LkiRtkSTplSRJTyRJai1/MwUCgUCQHwVZoR8A0C+P8/0BmH14TAaws/hmCQQCgaCw5OvQiegmgIg8LhkC4C9iHAFUliSplrwMFAgEAkHB0JDDGIYAAjI9D/xwLCSvF1WvXp3q168vh+kFAoHg0+HBgwdviahGTufk4dALjCRJk8FhGRgZGcHFxaUkpxcIBAKVR5Ikv9zOySPLJQhA3UzP63w4lg0i2k1ElkRkWaNGjl8wAoFAICgi8nDoZwGM/ZDt0gFAJBHlGW4RCAQCgfzJN+QiSdIxAN0BVJckKRDArwA0AYCIdgG4AOAzAK8AxAEYryhjBQKBQJA7+Tp0Ihqdz3kCME1uFgkEAoGgSIhKUYFAICgjCIcuEAgEZQTh0AUCgaCMIBy6QCAQlBGEQxcIBIKS4s0bhQ4vHLpAIBCUBG/eAE2aAOvXK2wK4dAFAoGgJJg3D4iMBAYMUNgUwqELBAKBorlxAzhwAJg7FzA3V9g0JSrOJS/mXJmDuwF3AQCSJKFt7bYY1ngYutXvpmTLBAKB4COSkoApUwBjY2DxYoVOpZIOvbxGeehp6QEAElMTsctlFxwDHeH4nSMAYMypMYhOis7ymp71e2Jmh5kAgOEnhiNFlpLl/KCGg/Bd6+9KwHqBQPBJ8ewZEBQE2NoCOjoKnUolHfqKniuyPI9JikFwdHD688CoQEQmRma5Jjw+PP3ngMgAJMuS05+nyFLwLv5d+ljTLkyDpppmltdPbDURHet2RFxyHJ6/eY7WtVpDkiS5vSeBQFBGadkS8PICSkBhViUd+sfoaemhYbWG6c8dvnXI83qnSU7ZjrEkDeD62hX2Pvbpz9P4zOwzAMDFlxcx4u8RMKpkhKGNhuLzJp+ji1EXqKupF/NdCASCMkVcHHDyJDBmTIk4cwCQPnZcJYWlpSWpYoOLiPgInPE4g9Mep3HF6woSUxNRXac6XL93hWFFQ1x6dQnP3jzL8hoJEqZYToG2praSrBYIBCXOtGnAjh3AgwdA69ZyG1aSpAdEZJnTuTKxQi9JqmpXxfhW4zG+1XjEJMXg0qtLuOl3E7Ur1AYA2D61xcHHB7O8pn7l+vipw08AgAOuB0BE0FDjj15dTR1djLrAqJJRyb4RgUCgOC5eZGc+a5ZcnXl+iBW6nIlPjs8SnwcAdUkdulq6ICKYbTWD1zuvLOd7m/TGlW+uAAAcfB2QkJKQ5XyDqg3QoGoDJKQkwMHXIducjas3Rv3K9RGTFIPb/reznNPV1EVno85Qk0SGqkAgV2QyIDUV0My03/buHbBhA7BlC1C/PuDsDJQvL9dpxQq9BNHW1IY2cg6tSJKEZ9OeISAyo6d2TFIMZCQDAITFhqHnwZ4gZP2SXdZ9GZZ0W4K3cW/R/0j/bONu7LMRszrOQkBkQI7nt/bfiuntphfnbQkEgsxcuMAhleBgoFkzoE8fYNUqjptv3AgMGgSsXSt3Z54fwqGXMFrqWjCtaprjOW0NbdydeDfb8ToV6wAAaujUwL2J97Kdr1epHgAO7Xx83vOtJ0Y3y7NHiUAgKAxr1wILFnAZ/4wZgKsrpyUCgKEh4O9fYpugHyNCLp8Ib+PewsbBBut6r4OOpmJzYQWCMkNyMnD7NnDnDtCxI2BtDXh7A8eOcdWnllbhxktKAiZNYhmApk2LZFJeIRcRWP1EuO1/GztddsJsqxmm/TcN17yvITk1Of8XCgSfKlFRQPfuQM+ewJIlwM2bfNzEBFi0qPDOnAiYOBH46y/g8WO5mwsIh/7JMLTxUFz6+hI61OmAA48PoPeh3miyvUn6+SG2Q6C3Si/9Yb7dHFe8rijRYoFAiURFAf36AU5OwO7dQEQEsHRp8cZcvBg4fBhYuRL46iv52PkRKhdDj02KhYaaBspplFO2KSpHb9Pe6G3aG3HJcbjqdRXP3z5PPzfAbADMqpoB4CKr/17+h10uu9DHtI+yzBUIlMe1a4CLC5frDx9e/PF27+ZN08mTgYULiz9eLqhcDH2b0zbMuzoPXYy6wNrYGj2Me8BA1yD9fOXylVGpfCV5mvpJkpiSiNjkWFTVrgrPt57Y/WA3hjUZho51OoqqWEHZJTgYqM01JfDzA+rVK9o4iYnA06e8YfrwIbBrF6/4z5wBNIq3js4rhq5yDt0pyAlH3Y7CzscOT8OeZjuvJqmhda3WsDa2Ri+TXuhp3FPkYBeTFTdXYPnN5UhKTYK+rj7a1GoDDTUNnB19FgDwu+PvuOZ9LctrdLV0cXzEcQCAjGTi/0BQugkNBX79Fdi3D3B0BNq0KfpY794Blpa8eQoAenpAr17AoUP8czEpU3no7QzboZ1hOwBAaEwobvnfQnRihrKiX6Qf7Hzs8Nu937D2zlo002+GFT1XYFDDQUJMq4gstlqMH9v/iAsvL+C0x2l4RXhlWaVHJUbhdczrLK+pUK5C+s9DbYciLjkOwxoPw9DGQ2FY0bDEbBcIciU1FahbF6hQgVfmCQnADz9wQVBx+OknXt3/+SfQpQtvoqqVzIJG5VboBSUmKQZnPc/CxsEGLyNeop1hO2zutxkd6nRQ2JyCnLFxsIHtU1t4hnsC4C/ln7v8jCGNhyAhJQG/XP8l22t6m3C8PzIhEitvrcx2fmDDgbCqZ4Ww2DBsuLsBGmoaGG0xGs0Mmin8/QhUmOBgXolv3gyoq3MeeVQUoKvLqYSNGhVv/PPnuaho8WJg+XL52PwRZSrkUlhSZCk46HoQNjdsEBEfgctjLqOLUReFzyvIzvM3z3Ha4zROe5xGL+NeWN1rNaITo2GwwSDbtYu6LsIiq0UIiQ6B6ZbshVirrVdjZoeZeBH+Ai13tURSahIkScK8TvOw2GqxEEITZCcwkFMQQ0K4g5C8NVbevePc8urVeUO1sGmNBeSTduhphMaEotuBbgiODob9OHtY1s7x8xCoKG/j3mLOlTk4+PggGlRtAJdJLqhUvhL+9fgX7xPeZ7m2doXa6dk79j726F6/u4jxl3W8vIC+fYGwMODSJaBTJ/nPMW4ccOQIpzoqUJBLOPQPBEYFwupPK0QmRsJhnIO4PS+D2Hnbwd7HHiutOUxjscMC7m/cs1zTx7QPLo+5DACo93s9GFYwxO5Bu2Ghb1Hi9gpKgBs3gKFDOY594QLQvr385/j7b2DkSC5AWrZM/uNnQjj0TPi880HXP7vifcJ7GOhlv9X/GHVJHSObjsScTnNQuXzlErBQIE+CooKyqV+W1yiPmno1QUQ4/OQwZl+ZjfcJ7zGv0zws6LIgy4auoAzw6hXw3Xe8SWlsLP/xXVwAKyvuTOTgoLBQSxrCoX/Ey/CXWHdnHRJSE/K9NjwuHBdfXUTl8pUxr9M8/Nj+R+hq6ZaAlYKSInO4ppx6OQTODkR1nep4HfMa8cnxWa7VVNdMF0sTlGL8/YEDB3jFrMjstsBAoF07oFw54P59QF9fcXN9QDj0YuL62hVLri/B+Rfnoa2hjS5GXdDTuCes6lmlN6sGgLoV66KKdhUlWiooDvcD7+OG3w3M6zwPAND3cN9s8gcW+hZwm+oGgJUsG1ZrKNJhSxNJScCmTRlhjwcPgMaNFTNXTAzQtSvH5+/eBSxKJmRXbIcuSVI/AJsBqAPYS0RrPjpfD8B+ADUARAAYQ0SBeY2pSg49jXsB93Dc/XiBipqsja3R2aizUDZUYa56Xc3SfBzgSuQhjYfA+503zLebo7dpb2z/bLvoOFUaCAkBevcG3N05Zv7770Wv9MyJx49ZCsDPj+fy8mLZ3PPngf7Z+xAoimI5dEmS1AG8ANAbQCAAZwCjiehZpmv+BnCeiA5KktQTwHgi+iavcVXRoWcmNCYUTkFO6fFZGcnwNOwp7Hzs4BjoiBRZCrTUtdCpbif0rN8TtSrUSn9t3Yp10ce0j1jZqTApshRsvb8Vi68vBhFhQMMB6YVT4ktcSVhbc9jD1hYYOLD44xEB4eHA5cvAzp0soaupCRgZATVrArVqAV9+CYwYUfy5CkFxHXpHADZE1PfD84UAQESrM13jDqAfEQVI7KUiiahiXuOqukPPi5ikGNzyuwU7HzvY+djB9bVrtmssa1tiVc9V6GXSSzh2Fcb3vS/W3VmH0x6n8Sb2DcLmhqGqdlW4hbqhuk71LF/kAgXj5sYr5n79ij5GYiJvoDo6cnw84cM+m5kZMHUqpyZWrSofe4tIcR36CLCz/u7D828AtCei6ZmuOQrgPhFtliTpcwAnAVQnovDcxi3LDv1j3ie8R0xSDABWMrzmfQ02N2zgH+mP7vW7488hf6J+5frKNVJQLGQkw/M3z9FUn5sW9DjYAzd8b8C8hnm6MmjtCrVxbvQ5APx7IL7I5cTdu9x8Qh6f588/A6tXA59/zhkxdesCLVpwFksJle/nR0k49NoAtgEwBnATwHAAFkT0/qOxJgOYDABGRkZt/Pz8ivymVJ3ElETsebgHi+0Xo5pONdz89qbQOClDuIe549TzU3AOdk7vEdutXjfM6TQHMpKhxa4W6GXcC+v7rIeGmspJKpUeDh4Evv0WOHoUGF3MVovOzkCHDjzevn3ysE4hKDzk8tH1egA8iCjP3K5PaYWeF05BTuj1Vy8YVjTEjW9vQF9X8WlPAuUSlRiFqf9NxVG3oxjWeBiODT8m9P2Lws2brGLYtStXf2pqFn2sxERWWHz/nmVvK5fempPitqBzBmAmSZKxJElaAEYBOPvRBNUlKb12eiE440VQANoZtsP5r87D770f+hzqgzexb5CUmoSk1CSkyFKUbZ5AAVQsVxFHPj+CLf224LTHaQy2HYy45Dhlm6VavHoFDBvGSob//FM8Zw5wmqO7O7BnT6l25vmR770eEaVIkjQdwGVw2uJ+InKXJGkZABciOgugO4DVkiQROOQyTYE2lzms6lnh31H/YtCxQdDfkLFCV5fU0c6wHadBmlijY52OYiVXhpjRfgZ0tXQx6dwkzL48G7sG7lK2SapBcjIweDD/fP48UKUYtR8xMdzwee1aYPz4Ek0/VASisKgU4RjoCHsf+/TnkQmRuOF3A87BzpCRLL2oydrYGp+ZfSa0aMoI5zzPoX2d9tDX1UdkQiQqlqsoNkzz499/OdvEyqpor3dyArZvB06eBGJjeePTwUElVueiUlTFSXPs9j72uOZ9LV1sanCjwVjRY4Vw7GUEIkLvQ71BIExvOz29iYhxZWM0M2iGVFkq/nv5H5obNP80s6LCwnjjcsCAoo9BBGzbxk0o9PQ4j3zcOFZfVJEvUeHQyxivY15j38N9WH93PaISozC62Wgs7b4UDao2ULZpgmIgIxn2PNiDedfmISoxKv349LbTsfWzrUhMSUT5leUBAC1rtsSwxsMwrPEwWOhblP0VvZcX55eHhQG+vkULsyQnAzNncpHQ4MHA4cPcrUjFEA69jBIRH4ENdzdg8/3NSExJxMRWE7Gk2xIhHqXiRMRHwPe9b/rzGjo1ULdSXchIBpdgF9z0u4nTHqdxL+AeCIR9g/dhQqsJSEpNgoaaRtnTdr90iVfRKSkcM+/YsfBjxMTwJuq1a9yZaNUq7likggiHXsZ5HfMaq26twi6XXVCT1NDfrD+01FnCs5x6OUxoNQHd63dXrpECufM65jXOep7FwIYDUbtCbex/tB+L7BdhSKMhGNZ4GHoY90j/PVBJiDgk8vffQMOGwNmzRW8RN3ky55bv28d55iqMcOifCH7v/bD85nLcCbiTfuxN7BuEx4ejt0lvrOy5Em0N2yrRQoEiueF7A9uct+Hiy4uITY5FpXKVMKDhAPw55E/VdewrVnBK4k8/sURtUbh8mcM18+ZxNouKIxz6J0x8cjx2uuzE6tur8TbuLYwqGaXfkmtraKNz3c6wNrFGT+OeoqipjBCfHI9r3tdw2uM0AqICcPWbqwCAjvs64kHwAwBAo+qNMLTRUIwwH4EWNVso09ysxMTwCvq774qnyZJGZCTL2laoADx8CJQvX/wxlYxw6AJEJ0Zju/N2PH/7PP1YRHwEbvndQmRiJABAUy3n4gw1SQ2tarVKlwXuVLeTyIdXQbY7bUdQdBBkJINjoCNu+d/C8CbDceKLE0iVpcLod/6yH2k+Ekt7LM2i9V8i+PgAQ4Zwgc+OHcD33xd/zIkTudHFvXvciKIMIBy6IFdSZCl4GPIQDr4O2Zopp5GQkoB7gffgHOSMVEpFTb2aWNx1MSa1maS6t/ICvIl9g+ikaJhUMYGMZPj+3PcIjw/HaY/TMKpkhJ0DduIzs8/kN6FMBtjbA3Z2wK1b7LSbNweOH2clw6QkDq+cOMG65kUlMZGzYuztgRkzgIULeRO0jCAcukAuRCVG4brPdWxy3IQbfjdQr1I9LOiyAHUr1k2/xqSKCRpXb1z20+jKMLf9b2PyucnwDPfEi+kvYFrVtHjqkCkprFG+Zg2vvjU0AEtLYMMGoHNn1jA/dIilaufN4w3QghISwl8AL14AL1/yw98fkMkQCx2Ub9EY6vfvFj3+XgoRDl0gV4gIV72v4me7n/Eg5EG287X0asHaxBrtDdunr+AlSGiq3xRta7eFpnoxdTcECicxJREOvg7o26AvAOCzI7xS/7Xbr2hfp33hBouI4KYQxsbAggWcPqgjhyYgHh6Q9eqD50EV8Ei7Mx5W7IYVVlehY14fNk8+x9LTzVHPiHD4iIQuXYo/XWlBOHSBQiAiuIW5ITElEQAXxriFucHOxw72PvYIiw3L9poKWhVgVc8qXZ/GQt+i7OVNlzGICAvtFuLg44MIjQnF9HbTsbLnSlQol0dRzpUrHErZu5crMJ8/55RDOWmKB11ywx+fX8bBxFHwl3HdhbY2V/RbWHBE59YtzlL09QUWLQJ++YVvDnx92TxDQ6BvXz6mSuTl0EFESnm0adOGBGUXmUxGwVHBFBQVREFRQeT7zpf+dv+bppybQmZbzAg2INiAaqyrQaP+GUV3/O8o22RBPkQmRNL0/6aTZCNRnY11yDXENftFISFEAwYQAUTGxkQBAXKbPymJKCKCiBwc6K6ONUlIpT5dYmjfPqKnT4mSk7O/JiqKaNw4NmfJEj62cyc/B4hq1yZatIjI21tuZiocsChijn5VrNAFSiEgMiC9Rd/FlxcRHh+OgQ0HYkWPFaUrje4Tg4glwdMq6xctYnnw0FA+3qQJYN7HEa6VlsN2uC0qlKuQEV+/eJFTDqOjgeXLkTp1OlzcyuHFC6BGDW7DaWAAVK9ecLVbIsDDAzixNxK796pjULkr2PVmOKhRYwQfsoNh29oFGufkSaBnT35fERHcKvTpU17BX7zImlz+/oCubtE+t5JEhFwEpZqYpBhsvb8V6+6uw/uE9zCvYV7oMIy6pI4R5iMws/3MvEMBAoSGsmMFuAjT0ZEzBr29OTmkQQPg0SM+P2AAt9Y0MOBU7idPuKnPoUPsbAcNjMGD1r3Qv8bX2LRiI1I0KyDoN1s0H2WOGzeA7t2zz3/qFIfR7ex4D/Trr/lhYADOhHFxAS5dwhLbpjjo1RkBSTUBAP1wET+ZXUDfyfU4HbE4srmZCAxkefXu3fk9BQZy57nSinDoApXgXfw7/O74O56+eVro10bER8DB1wE1dGrg564/Y4rlFJTXUP0iEnmRmMiKs3v2sLMO/9Dt98svuaLexIQfxsasJDtxYg6DhIUB9+4h9Yk71J8/RepjN7z284DpiI5INL6F8v6tkHpuLxZMaY1lyzgL8dQpoFUrnu/1a/4y6deP53F15Yp8Z2dAXZ3QqdoLRIYnwzW1GSRJwtxKu+Gt1Qj9Gvmgn1U86n5rzd82CmTfPs507NsXaNyYH1ZWbG9pQcTQBZ8EjgGO1OuvXgQbkNkWM3ILdVO2SXInMJAoNLTg16ekEG3bRlS9OseMjYyIli0jksn4fEJCxs+5knbB/v0Zwef69TlWvmABxfuG0Mr/DlDlVVVJc5kmzb+8mBJTEomIyCvCi8JiwvIc+9nKU7RAawO1UntEo+rfpcg9x4nevCn4m5QjQUFEY8cSNWlCpKHBb1VXlyg4WCnm5AjyiKELhy4oc1x+dZlqbqhJOit16OiTo8o2p9jExhL99RdR9+4Z/tTQkJ01EdHhw+ykN20iOn+eyM8vwwfb2fH1PXsSXbqU8ZoC8eABUbduRNu38/PQUCJHR95pzIGwmDAac2oMWe62pJRUnqjxtsakuUyTltgvofjk+Kwv8PUlGjaMDbSy4ueliKQkoidP+LMvTeTl0EXIRVAmCYkOwch/RuK2/238YPkDOht1Tj9Xr1I9tDNsp7R8+LAw4MEDTrNLizH/+y9gbg6YmXGWX5rrVlMD1q0D5s8HTE15z1FXF3j7Fli5kl87dChw5kzWOZo143g3wL2Uu3YtZP8GOzsuw69QgQWtxo4t8EvjkuOgo8l55hdeXsCxhwdx2OMEGpY3xG7dUej2IJyN8vbm3dGVK4HZs0u9nO3du0C1akUXfJQXIoYu+CRJTk3G3Ktzsfn+5mzn9LT0YFXPivu0qudcRVinYh180fQLaKgVP1H5wQPgt9+A27eBgAA+Nm4cy4wAgJYW91+oVg1o3543KZcsAUaP5i8AD4+8nXJyMutQeXoCbm78ZTB1ahGNPX0aGDWKKzavXAFq1Sr8GESsPb5yJXDjBq6YAlMGAj5VAM+/KqFh8x5IsuoMrUFDFR4XlwfJyezIU1KAGzeUG1MXDl3wSRMYFYi45DgAHGJ8GvY0PWXyRfiLPF9rVtUMy3ssxxdNv4CapIZnz4AjR7hOJiGBV88WFuxwr13jn2vX5u5maQ9JAtq0YSfdrx9XvVta8rXVqvE8jx6x0793j7NOqlbllEF5CA4WCj8/vk1o0wb47z82pLBcuQIsXsy7nYaGLLLVsCHialbDvtjbmN53CSR1dUw4MwEvwl9gx4AdaG7QXP7vRc64unLqo7Y2cPUq31EpA7EpKhDkQlxSHMUkxuT4OONxhix2WBBsQA1/HUyGjUIIIFJXl1HTpkSWlkQuLjzO9u0Z8e3MDw8PPv/sGVFkpPLeZ654eBAtXkz0+ecZgfczZ4iio4s23sWLRGpqRCYmRLt3865rLux22U011tUgjWUatODqAopLiivanCXIkydENWsSVatG5OysHBsgYugCQdGIeCfD5cDjWGm3Be4b1wPm/6CS5UX0bNY0Xb6gUbVGACSEhLD2VFgYy3rHxLCsd6VKyn4XH0HEdfEbNgDnznHs2tKSG0EUx9inT7nZsokJx5b08pffjYiPwNwrc7HfdT+MKxvj+Ijjpb4Jy6tXQK9eQP/+3J60pBEhF0GZJCGBi0AkiTcMC0JSEoc3bt9mn+btzbnHbduyA/b25krCiAjuIfzsGfD4MYv1hUSHwN7HPl2rxi/SDwBQu0LtdK14axPr0t/T9cgRYMwYjvdMm8YP/WI2NwkL4+B/YiKrJxayMue6z3UstFsI2xG2qF+5Ps55nsOhJ4eyKTwe+fwINNQ04BbqBk11TTSu3rh4dheR0FCORhW04lWe5OXQVUyWRvCpQ8QJEmvW8IKSCBg5knWgUlKAPn04zmlhwc7e3x8YMYJ7G9y4AfTowa8BeC/O1DRjz2/vXmDWrIy5dHR4YzLNp9SqUAtfN/8aXzf/GkQE73feGfIFry7i0JNDAICG1RqmO/j2ddqnNw6RJAk1dGooT1o4PJyd+OjRrEg1aJB8VA/j4jjVJjSU/3OKUGbZw7gHHL9zTH/+IOQB3MLcsl0nIxkA4FeHX3Ha4zQaV2+Mr5t9jf91/B+0NbWL/h4KSVqlrbs7LwIGDSqxqfNErNAFKsWYMbzA1NcHJkzgSj4LC97DCw5m534no6UqtLT4tnjCBD6/ezfQtCnQpUv25A1nZ/4CqFKFV1/16hW8ulxGMriFuqU7+Jt+NxGTFJPtOgNdA/Q07glrY2t8ZvYZalUoQgZJYUlJ4bzHv/7inT1DQ/mN7eICfPMNp9ecOMHfniVAQGQAzniewWmP07D3sYdpFVP8MfAPWJtYl8j8afTty5vZ3t5AxYolM6cIuQhUmqdPOfGiXDngn3+AN284H1s7lwVZUBA7byMjFoWSk2JroUhOTYZzsDOehD5B2t9YUmoSnIKdYO9jj9cxr6GnpYcDQw5guPlwxRqzeDGnD06bxnFzefTVTEnh26SlS1l168ABwLpknWka132uY/L5yfjB8gfM6jgLKbIUqEvqJXIn5OzMd3+//grY2Ch8OgAiy0Wgorx7R/TDD5w0sX69sq2RHzKZjJ68fkId9nYg2IDmXplLyak5aL/Kgxs3iCSJaPx4+Y3p6krUti2n8Ywe/UHTVrnEJcWlf4a/3/udTDeb0pzLc+jF2xcKn3v4cCI9PaKwPBQO5AlE6b9A1bhyhahOHSJ1daLp04nevlW2RfInITmBpp6fSrAB9TjQg857nqeohJzL6ovEu3cs3mJqmmu5fqGIiyNasID/U2rUILK1Lf6YCuCc5znqe6gvaS7TpNq/1VZ4OuSzZ7zomDVLodOkk5dDF61iBKWOdet4c1NPjwtttm7NKMApS5TTKIcdA3bgwJADcApywsBjA1F1XVV03t8ZS+yXwMHXIb0bVJFQV+f8uqNHuYS/ILx/D8TGZj3m7c1Nlps25TDLuHFcSfXll0W3TYEMbDgQl8ZcwrWx1xAcHYxtTtsUOl+TJlyVWxq01EUMXVAqIALi4znp4uFD3vhcsSL3OHlZIz45HncD7qZvqroEu0BGMmhraKOHcQ8s6LwAXet15T9yL8AAACAASURBVBzK0FDerW37IV/75EneCX7+nJ14xYrsfBctKrgBcXHstNet4zr3unW51j0qivu6AZxjvmIFpwqpCP2P9Id/pD/cprqVmVaHYlNUUKpxdOR0QQsL1usWAO8T3uOm303Yedvh72d/4927EBxzroehVzj3HYaGnJcJcKrFzZu8VJQkdsJNm7LiV34QcYn/jBncbPPrrzl1yNOTHwBnrnz5Jaf9qBiBUYGoUr4KdLUUv3yWyXgDv7mCVQxEHrqgVOLjAyxcyDnkNWuy5IeAqVy+MgY3GozBjQZjjdEExA7si+q+ftjcHnjavQnaGrSGqbcdOht1RvkjR7iHWkG6HYeHc6bL/fusEhYYyBVa5uaAgwPQrZvC31tJklbklSJLQUJKAvS08q9eLSq//cbZoYGBrOejDAp0DyJJUj9JkjwlSXolSdKCHM4bSZJ0XZKkR5IkPZEk6TP5myooSxw/zgvBs2e5eOflS05FFGRH28AQ1asaIvbcKcStX4VnDavgh2hb9DrUC0abjGAX9Th/Zx4fz/FvU1MOq8THA61bA9OnA/v3c/lsGXPmaSSmJKL5zuZYbL9YofMMHMg3PCdPKnSavMlttzTtAUAdgBcAEwBaAB4DMP/omt0Apn742RyAb37jiiyXT4PUVKLr14m++46oVSuiffv4uL8/HwsMVKp5pRdvb07vSWtl/1FbociESDrrcZbMt5uT2lI1Wnt7Lclyaz3k7s4pQwDRwIFEbiXTyUkmI3r5ksjJiX8PlMnEMxNJa7kWzb40m2753UpvwCFvmjUj6tJFIUOngzyyXAoScmkH4BUReQOAJEm2AIYAeJb5ewFAWp1UJQDBxfuaEag6ycm8ENy/P6OKrlMnjgwAvOcm4uWZiI9ngZm0jsVbtnBF1HffcZPPj4pkKpariEGNBqGHcQ9MODMB86/Nx/2g+9gzaA+qameSvI2L4/LZpCTWPrCyUvjb2LOHFXQdHTN6l5qYAOPHc4KMjg6/zcBAbkr97BmX0IeEcLbIjz/KXyNlZc+VeB3zGludtmKj40Y0qNoAntM95b5ROnIk33EGBcm3ILeg5LspKknSCAD9iOi7D8+/AdCeiKZnuqYWgCsAqgDQBdCLiB7kMNZkAJMBwMjIqI2fn5+83oeglBAQwM6aiLWaKlTgsvthw+QjG1JmCQnJEnh9Vb8XDnXfB38YITmZtUNq12YnYWLCCShpwohEhI33NmL+tfnQ1dLFnI5z8FOHn1ChXAXemNi9G4/XXcbr5n0A8HdDnToc8vq4ijY+ngtJC1tkmZoKHDrEziwwkPdnO3YEOnRg+YWDB4Hr13N+bdWqvIcrSby326wZyzV07pzz9cUhKjEKF15eQGhMKGZ2mAkAcA9zR1P9pnIZ39OTP9ctW3ifWREUq1IUwAgAezM9/wbAto+umQ3gfx9+7ghevavlNa4IuZQtAgKIevUi0tYmCg/nY3lIYX9SREURnTxJNHky0ZAh3N+zXTui8e3d6U6XuXTntozehqXS8R8cqHMtL9JCAqmrE1WuTFS3LkuL6+hQNq31WrWIevQgmjqVaMsWot3/ulGvvUMJNqDq66rTsvVjKV4DtEVnfo5a7RUrEllbE02axDbVrs3H27QhOn26YGGSgACe28KCX9u2LYfYcsLLi2jtWu59+vff3J709euMaJJMxvPWrctjjRhBdPWqYsM1/734j2ADmnp+KqXK5DORvT1RYqJchsoRFEcPXZKkjgBsiKjvh+cLP3wRrM50jTt4FR/w4bk3gA5EFJbbuCJtsexw8SLrMyUkAMuXA5Mnl44ii5wID+d+nBUqcBhIVzdjNZqaCrx4wXnwDx+yImytWhkrY1NT7sqWm8w3EY//4gVv8r58yVofDg4c8ahUCahfH6ikm4JRETvwrecCRJMe2sIZ/uCUwO7dgTlzWGs78+qZiFvMBQVxRMbDI+Px/DmfS8fQCXp9ZiGm3l3oR2rB8P1mLB4yEbX0NUHE6XWvXnGiy/373KSoQQNeVdepA9jaciikWTNe4Jua8l2Xvj7fgaXNefUqvx7gaxcvBr74ovCr+4+JiQFWrwZ27WIZYxMTjjxNniz/ArPYpFgstFuIrU5bsWvALnxvWfpTrYq7QtcA4A3AGBmbok0/uuYigG8//NwEHEOX8hpXrNDLBsuW8WqqWbOM7jzK4P17IgcHos2bWbbk22+J9u/nvcXkZKJz54iGDiXS0Mi+Us3pUb48Ub16ROXKZT9XuzavsHv14qb1I0fyyrRy5azXqasTmZsT/e9/bFtyMhHdvk3UogVf0K8fhbuH0MmTRL/8UvQOODIZUXAw0Z1jfuQ4Zit5mfWhJDUtutBQl1pvbEWwATXY0oCOPjlaoFVocjLR4cNETZrk/vmoqfFKfuVKxf2/x8cTHTlC1L07z6mjQzRjBv+fyhOZTEY9DvSgSqsrUXBUcLHHS0kh+vlnokOH5GBcDqC4HYs+pCH+Ds542U9EKyVJWvZh4LOSJJkD2ANAD7xBOo+IruQ1plihqwZEQHQ016rExPDPbm68wSVJwKRJ/O/mzSVf1ZmczHcH+/dzbUxKCh+vUYPtfvuWn2trc2xYX5+b17dsye8jOjp7lbuJCWfzNW7MmYBEwLt3HBd++ZJX356eHPJOGyMxkWtuzMz40bAh/2ts/NHmXlJSRieO338HPv+8+MtZIr4F2LQJOH+enzdsyALd48eDzM1x/sV5LLJfBLcwNzTTb4YVPVdgUMNB+aoRymS8Ik9LVw8N5ZV648b8Nsrl3FtbITx9yunzR4/ynVT9+hx7r1KF7y4mTOCmS0XlRfgLNN/ZHIMbDcaJL04U297mzdk+B4diD5UNUSkqyBUizkJ58IALfYKD+bZ+7Vr+o92xg1VXP8bVlZMvYmNLPrzy9i3ru+zaxWERAwPWSbe2ZmddsyZf9+wZb8Q9fcrFlAMHKqfDDCIiON6irs4fnJlZ4T40Ik4DuXCB00cSEjJiRp6eLAdQowYwZQp/EA0bZhtCRjKccD+BJdeX4FXEK7Q3bI9V1qvQ07inHN+o4gkMZE17Ly/+oo2I4AVGXBxr4k+Zwv07ivI7ucN5B2rq1cTnTT4vtp2LFvHf0Js3BdfULyhCPleQhbAwFuIj4s26jzfKGjfOaH78+DHRunXc7/fYMQ5dPHuWLS26RPDxIfrxR954BYgGDSI6e5YoKankbSkwz54R1a9PNH9+4V6Xmkp05w6/4bRdQoCoeXPeyWzblqhRI+5UvXcvxycKQFJKEu15sIfqbKxDsAFZH7SmW3635LYhqAzev+cm3Wkbs5UqcWjm2TPl2XTvHtty9Kj8x4ZoEi0gYmmPtBzhNWt48y00FDhzhm9X89rwUwaRkbypePkycOkSr7Q1NFhuZN48rlZXOrGxwLVrHH/o2pWXhs+fc8NST0+OB2lpcTikbQGbH2/ezPGFwEAet18/vr3o319uyc0JKQnY5bILq26twpu4N6iuUx096veAtbE1RlmMQqXypa2zdf4QsUbZrl3A339zhKtVK06ftbTkUJGfH9+5eXoCvXtnhAwzs+b2GrgEu+DQsENFbmsnk/GGurU1h4nkiVihf+LY2WX0I6hblxeLz58r2yomMZHo8mWuIF27lmjuXN68NDbOWJRqafGidP16Ij8/ZVv8gbg4ot9+Y13wNEPTduuWL8/YWe3WjW8tCsrvv/Nre/TgXbXISEVYn05UQhQddD1IY0+PJcPfDAk2INPNpvT49WOFzqtowsKI1qzhdMyKFbNvVqelaP7wQ0Yxbhrr7f8gyUaiHgd6UHRidJFt+PFHookTi/lGcgCiwcWnR+YmMr17syP/80/egS8NeHlxrwR9/ax/bOXKETVsyJkjq1YRXbxIFBOjbGs/4vlzTgIHONXl6lWiu3czko9fvyby9S18AvWxYzzmsGFK+Y+SyWTk4ONAtTbUIu0V2nT48eESt0ERpKYSeXpyuPDpU/5vSk0lmjePP+6+fYlCQ7Nm1FiOP0zqS9Wpw94OFBGn/I5MmREOvYwjk3GBx5kznP7WpQunlXl58fmgoAKHWBVCSgr/QR06RDRtGqe7SRLbOGQI/6H5+BBFRysnNl9goj+s1lJTeWl344b8xr5yhUhTk8jKSrn/WUQUEh1CXfd3JdiAvj/3PYXFlFBvNSWwZw+nskoSe0NjY6KxY/nntt+cIq3lWtRhb4di7THIo1lUZoRDL2NERxOdOpVxh3/mTMYKV02NRbCWLGFHXpJERhLdv090/DiHT777jvO1M1c56upyNGHZMv4SUgmSkzlOpa/PSzl5EBnJtx9Ll7JglrY2b3im7VYrmaSUJJp9aTapLVUjvVV69Iv9LxSZoNjwj7K4fp3DI5mrUrdt49/X1mP+pu2Ou4ss5jVlCpGZmfxsJRIOvcwQGclhiGrV+H/u99/5+OvXXH59507Jhyfi4zlTZtgwjnVnDp9Ur87Oe+ZMjpE/eVJ6Qj4FJjmZaNQofkMTJhSvIXJoKKcL9e+f8WFJElfwTJjA1UGljGdhz2jEiREEG1DVtVVp7OmxdND1IAVGln2ZzJ07+b/os8+KXsqf9sUgz+KrvBy6yHJRAYiAjRuBlSs597Z/f85Q6dhRccU89KGgJjSUc9MfPeJOZE5OwOvXnLihqckp0XFxnPs9ahR3JzM25kKbihXzn6dUk5rKIu2HD3NS8bx5RRvn3Ttu77ZlC6deGBuzWtlnn3Hmiwp8UA9DHmL93fW46nUV4fEsoainpQcJ+RdG1alYBweHHkRbwwJm+ZQi/vgDmDI1Fa2/34nZU6rh6xajC/V6Pz8uglq/nv9m5YEoLFJxUlOBr77iqsRly4pXEZcbcXGs3mpnx48nT7gSMzPGxux/jIy4KjM5mdMIBwxgR16QhjkqxaZNwOzZ3EezMP0500hKYtnAZcvYqY8bB8ycmaMcrqogIxncQt1g52OHwKjAAr3m1PNTCIkJwbb+2zCpzSQFWyh/1q4lLHjZGbq1/RC2+BV0tAq3imrRgmWjb9yQjz3CoasoMhn7gWrV2IGqq8vfDwQFcdrzrl38haGpyZKnHTtyHq2BAT+aNeNixDKPjw/31uzRg28/Tp7kxPfCkJAA7NvHq/qAAKBXL84rb9FCISaXdsLjwjH65Ghc9b6KCS0nYHSzjFWuvq4+LPQtSn0D59ELb8C2fHdYp27AtWX/K9Rrf/6ZewNER8vnjlo4dBUkNZX1KZycuLhG3gU/r16xot2hQzzXyJGsc2JlVXqVEhXCzp1cGBQRwbEkDw8WLPHzK/y3Z2ws16WvX89iL507A7/8whUsKroilxepslT86vArVt5ame1cWlFTvwb9MLbFWGiolb5bPSLA6Od+CJS5YGM9b8z6oeBhssePOWQ5cqR8egKIwiIVIyqKaMAA3kxZvly+Y/v6crGDujrXvfzwQ0Z6Y5knOZm1DGxsMvQC5sxhScQuXTiHcu3awhUCEXHt+YoVvAucVhRkb1/KczCVg8cbD7rldyv98ZfrXzTu9Lh0KYJZl2Yp28RcuR/gQrABST1/yVXzvSSA2BRVHQICuMrb3R3Yto3FhopDaiqPdfcud4P55x9eLE6ZAixcmCFkpbLQB3Uxd3cWwDI25vJ4dXU+//w5K3k9fMhLpYQEFhq/eTP/ljgpKfya27cBFxces1IlfiQk8Cre3581CWJieJNz0SLutScoFESEmZdmYqvTVvzzxT8Ybj5c2SblyNyLS3B8bTfEPe0FZ2f+dSsI7u78K9K+ffFtECt0FWLQIC5Vvny5eOOEh7Mmc2aNbgMD7m7j7y8fW5VKWv6jl1fWXEmAC3ROnODzjo78gXbvTjR7Ngt955Wgn5aHOXw4kZ5expiGhkRGRjyWJHHaYYMGXFv+/fdEDx4o/j2XcRJTEqn9nvZUcXVFevH2hbLNyZUXL4iqVGExsIIWDXXtStSpk3zmh1ihl06IWHjqxAnWF+/alUOv4eGAhUXRxgsI4DDuli28Ihg+HBg6lBeN9euXgVBucjLfWrx6BZw+zcf27+emlNHRvKnp4wN068aiVjIZX5PW/sfbm9vsBATw6josjD84gLNSHBxY/F1fn1MLu3Xj/5g6dTJs+HhMgdzwj/RHqz9aoU7FOnCc6FhkcSxFEhEfgalH1uCfedPRpZkRjhzJ+uuREz/+yL+mUVHF/7URK/RSyh9/ULrc559/Fm2MpCQuXvj88wzBIYDoiy+I3Nzkaq7yCQwk6tyZ0lWVCqObm5LCOsCZq58qV2YJWnNzfjRtSjRuHJfhf6zYJCgxLry4QLABDTk2pFjiWIrC770faS3Xom6/TSAdHV6tp90Q5sa+ffwr90IONx4QlaKlDycn9i39+hW9Cu35c9ZFAYhMTYm+/ppo69bSo6QoV548IapZk7UDCisy7eXFm55pwldPnshfYEMgV7Y4biG1pWpkvt2cPN4osbdhLsy8OJPUlqrRJRcPateOf7XGjct9jfHgAV+Tn+MvCMKhlzIiIlj9sH59jnUXFpmMBf21tVkG4NQp+dtYqkhJYQlGQ0OWy8uPFy+INmzgdJ5OnfiDqliR6K+/ROaJCmHnbUfV11WnCqsq0KlnpeuXPDQmlHRX6tJXJ7+ipCSiRYvYm65bl/P18fEsArZoUfHnFg69lJGayposBd1HS00levWKb9u++oo3Nz/0GC6N8h+K4eHD/NMJ077pypfnD0hfn/XIp08vRULqgsLg/96f2u1pR7ABHXh0QNnmZGHaf9Oo/Iry6aJlgwezEJ2vb87X37xJ9OZN8ecVDl2JJCVxGGTCBJbOLug3tIsLS8126kRUoQKlh3319YlGj2bp7DK/2Lx4kXPGC0JYGKcIpQlcCwdeZohPjqfef/UmtaVqdPzpcWWbk879wPs05tQYCohk2VA/P44IDhyo2L9N4dCVxIsXGZ2CatUiat8+70IhmYzrUXr3pnSp2a5d2bHv3s2h3zLvxNNwdOTlTsuW+euDnz7N8XUtLaJNmwrfWEJQ6olJjKEu+7uQxjINOutxVtnm5MqGDfy3e/Jk9nPe3kSrVxctzJoZ4dCVxJw5vAP+998Zx+zsWHt56FCi1q05fFKlCidcpK3EDQw4Fqfg7mOll2fPiKpWJTIxIQoJyf26sDCiL7/kD61FCyJX15KzUVDiRCZEUtvdbUlruRad8zynbHPScQt1S+9qlJzMv4qGhtn33e3s+Ff16tXizSccegni5cUZLES8sExr4uDiwiGXtJV306Ysiz1pEod4Z8xgR797t9Ib1igXf3/eMTYw4I2D3DhzhkvttbT4tqcwKYwClSU8Lpxa/9GaJBuJbK7bFKuTkDzweONBsAFtu78t/ZijI9eeTZ6c9dq3b/nvf/364s0pHHoJkJDAXXjKl+dUwrTQSGws0Zgx/ElXq8YRgYQE5dpaqjl7lm9XHj7M+XxqKsfVAb7FKUjWi6BMEZsUS9+c+oZgAxpwZIDSe34229GMOu3LWgaa1q/0yJGs19apw+nFxUE4dAUTHs5t3wBubhz4oZlLRARvaqqpcRn++/fKtbNUkzm+FJZLD8uoKI5VpSX9ftK3Mp82MpmMtjttJ81lmmSy2YRcQ5QXblt9azXBBuQd4Z1+LCmJSx90dTmCmMbAgXx3XhzycuiidrmYREdzByF3d+Dff4Hjx1kbKjiYpWhdXLi0f+VK1nQS5MDVq6xLcO0aP/9YeD0pieumW7YEzp1jAfc//wTKly9xUwWlA0mS8EPbH3Dj2xtISElAx30dceTJEaXYMspiFADA9qlt+jFNTcDWluVyR4xgZWWAf4V9fPhXWiHk5ukV/SgrK/TERE4jPJtp493VlbuH6+nxRoggDw4e5IqL5s2zi2a9fcuNU+vU4VV5q1ZEDg7KsVNQagmJDiGrP60INqAZF2ZQYkoRS6+LQed9nclyt2W249eucTx97Fh+HhVV/O0eiJCL/AkLy14k8P49N0RWV+d88bTNUUEOyGS86QAQWVtnxKOCgog2b2ZNcXV1Pm9lRXTp0ieUsykoLEkpSTT70myCDajzvs4UHFWyFXeebz0pKiFnOYm0eHpagkRxEQ5djri6Eo0fT1SuHMtnJiRwZfrBg5wKLUlEU6YUP9e0zHPmDP/6jR3Ltzn+/qztmyae1bQpV2EJWVpBIbB1syXdlbpUc0NNuul7U9nmEBGRuzv/Su/aJZ/xhEOXA//8Q9ShA39iOjrstJ8+JbK1JWrcmI9bWopVeZ7ExRHdvs0/y2RcfREZyY5cU5MfkycTeZQ+MSaB6vA09CmZbTEjjWUa9IfLHyU275pba2in885sx2UyLqkYMEA+8+Tl0MWmaB7cvcuNaQDe5ExI4Gavjx+zXvmXXwKjRrG+8d9/s8x227bKtblUkpzMu8L16nF/zYgIFma3tGSt8d27gYkTWeP8jz+ARo2UbbFAhWmq3xTOk5zR26Q3pv43Fdd9rpfIvJe8LuGA64FsxyWJu5DZ2QFxcYq1oUAOXZKkfpIkeUqS9EqSpAU5nN8kSZLrh8cLSZLey9/UksPXlxu6du7M/gUApk4FVq0C7t0DzM2B6dMBDQ3g6FHgyRPeyRb9DnIgOBjo2RNYvBho1w747z+gShXufN2+PX/YFy5ws2YjI2VbKygjVCpfCSe+OIFG1Rph1MlRCI4OVvic7Wq3w6PXj5CUmj2FZeBAXhDa2yvYiNyW7mkPAOoAvACYANAC8BiAeR7XzwCwP79xS2vIZccOLg7S1iZaupRj4Xv2EDVpQuniWLNmiSrzAhEZySI2OjoZFRbJyRxM1NZm/WB3d+XaKCjTuIe5k85KHeq6vyslpyq2ack/7v8QbEDOQc7ZziUmctbbx9WjRQHFDLm0A/CKiLyJKAmALYAheVw/GsCxIn/DKJENG4AffuAFpbs7dyEzNwcmTQLKlQMOHeLOZRs3Ai1aKNvaUkxai7aKFYElSzgWNXo0cOoU0KwZd6hu146Pm5sr11ZBmca8hjn2DNqDW/638LPdzwqdq51hOwCAU5BTtnNaWkDfvsD58xkdDxVBQRy6IYCATM8DPxzLhiRJ9QAYA8jxxkKSpMmSJLlIkuTy5s2bwtqqcD77DJg1i/3NwIEcZmnYkG+THj4Exozh/xhBHri6cmzczo5/czt2BM6cAVq35ganksS9QK9f529MgUDBfNXsK0y1nIr1d9fDeLMxJp6ZiKNuRxGbFCvXeepUrAOzqmaISozK8fzAgRyBfPRIrtNmJbelO2WEUEYA2Jvp+TcAtuVy7XwAW/Mbk0pRyCU1lRtHyGSchPHVVxxaadCAVVlF6nMhWLOGi4SqVeMmp2kFQWkpQPv2iV6dAqWQmJJIu5x30efHP6fKayoTbEDdD3SXu7iXLA+HERrKac1LlxZvDhQnbRFARwCXMz1fCGBhLtc+AtApvzGpFDn0LVv4Uzh1in0OwB94Uft8frJs3EjpjZcBTkEcPJid+CfTVkmgCqSkptDv934n2ID2PNhTonN36MA9EopDcR26BgBvcCglbVO0aQ7XNQbgC0DKb0wqJQ795Uvem+vYkYuC9PSI/v1X2VapIDt3ZqzEW7bkb0l59NoSCBREqiyVrP60osprKlNIdB6a+4XkWdgzarWrFV33uZ7j+ZUr+c+kOGucvBx6vjF0IkoBMB3AZQDPAZwgIndJkpZJkjQ406WjANh+mLDUk5oKfPstpxo+fMg6T3fvAkPy2u4VZBAfzymIQ4fyZkP16sCxY/xhzpjBzwWCUoqapIbdA3cjPjkeP178UW7jGugZ4NHrR3AMdMzx/MCB/O+FC3KbMgsaBbmIiC4AuPDRsV8+em4jP7MUz+bNwJ07/HOHDsDZs9lF/gQfkZrKFVRHjrAyYkICy8mtWsW7yUL9UKBCNKreCEuslmDx9cU463kWgxsNzv9F+VBVuyrMqprlmOkCcJLX2rVAly7FnipHPslSmMRE4NYt/nnYMM5iEc48D1JSgMOHgaZNOf3w7t0M592yJTBvnnDmApVkbue5sNC3wIQzEzDjwgz86/Ev3icUry6ynWG7XB26JPGfi6KKoT8Zh56SAly5wiEVAwPWLp81ixec2trKtq6U4eUF7NoFzJnD33impsA33wDv3nFCfkQEYGICnDzJ34zq6sq2WCAoElrqWrAdbgvL2pbY77ofw44PQ7V11bDv4b4ij9m2dlsERQchKCpIjpYWjAKFXFQZb29g3z5+hIbyMSsrrnfp1Uu5tpUqUlM5sLdjB3DpEh/T1GR9g27dgE2bWKXfxYUDgb168XJDIFBxmuo3xaUxl5CYkoj7Qfex2H4xfrr8E/qY9kHdSnULPZ5VPSt82fRLJKQkKMDavJGUtYdpaWlJLi4uChv/1SvWW7l8mf1OzZpASAgLah04ICIEWXj1Chg8GHj+nNsqmZvzh+Xry/eGR44Abdoo20qBoETweecDi50W6GncE2dHnYVUyhYukiQ9ICLLnM6VyZDLqVPsf5ydubqzRg3gzRtgzRpOxBDO/AMvXwI//shVnGFh3OYtMpIzVWrXBv75hzUQhDMXfEIYVzHG8h7Lcf7FeZxwP1HkcSITIuVoVcEoUw49ORmYPZsrzBs35hLbL74AatVi5z5/vogSAOBY+JgxrGuwdStnkN+9C4wfzw0PY2M5BWj4cBEfF3yS/Nj+R7Sp1QY/XvoREfERhX79tP+mocn2JgqwLG/KjEMPDWVRrU2b2IlPmMBqrIMHAw8ecDKGAJxuaGHBtyoA51G9esXOHeBmzcKJCz5xNNQ0sHfwXoTHhWPulbmFfr1pVVOExIQgLDZMAdblTplw6C4urAfl4sINJ06fZuXExEQ+L/xTJqKjeQUuk3HKz927nPYjEAiy0LJmS8zuOBv7XffjUUjhFLVa1uQV5OPXjxVhWq6ovEM/fJib3kgSJ17Y2rKfcnLiDDvBB4KCeJNz2TKOky9fzpsNenrKtkwgKLUsPXNMpAAAEzdJREFU6roI1bSrYf61+YV6XQsD1td2fe2qCLNyRWUdeng417h88w1La48dy1rDv/zCueVVqijbwlKEvT2HUpo04Rj5f/9xByHRYkkgyJNK5SthidUSXPW+iiteVwr8umo61VCnYh24hgqHni///stFiydP8oLz2jXOZPnmG8DGRmx8ZuH6daBfP66sateOM1g++0zZVgkEKsMUyykwrmyMeVfnIVWWWuDX/drtV4xqOkqBluVAbqpdin4UVW1x9eoMUb/Hj1nPPA2hXZ4JmYx1gCWJP7CVK8UHJBAUkWNuxwg2oIOuB5VtSrFb0JUqRozgVbmTE1CtGqdQX/lwJyRW5h+IjeUKql9/5Q/l8GHg55/FByQQFJGRTUfCsrYlFtsvLnAFaHJqMh6FPMKb2JLrzqZyDr1BAy7bj4gArK25tL9qVWVbpWTCwzkNcexY/lDateOioC+/BAIDga+/VraFAoFKoyapYX3v9QiICsCW+1sK9Bq/SD+03t0aZz3PKti6DFRSyyU8HOjdmxs2X77MKYufJEeOAFu2cNUUEauMJSTwrcuVK0KsRiCQI93rd8cAswFYdWsVJraaiGo61fK83qSKCfS09PA4tORSF1VuhR4dzd2zX7xgDXNF6QqXWvz8gKQk/vn9e06yHz2axWri44Fx47hcXzhzgUDurOm1BtFJ0Vh1a1W+16pJamhu0LxEUxdVzqHr6HDc/NQpji58MhABf/7JVZ4rVvCxadM4/fDoUV6V37zJ1+jrK9dWgaCMYqFvgfEtx2Ob8zb4vPPJ9/oWBi3wOPRxWptOhaNyDl1dHdi9+xPLvJPJOA4+YQLHlyZO5OP+/pyr2bIlh126dlWunQLBJ8DS7kuhLqlj8fXF+V7bsmZLRCVGwfe9r+INgwo69E+Sdet403PpUsDODqhXj8MuI0dyfrno0iEQlBiGFQ0xq8MsHHU7igfBD/K8doDZAFwZcwUGeiUjr1Fm9dDLDO/eAcbGXBx07FhG6uHMmbwh+s8/rIooEAhKjMiESDTY2gCNqzfGjW9vQE0qubXxJ6eHXqaoUgW4fx/44w925lFRnLe5ZQs7deHMBYISp1L5SlhjvQa3/W9j78O9eV570+8m/nb/u0TsEg69tEIEXLzI/zZqBGhpsYSkiQlvin75JYdiBAKBUpjQagK61++OeVfnISQ6JNfrdjjvwLxr80rEJuHQSyurVvHO7549wNy5HDefO5e7Bzk5sayklpayrRQIPlkkScLugbuRkJKAGRdn5Hqdhb4FfN/7Ii45TuE2CYdeGjl+nNMR9fWB778Hfv+dE+5v3OBKqrZtlW2hQCAAYFbNDL92+xUnn5/EGY8zOV5jWsUUAEok00U49NLGzZsZpfrq6sDq1VwSe+oUYGWlXNsEAkE25nSag+YGzfHDhR8QmxSb7bxJFRMAgPc7b4XbIhx6acLRkaulUlM5JfHZM2DBAq4CFQgEpRJNdU1s6rsJwdHBOOOZfZVuXMUYgHDonw6PH7MD79SJS2G3beOwS+XKyrZMIBAUgO71u6NOxTo49vRYtnM1dGrAY5oHvm/zvcLtEA5dWRDxitzKiis9z54FFi7kjkLTpinbOoFAUAjUJDWMajoKl19dRkR8RJZzkiShUfVGKKeh+J6YwqGXNHFxrF3QujXQsSNw6xbrsBw+DKxcKbSABQIVZXSz0UiWJePks5PZzp1/cR6rb61WuA3CoZckbm7syL//nkv2DQw4rzwoiDt3CAQClaVVzVZoWK1hjmEXO287rLi1QuEiXcKhlwREwL593HgiMhK4dAn49lsgNJQrPssp/lZMIBAoFkmSMNpiNBx8HRAcHZzlnEkVE8QlxyEsNkyhNhTIoUuS1E+SJE9Jkl5JkrQgl2tGSpL0TJIkd0mSjsrXTBVGJmN1xO++41xyV1cWdG/UiFfqAwYo20KBQCAnRluMBoFwwv1EluNpqYs+7/OX3C0O+Tp0SZLUAWwH0B+AOYDRkiSZf3SNGYCFADoTUVMAPynAVtVk40bWKP/5Z16ZG3xQXRs4ENi1S7m2CQQCudKoeiO0qtkqW9ilpFIXC7JCbwfgFRF5E1ESAFsAQz66ZhKA7UT0DgCISLH3FarCgwfsyD//PKMpxX//AcuXc6s4gUBQ5hhtMRpOQU7wivBKP1a/cn0AyBaKkTcFceiGAAIyPQ/8cCwzDQE0lCTpjiRJjpIk9ZOXgSpLTAy3hjMwAAYNAkaNAmrU4JX5H38AiYnKtlAgECiALy2+BAAcenIo/ZiOpg5if47FnE5zFDq3vDZFNQCYAegOYDSAPZIkZauKkSRpsiRJLpIkubx580ZOU5dSZs4EXr0Cpk4Fxo/n9MQhQ1jT3M0NqFRJ2RYKBAIFYFTJCIMaDsImx014G/c2/biOpo7C5y6IQw8CUDfT8zofjmUmEMBZIkomIh8AL8AOPgtEtJuILInIskaNGkW1ufSzaxewfz+HWxYsAA4cYD2WP//klXqVKsq2UCAQKJA1vdYgJikGK2+uTD9m+9QWk89NVui8BXHozgDMJEkyliRJC8AoAGc/uuZf8OockiRVB4dgFC9cUBpZt45X5fXrc2qimhowbhwLbQkEgk8C8xrmmNByArY7b0/fCH3+5jn2PtyLpNQkhc2br0MnohQA0wFcBvAcwAkicpckaZkkSYM/XHYZQLgkSc8AXAcwl4jCFWV0qYSIS/fnz+dYua8vYG+vbKsEAoGSWNpjKTTUNLDIfhEAznQhEPwj/RU2p0ZBLiKiCwAufHTsl0w/E4DZHx6fHnFxwIwZHGbR1eUN0cOHM2RwBQLBJ0ftCrXxv47/w4pbKzC7w+wsMroNqjZQyJyiUrS4ODqyuNb+/RxWqV4duHNHOHOBQIC5neeihk4NzL82P6O46J3iiouEQy8qCQm86dm5M5CUBFy4AEyaBLi4AK1aKds6gUBQCqhYriJmtp+J677XoammiVp6tZCQorgalAKFXAQfcfEih1i8vHjDc8MGXpn3769sywQCQSmja72uAACXYBcE/0/5hUWCNAICgGHDuHmzhgZw5Qp3E+rbl+PoAoFA8BFtarWBmqQGpyAnhc8lHHpBuXqVY+VXrgBr1gBPnnB3oXXrWBJXR/FFAwKBQPXQ1dKFhb4FnIKdsP/Rflj/Za2wuYRDzw8idtr9+gG1a3O7uPnzgagoDrfUq8cCXAKBQJAL7Wq3g1OQEyLiI2DvY4938e8UMo9w6HkRFcWVnfPncwOKe/eABg1447NpU8Dfn6tAK1RQtqUCgaAU075Oe0TER0BbQxuA4mR0hUPPDWdnDqWcPAmsXQvY2gLly/O5hg2BDh34mm7dlGunQCAo9bQzbAcAiEyIBKA4GV2R5fIxMhmHUBYu5BDLjRvcUWjCBM45f/oUqFgROHNG2ZYKBAIVwbyGOXQ0dRAUHQS3qW4wrWKqkHmEQ8+MTMaO++BB1jD/3/+AuXOBu3e5AvSbb4DYWHboAoFAUEA01DRgWdsSD0IewELfQnHzKGxkVYMI+Omn/7d3/7FV1Wccx98fi0jcZP6oM/zoFCMkM4jOFXBGt6mTiFFqgkyXmIlBZzTOxOkSjIk1GEkWowYNZlYxTuMP/BXSZS5EFxaSAUKJrgoTRaeI4qjWogSxo3v2x/dWbqFwL9h7T3vu55U0ueeewz1Pnlyenn6/3/OcVMzvuAMuuSQNq4wcCQsWpAlQt7w1s4M0ZfQU7l99P9093QyvG16Rc3gMvVdzMzzwQLoqv/12OOWU1Pq2vR1uvNHF3My+laljp9Ld0037f9ordg4XdIB77kmPhbvqKvjkE3jrrdT2trl59zNAzcy+hd6J0Vc3v1qxc7igP/EE3HILzJoFPT3w5JOwbl3WUZlZzjSMbOC47xzH6o8rd8dobRf0pUvTJOi550JjIzz+eLoqv/TSrCMzs5yRxNSxU32FXhFr18LMmekGoeuvT8sUZ85M4+dmZhUwZfQUNny2ga6dXRX5/Nos6OvXpwZb9fWp7e3ChTBpUlrhckhtpsTMKq93HL3t47aKfH7tVa8XX4SpU0FKQy6jR6fGW6+8ktaam5lVyOQxkxl2yDDe7Xy3Ip9fO+vQe3rScMr8+amgv/BCuhr//HM46ig45pisIzSznDtyxJFsm7uNww+tTHfW2rhC37QpdUucPx+uvjrdzj9mTFpfftpp6YlDZmZVUKliDnkv6BHQ0gITJ6ZOiS0t8PDDqTfLypXw/PNplcvwyty1ZWZWTfkdcunsTK1vX34ZzjkHFi2CcePSvoh0R+ioUWkNuplZDuSzoHd1wbRp8MYb8OCDcO21fVevLFiQrtAfecQToWaWG/kr6F98kcbL29vTipaLLuq7PwJefx2ammD27ExCNDOrhHwV9O3b0/rytWvhuef2LuY7dqRnfy5alFa91NVlE6eZWQXkZ1L0yy9TMV+1Cp5+OrW/7RWRHloxaVJqvlVX54lQM8udfBT03mGWFStSc63iXixffZW6KN58M5x6Khx9dHZxmplV0NAv6F1dcP75sHo1LF4Ml122e98HH8DZZ6db+pub0zCMr8zNLKeG9hj61q1pmKW9Pa0pb2rqu/+mm+Cdd6C1FS6+OJsYzcyqZOgW9LffhunTYcsWWLIkFfZeu3bBsGHpRqLOTpgwIbs4zcyqZGgOuaxYAWeemSZCly3bXcwjYN68NATT3Z26KbqYm1mNKKugS7pA0gZJGyXN7Wf/bEkdkl4v/Fw98KEWLFkC552XGmqtXJkabfWaOzeNlTc0pOJuZlZDSg65SKoDFgLnA5uBNZJaI2L9HocujogbKhBjX4cdBpMnp26Jxx67+/3ly+Huu+Gaa+Chh1J7XDOzGlLOFfoUYGNEvBcR3cAzQFOJf1M506enbonFxXz79nTX54knwn33uZibWU0qp6CPAT4s2t5ceG9PMyW1S3peUsOARLcvexbsLVtgxAh47DH3ZjGzmjVQk6J/Bk6IiEnAy8Cf+jtI0m8ktUlq6+joGKBTA+PHp0ZcZ501cJ9pZjbElFPQPwKKr7jHFt77RkR8FhFfFzYfAX7c3wdFREtENEZE47HFQyYHq6MDbrstDbm4L4uZ1bhyCvoaYLykcZKGA5cDrcUHSBpVtDkD+NfAhbgPO3emfi333pvWpJuZ1biSq1wiYpekG4ClQB3waESskzQPaIuIVuBGSTOAXUAnMLuCMacliXPmpPXozz4Lp59e0dOZmQ0FZd0pGhEvAS/t8d7tRa9vBW4d2ND248474amn4K67YNasqp3WzGwwG3p3in76aVqaeOWVcGv1foeYmQ12Q6+XS309rFmT7gb1enMzs28MvYIOcNJJWUdgZjboDL0hFzMz65cLuplZTrigm5nlhAu6mVlOuKCbmeWEC7qZWU64oJuZ5YQLuplZTigyevampA7gg0xOPnDqgU+zDmKQcU76cj725pz0daD5OD4i+u0/nllBzwNJbRHRmHUcg4lz0pfzsTfnpK+BzIeHXMzMcsIF3cwsJ1zQv52WrAMYhJyTvpyPvTknfQ1YPjyGbmaWE75CNzPLCRf0Mki6QNIGSRslze1n/+8krZfULulvko7PIs5qKpWTouNmSgpJuV7VUE4+JP2y8D1ZJ+mpasdYTWX8n/mBpGWSXiv8v7kwizirRdKjkrZKenMf+yXp/kK+2iUd3IOSI8I/+/khPRj7XeBEYDjwT+DkPY45Bzi88Po6YHHWcWedk8JxRwDLgVVAY9ZxZ/wdGQ+8BhxV2P5+1nFnnI8W4LrC65OB97OOu8I5+SlwOvDmPvZfCPwVEHAG8OrBnMdX6KVNATZGxHsR0Q08AzQVHxARyyJiR2FzFTC2yjFWW8mcFNwJ/AHYWc3gMlBOPq4BFkbE5wARsbXKMVZTOfkIYGTh9feAj6sYX9VFxHKgcz+HNAGPR7IKOFLSqAM9jwt6aWOAD4u2Nxfe25c5pN+0eVYyJ4U/GRsi4i/VDCwj5XxHJgATJP1D0ipJF1QtuuorJx93AFdI2gy8BPy2OqENWgdaZ/o1NJ8pOkhJugJoBH6WdSxZknQIcC8wO+NQBpNhpGGXn5P+glsu6ZSI6Mo0quz8CngsIu6R9BPgCUkTI+J/WQc2lPkKvbSPgIai7bGF9/qQ9AvgNmBGRHxdpdiyUionRwATgb9Lep80Jtia44nRcr4jm4HWiPhvRPwbeJtU4POonHzMAZ4FiIiVwAhST5NaVVadKcUFvbQ1wHhJ4yQNBy4HWosPkPQj4CFSMc/z2Giv/eYkIrZFRH1EnBARJ5DmFWZERFs24VZcye8IsIR0dY6ketIQzHvVDLKKysnHJuA8AEk/JBX0jqpGObi0Ar8urHY5A9gWEVsO9EM85FJCROySdAOwlDR7/2hErJM0D2iLiFbgbuC7wHOSADZFxIzMgq6wMnNSM8rMx1JgmqT1QA/w+4j4LLuoK6fMfNwMPCzpJtIE6ewoLPfII0lPk36h1xfmDZqBQwEi4o+keYQLgY3ADuCqgzpPjnNoZlZTPORiZpYTLuhmZjnhgm5mlhMu6GZmOeGCbmaWEy7oZmY54YJuZpYTLuhmZjnxf6ktjjLFHX81AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geeGh4HLc0Xg",
        "colab_type": "text"
      },
      "source": [
        "# ***The model using NN***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3MD1cOJcye2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrkPujj1hlrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "\n",
        "def create_model(dense1=128, dense2=64, dense3=32, dropout_rate=0.4, l1_rate=0.001, l2_rate=0.001, init_std=0.01, lr=0.001):\n",
        "  out_model = Sequential()\n",
        "  \n",
        "  out_model.add(Dense(dense1, activation='relu',\n",
        "                      input_shape=(X_to_train.shape[1],),\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dense(dense1, activation='relu',\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(dense2, activation='relu',\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(dense3, activation='relu',\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  out_model.compile(\n",
        "            optimizer=Adam(learning_rate=lr),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=[METRICS])\n",
        "  \n",
        "  return out_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B8icGb9id1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "63babd42-552d-4207-919a-04f9ed5d01c9"
      },
      "source": [
        "#my_model = create_model(dense1=256, dense2=256, dropout_rate=0.4, l1_rate=1e-4, l2_rate=5e-4, init_std=0.1, lr=0.00008)\n",
        "my_model = create_model(dense1=256, dense2=64, dense3=16, dropout_rate=0.425, l1_rate=5e-4, l2_rate=5e-4, init_std=0.01, lr=0.0000001)\n",
        "#my_model = tf.keras.models.load_model('./best_model.h5')\n",
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 256)               155904    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 240,545\n",
            "Trainable params: 239,873\n",
            "Non-trainable params: 672\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UTsRGUjjzpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4023feef-a03d-4451-8c1a-c94491171af1"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "NB_EPOCH = 2000\n",
        "PATIENCE = 25\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_auc', patience=PATIENCE, verbose=0, mode='max',\n",
        "    baseline=None)\n",
        "\n",
        "best_model_hold = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='./best_model.h5', monitor='val_auc', verbose=1, save_best_only=True,\n",
        "    save_weights_only=False, mode='max')\n",
        "\n",
        "history = my_model.fit(X_to_train, Y_to_train, verbose=0,\n",
        "             batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "             validation_split=0.01, shuffle=True,\n",
        "             callbacks=[early_stop, best_model_hold])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_auc improved from -inf to 0.69593, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00002: val_auc improved from 0.69593 to 0.72392, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00003: val_auc improved from 0.72392 to 0.74232, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00004: val_auc improved from 0.74232 to 0.75332, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00005: val_auc improved from 0.75332 to 0.76131, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00006: val_auc improved from 0.76131 to 0.76751, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00007: val_auc improved from 0.76751 to 0.77188, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00008: val_auc improved from 0.77188 to 0.77643, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00009: val_auc improved from 0.77643 to 0.78053, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00010: val_auc improved from 0.78053 to 0.78484, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00011: val_auc improved from 0.78484 to 0.78870, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00012: val_auc improved from 0.78870 to 0.79245, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00013: val_auc improved from 0.79245 to 0.79454, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00014: val_auc improved from 0.79454 to 0.79766, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00015: val_auc improved from 0.79766 to 0.79980, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00016: val_auc improved from 0.79980 to 0.80247, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00017: val_auc improved from 0.80247 to 0.80421, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00018: val_auc improved from 0.80421 to 0.80645, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00019: val_auc improved from 0.80645 to 0.80755, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00020: val_auc improved from 0.80755 to 0.80941, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00021: val_auc improved from 0.80941 to 0.81027, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00022: val_auc improved from 0.81027 to 0.81198, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00023: val_auc improved from 0.81198 to 0.81252, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00024: val_auc improved from 0.81252 to 0.81375, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00025: val_auc improved from 0.81375 to 0.81469, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00026: val_auc improved from 0.81469 to 0.81574, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00027: val_auc improved from 0.81574 to 0.81665, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00028: val_auc improved from 0.81665 to 0.81736, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00029: val_auc improved from 0.81736 to 0.81818, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00030: val_auc improved from 0.81818 to 0.81916, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00031: val_auc improved from 0.81916 to 0.81960, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00032: val_auc improved from 0.81960 to 0.82024, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00033: val_auc improved from 0.82024 to 0.82118, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00034: val_auc improved from 0.82118 to 0.82185, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00035: val_auc improved from 0.82185 to 0.82223, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00036: val_auc improved from 0.82223 to 0.82288, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00037: val_auc improved from 0.82288 to 0.82338, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00038: val_auc improved from 0.82338 to 0.82403, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00039: val_auc improved from 0.82403 to 0.82460, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00040: val_auc improved from 0.82460 to 0.82544, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00041: val_auc improved from 0.82544 to 0.82597, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00042: val_auc improved from 0.82597 to 0.82646, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00043: val_auc improved from 0.82646 to 0.82716, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00044: val_auc improved from 0.82716 to 0.82741, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00045: val_auc improved from 0.82741 to 0.82812, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00046: val_auc improved from 0.82812 to 0.82859, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00047: val_auc improved from 0.82859 to 0.82908, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00048: val_auc improved from 0.82908 to 0.82968, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00049: val_auc improved from 0.82968 to 0.83007, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00050: val_auc improved from 0.83007 to 0.83025, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00051: val_auc improved from 0.83025 to 0.83118, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00052: val_auc improved from 0.83118 to 0.83161, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00053: val_auc improved from 0.83161 to 0.83247, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00054: val_auc did not improve from 0.83247\n",
            "\n",
            "Epoch 00055: val_auc improved from 0.83247 to 0.83292, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00056: val_auc improved from 0.83292 to 0.83323, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00057: val_auc improved from 0.83323 to 0.83394, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00058: val_auc improved from 0.83394 to 0.83443, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00059: val_auc improved from 0.83443 to 0.83451, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00060: val_auc improved from 0.83451 to 0.83516, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00061: val_auc improved from 0.83516 to 0.83581, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00062: val_auc improved from 0.83581 to 0.83586, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00063: val_auc improved from 0.83586 to 0.83693, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00064: val_auc did not improve from 0.83693\n",
            "\n",
            "Epoch 00065: val_auc improved from 0.83693 to 0.83752, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00066: val_auc improved from 0.83752 to 0.83811, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00067: val_auc did not improve from 0.83811\n",
            "\n",
            "Epoch 00068: val_auc improved from 0.83811 to 0.83833, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00069: val_auc improved from 0.83833 to 0.83873, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00070: val_auc improved from 0.83873 to 0.83915, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00071: val_auc improved from 0.83915 to 0.84001, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00072: val_auc improved from 0.84001 to 0.84039, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00073: val_auc did not improve from 0.84039\n",
            "\n",
            "Epoch 00074: val_auc did not improve from 0.84039\n",
            "\n",
            "Epoch 00075: val_auc improved from 0.84039 to 0.84064, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00076: val_auc improved from 0.84064 to 0.84087, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00077: val_auc improved from 0.84087 to 0.84158, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00078: val_auc improved from 0.84158 to 0.84198, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00079: val_auc improved from 0.84198 to 0.84219, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00080: val_auc improved from 0.84219 to 0.84289, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00081: val_auc did not improve from 0.84289\n",
            "\n",
            "Epoch 00082: val_auc improved from 0.84289 to 0.84289, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00083: val_auc improved from 0.84289 to 0.84295, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00084: val_auc improved from 0.84295 to 0.84390, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00085: val_auc improved from 0.84390 to 0.84430, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00086: val_auc improved from 0.84430 to 0.84458, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00087: val_auc improved from 0.84458 to 0.84513, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00088: val_auc did not improve from 0.84513\n",
            "\n",
            "Epoch 00089: val_auc did not improve from 0.84513\n",
            "\n",
            "Epoch 00090: val_auc did not improve from 0.84513\n",
            "\n",
            "Epoch 00091: val_auc improved from 0.84513 to 0.84537, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00092: val_auc improved from 0.84537 to 0.84574, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00093: val_auc improved from 0.84574 to 0.84588, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00094: val_auc improved from 0.84588 to 0.84628, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00095: val_auc improved from 0.84628 to 0.84630, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00096: val_auc improved from 0.84630 to 0.84683, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00097: val_auc did not improve from 0.84683\n",
            "\n",
            "Epoch 00098: val_auc improved from 0.84683 to 0.84714, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00099: val_auc improved from 0.84714 to 0.84772, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00100: val_auc did not improve from 0.84772\n",
            "\n",
            "Epoch 00101: val_auc did not improve from 0.84772\n",
            "\n",
            "Epoch 00102: val_auc did not improve from 0.84772\n",
            "\n",
            "Epoch 00103: val_auc improved from 0.84772 to 0.84836, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00104: val_auc improved from 0.84836 to 0.84871, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00105: val_auc did not improve from 0.84871\n",
            "\n",
            "Epoch 00106: val_auc did not improve from 0.84871\n",
            "\n",
            "Epoch 00107: val_auc did not improve from 0.84871\n",
            "\n",
            "Epoch 00108: val_auc improved from 0.84871 to 0.84899, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00109: val_auc improved from 0.84899 to 0.84922, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00110: val_auc did not improve from 0.84922\n",
            "\n",
            "Epoch 00111: val_auc did not improve from 0.84922\n",
            "\n",
            "Epoch 00112: val_auc did not improve from 0.84922\n",
            "\n",
            "Epoch 00113: val_auc improved from 0.84922 to 0.84994, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00114: val_auc did not improve from 0.84994\n",
            "\n",
            "Epoch 00115: val_auc improved from 0.84994 to 0.85006, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00116: val_auc did not improve from 0.85006\n",
            "\n",
            "Epoch 00117: val_auc improved from 0.85006 to 0.85049, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00118: val_auc improved from 0.85049 to 0.85063, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00119: val_auc did not improve from 0.85063\n",
            "\n",
            "Epoch 00120: val_auc improved from 0.85063 to 0.85076, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00121: val_auc improved from 0.85076 to 0.85078, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00122: val_auc improved from 0.85078 to 0.85091, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00123: val_auc improved from 0.85091 to 0.85112, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00124: val_auc improved from 0.85112 to 0.85163, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00125: val_auc did not improve from 0.85163\n",
            "\n",
            "Epoch 00126: val_auc did not improve from 0.85163\n",
            "\n",
            "Epoch 00127: val_auc did not improve from 0.85163\n",
            "\n",
            "Epoch 00128: val_auc improved from 0.85163 to 0.85227, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00129: val_auc did not improve from 0.85227\n",
            "\n",
            "Epoch 00130: val_auc did not improve from 0.85227\n",
            "\n",
            "Epoch 00131: val_auc improved from 0.85227 to 0.85263, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00132: val_auc did not improve from 0.85263\n",
            "\n",
            "Epoch 00133: val_auc did not improve from 0.85263\n",
            "\n",
            "Epoch 00134: val_auc did not improve from 0.85263\n",
            "\n",
            "Epoch 00135: val_auc did not improve from 0.85263\n",
            "\n",
            "Epoch 00136: val_auc improved from 0.85263 to 0.85293, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00137: val_auc did not improve from 0.85293\n",
            "\n",
            "Epoch 00138: val_auc improved from 0.85293 to 0.85299, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00139: val_auc improved from 0.85299 to 0.85333, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00140: val_auc did not improve from 0.85333\n",
            "\n",
            "Epoch 00141: val_auc improved from 0.85333 to 0.85350, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00142: val_auc did not improve from 0.85350\n",
            "\n",
            "Epoch 00143: val_auc did not improve from 0.85350\n",
            "\n",
            "Epoch 00144: val_auc did not improve from 0.85350\n",
            "\n",
            "Epoch 00145: val_auc improved from 0.85350 to 0.85381, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00146: val_auc improved from 0.85381 to 0.85399, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00147: val_auc improved from 0.85399 to 0.85401, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00148: val_auc improved from 0.85401 to 0.85433, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00149: val_auc improved from 0.85433 to 0.85483, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00150: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00151: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00152: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00153: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00154: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00155: val_auc improved from 0.85483 to 0.85505, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00156: val_auc improved from 0.85505 to 0.85524, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00157: val_auc did not improve from 0.85524\n",
            "\n",
            "Epoch 00158: val_auc improved from 0.85524 to 0.85532, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00159: val_auc did not improve from 0.85532\n",
            "\n",
            "Epoch 00160: val_auc improved from 0.85532 to 0.85558, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00161: val_auc did not improve from 0.85558\n",
            "\n",
            "Epoch 00162: val_auc did not improve from 0.85558\n",
            "\n",
            "Epoch 00163: val_auc did not improve from 0.85558\n",
            "\n",
            "Epoch 00164: val_auc improved from 0.85558 to 0.85586, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00165: val_auc did not improve from 0.85586\n",
            "\n",
            "Epoch 00166: val_auc did not improve from 0.85586\n",
            "\n",
            "Epoch 00167: val_auc improved from 0.85586 to 0.85588, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00168: val_auc improved from 0.85588 to 0.85592, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00169: val_auc improved from 0.85592 to 0.85601, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00170: val_auc did not improve from 0.85601\n",
            "\n",
            "Epoch 00171: val_auc improved from 0.85601 to 0.85639, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00172: val_auc did not improve from 0.85639\n",
            "\n",
            "Epoch 00173: val_auc improved from 0.85639 to 0.85641, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00174: val_auc did not improve from 0.85641\n",
            "\n",
            "Epoch 00175: val_auc improved from 0.85641 to 0.85653, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00176: val_auc improved from 0.85653 to 0.85653, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00177: val_auc improved from 0.85653 to 0.85691, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00178: val_auc improved from 0.85691 to 0.85724, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00179: val_auc did not improve from 0.85724\n",
            "\n",
            "Epoch 00180: val_auc improved from 0.85724 to 0.85727, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00181: val_auc did not improve from 0.85727\n",
            "\n",
            "Epoch 00182: val_auc improved from 0.85727 to 0.85754, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00183: val_auc did not improve from 0.85754\n",
            "\n",
            "Epoch 00184: val_auc did not improve from 0.85754\n",
            "\n",
            "Epoch 00185: val_auc did not improve from 0.85754\n",
            "\n",
            "Epoch 00186: val_auc improved from 0.85754 to 0.85756, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00187: val_auc improved from 0.85756 to 0.85766, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00188: val_auc did not improve from 0.85766\n",
            "\n",
            "Epoch 00189: val_auc did not improve from 0.85766\n",
            "\n",
            "Epoch 00190: val_auc improved from 0.85766 to 0.85769, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00191: val_auc did not improve from 0.85769\n",
            "\n",
            "Epoch 00192: val_auc improved from 0.85769 to 0.85791, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00193: val_auc did not improve from 0.85791\n",
            "\n",
            "Epoch 00194: val_auc improved from 0.85791 to 0.85811, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00195: val_auc did not improve from 0.85811\n",
            "\n",
            "Epoch 00196: val_auc did not improve from 0.85811\n",
            "\n",
            "Epoch 00197: val_auc improved from 0.85811 to 0.85883, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00198: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00199: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00200: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00201: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00202: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00203: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00204: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00205: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00206: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00207: val_auc improved from 0.85883 to 0.85911, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00208: val_auc did not improve from 0.85911\n",
            "\n",
            "Epoch 00209: val_auc did not improve from 0.85911\n",
            "\n",
            "Epoch 00210: val_auc did not improve from 0.85911\n",
            "\n",
            "Epoch 00211: val_auc improved from 0.85911 to 0.85923, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00212: val_auc improved from 0.85923 to 0.85937, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00213: val_auc improved from 0.85937 to 0.85939, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00214: val_auc did not improve from 0.85939\n",
            "\n",
            "Epoch 00215: val_auc did not improve from 0.85939\n",
            "\n",
            "Epoch 00216: val_auc did not improve from 0.85939\n",
            "\n",
            "Epoch 00217: val_auc improved from 0.85939 to 0.85950, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00218: val_auc improved from 0.85950 to 0.85985, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00219: val_auc did not improve from 0.85985\n",
            "\n",
            "Epoch 00220: val_auc improved from 0.85985 to 0.85994, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00221: val_auc did not improve from 0.85994\n",
            "\n",
            "Epoch 00222: val_auc did not improve from 0.85994\n",
            "\n",
            "Epoch 00223: val_auc did not improve from 0.85994\n",
            "\n",
            "Epoch 00224: val_auc improved from 0.85994 to 0.86014, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00225: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00226: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00227: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00228: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00229: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00230: val_auc improved from 0.86014 to 0.86072, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00231: val_auc did not improve from 0.86072\n",
            "\n",
            "Epoch 00232: val_auc improved from 0.86072 to 0.86081, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00233: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00234: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00235: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00236: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00237: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00238: val_auc improved from 0.86081 to 0.86097, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00239: val_auc improved from 0.86097 to 0.86103, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00240: val_auc did not improve from 0.86103\n",
            "\n",
            "Epoch 00241: val_auc improved from 0.86103 to 0.86111, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00242: val_auc did not improve from 0.86111\n",
            "\n",
            "Epoch 00243: val_auc did not improve from 0.86111\n",
            "\n",
            "Epoch 00244: val_auc improved from 0.86111 to 0.86112, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00245: val_auc did not improve from 0.86112\n",
            "\n",
            "Epoch 00246: val_auc did not improve from 0.86112\n",
            "\n",
            "Epoch 00247: val_auc improved from 0.86112 to 0.86115, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00248: val_auc improved from 0.86115 to 0.86153, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00249: val_auc did not improve from 0.86153\n",
            "\n",
            "Epoch 00250: val_auc improved from 0.86153 to 0.86154, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00251: val_auc did not improve from 0.86154\n",
            "\n",
            "Epoch 00252: val_auc improved from 0.86154 to 0.86166, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00253: val_auc improved from 0.86166 to 0.86169, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00254: val_auc improved from 0.86169 to 0.86187, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00255: val_auc did not improve from 0.86187\n",
            "\n",
            "Epoch 00256: val_auc improved from 0.86187 to 0.86192, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00257: val_auc improved from 0.86192 to 0.86195, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00258: val_auc improved from 0.86195 to 0.86223, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00259: val_auc did not improve from 0.86223\n",
            "\n",
            "Epoch 00260: val_auc improved from 0.86223 to 0.86227, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00261: val_auc did not improve from 0.86227\n",
            "\n",
            "Epoch 00262: val_auc improved from 0.86227 to 0.86245, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00263: val_auc did not improve from 0.86245\n",
            "\n",
            "Epoch 00264: val_auc did not improve from 0.86245\n",
            "\n",
            "Epoch 00265: val_auc improved from 0.86245 to 0.86264, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00266: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00267: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00268: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00269: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00270: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00271: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00272: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00273: val_auc improved from 0.86264 to 0.86292, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00274: val_auc did not improve from 0.86292\n",
            "\n",
            "Epoch 00275: val_auc improved from 0.86292 to 0.86305, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00276: val_auc did not improve from 0.86305\n",
            "\n",
            "Epoch 00277: val_auc improved from 0.86305 to 0.86316, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00278: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00279: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00280: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00281: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00282: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00283: val_auc improved from 0.86316 to 0.86340, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00284: val_auc did not improve from 0.86340\n",
            "\n",
            "Epoch 00285: val_auc did not improve from 0.86340\n",
            "\n",
            "Epoch 00286: val_auc improved from 0.86340 to 0.86353, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00287: val_auc improved from 0.86353 to 0.86386, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00288: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00289: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00290: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00291: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00292: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00293: val_auc improved from 0.86386 to 0.86412, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00294: val_auc did not improve from 0.86412\n",
            "\n",
            "Epoch 00295: val_auc did not improve from 0.86412\n",
            "\n",
            "Epoch 00296: val_auc improved from 0.86412 to 0.86424, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00297: val_auc improved from 0.86424 to 0.86427, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00298: val_auc did not improve from 0.86427\n",
            "\n",
            "Epoch 00299: val_auc improved from 0.86427 to 0.86457, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00300: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00301: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00302: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00303: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00304: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00305: val_auc improved from 0.86457 to 0.86478, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00306: val_auc did not improve from 0.86478\n",
            "\n",
            "Epoch 00307: val_auc improved from 0.86478 to 0.86481, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00308: val_auc improved from 0.86481 to 0.86496, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00309: val_auc improved from 0.86496 to 0.86506, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00310: val_auc did not improve from 0.86506\n",
            "\n",
            "Epoch 00311: val_auc did not improve from 0.86506\n",
            "\n",
            "Epoch 00312: val_auc did not improve from 0.86506\n",
            "\n",
            "Epoch 00313: val_auc did not improve from 0.86506\n",
            "\n",
            "Epoch 00314: val_auc improved from 0.86506 to 0.86524, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00315: val_auc improved from 0.86524 to 0.86530, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00316: val_auc did not improve from 0.86530\n",
            "\n",
            "Epoch 00317: val_auc did not improve from 0.86530\n",
            "\n",
            "Epoch 00318: val_auc improved from 0.86530 to 0.86537, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00319: val_auc did not improve from 0.86537\n",
            "\n",
            "Epoch 00320: val_auc improved from 0.86537 to 0.86574, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00321: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00322: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00323: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00324: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00325: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00326: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00327: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00328: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00329: val_auc improved from 0.86574 to 0.86585, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00330: val_auc did not improve from 0.86585\n",
            "\n",
            "Epoch 00331: val_auc improved from 0.86585 to 0.86624, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00332: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00333: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00334: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00335: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00336: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00337: val_auc improved from 0.86624 to 0.86635, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00338: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00339: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00340: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00341: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00342: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00343: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00344: val_auc improved from 0.86635 to 0.86657, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00345: val_auc did not improve from 0.86657\n",
            "\n",
            "Epoch 00346: val_auc did not improve from 0.86657\n",
            "\n",
            "Epoch 00347: val_auc did not improve from 0.86657\n",
            "\n",
            "Epoch 00348: val_auc improved from 0.86657 to 0.86679, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00349: val_auc improved from 0.86679 to 0.86683, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00350: val_auc did not improve from 0.86683\n",
            "\n",
            "Epoch 00351: val_auc did not improve from 0.86683\n",
            "\n",
            "Epoch 00352: val_auc did not improve from 0.86683\n",
            "\n",
            "Epoch 00353: val_auc improved from 0.86683 to 0.86713, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00354: val_auc did not improve from 0.86713\n",
            "\n",
            "Epoch 00355: val_auc did not improve from 0.86713\n",
            "\n",
            "Epoch 00356: val_auc improved from 0.86713 to 0.86723, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00357: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00358: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00359: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00360: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00361: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00362: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00363: val_auc improved from 0.86723 to 0.86740, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00364: val_auc did not improve from 0.86740\n",
            "\n",
            "Epoch 00365: val_auc did not improve from 0.86740\n",
            "\n",
            "Epoch 00366: val_auc did not improve from 0.86740\n",
            "\n",
            "Epoch 00367: val_auc improved from 0.86740 to 0.86772, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00368: val_auc did not improve from 0.86772\n",
            "\n",
            "Epoch 00369: val_auc did not improve from 0.86772\n",
            "\n",
            "Epoch 00370: val_auc improved from 0.86772 to 0.86778, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00371: val_auc did not improve from 0.86778\n",
            "\n",
            "Epoch 00372: val_auc did not improve from 0.86778\n",
            "\n",
            "Epoch 00373: val_auc did not improve from 0.86778\n",
            "\n",
            "Epoch 00374: val_auc improved from 0.86778 to 0.86786, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00375: val_auc did not improve from 0.86786\n",
            "\n",
            "Epoch 00376: val_auc did not improve from 0.86786\n",
            "\n",
            "Epoch 00377: val_auc improved from 0.86786 to 0.86793, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00378: val_auc improved from 0.86793 to 0.86821, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00379: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00380: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00381: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00382: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00383: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00384: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00385: val_auc improved from 0.86821 to 0.86884, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00386: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00387: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00388: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00389: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00390: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00391: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00392: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00393: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00394: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00395: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00396: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00397: val_auc improved from 0.86884 to 0.86885, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00398: val_auc improved from 0.86885 to 0.86890, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00399: val_auc did not improve from 0.86890\n",
            "\n",
            "Epoch 00400: val_auc did not improve from 0.86890\n",
            "\n",
            "Epoch 00401: val_auc improved from 0.86890 to 0.86904, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00402: val_auc improved from 0.86904 to 0.86904, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00403: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00404: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00405: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00406: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00407: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00408: val_auc improved from 0.86904 to 0.86909, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00409: val_auc did not improve from 0.86909\n",
            "\n",
            "Epoch 00410: val_auc improved from 0.86909 to 0.86941, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00411: val_auc did not improve from 0.86941\n",
            "\n",
            "Epoch 00412: val_auc did not improve from 0.86941\n",
            "\n",
            "Epoch 00413: val_auc improved from 0.86941 to 0.86963, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00414: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00415: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00416: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00417: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00418: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00419: val_auc improved from 0.86963 to 0.86989, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00420: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00421: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00422: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00423: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00424: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00425: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00426: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00427: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00428: val_auc improved from 0.86989 to 0.87014, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00429: val_auc did not improve from 0.87014\n",
            "\n",
            "Epoch 00430: val_auc did not improve from 0.87014\n",
            "\n",
            "Epoch 00431: val_auc improved from 0.87014 to 0.87014, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00432: val_auc did not improve from 0.87014\n",
            "\n",
            "Epoch 00433: val_auc improved from 0.87014 to 0.87034, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00434: val_auc improved from 0.87034 to 0.87064, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00435: val_auc did not improve from 0.87064\n",
            "\n",
            "Epoch 00436: val_auc improved from 0.87064 to 0.87069, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00437: val_auc did not improve from 0.87069\n",
            "\n",
            "Epoch 00438: val_auc did not improve from 0.87069\n",
            "\n",
            "Epoch 00439: val_auc improved from 0.87069 to 0.87070, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00440: val_auc improved from 0.87070 to 0.87089, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00441: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00442: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00443: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00444: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00445: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00446: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00447: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00448: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00449: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00450: val_auc improved from 0.87089 to 0.87098, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00451: val_auc did not improve from 0.87098\n",
            "\n",
            "Epoch 00452: val_auc improved from 0.87098 to 0.87132, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00453: val_auc did not improve from 0.87132\n",
            "\n",
            "Epoch 00454: val_auc did not improve from 0.87132\n",
            "\n",
            "Epoch 00455: val_auc did not improve from 0.87132\n",
            "\n",
            "Epoch 00456: val_auc did not improve from 0.87132\n",
            "\n",
            "Epoch 00457: val_auc improved from 0.87132 to 0.87145, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00458: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00459: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00460: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00461: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00462: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00463: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00464: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00465: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00466: val_auc improved from 0.87145 to 0.87151, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00467: val_auc did not improve from 0.87151\n",
            "\n",
            "Epoch 00468: val_auc improved from 0.87151 to 0.87164, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00469: val_auc did not improve from 0.87164\n",
            "\n",
            "Epoch 00470: val_auc did not improve from 0.87164\n",
            "\n",
            "Epoch 00471: val_auc improved from 0.87164 to 0.87173, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00472: val_auc improved from 0.87173 to 0.87201, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00473: val_auc did not improve from 0.87201\n",
            "\n",
            "Epoch 00474: val_auc did not improve from 0.87201\n",
            "\n",
            "Epoch 00475: val_auc improved from 0.87201 to 0.87208, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00476: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00477: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00478: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00479: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00480: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00481: val_auc improved from 0.87208 to 0.87217, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00482: val_auc improved from 0.87217 to 0.87218, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00483: val_auc did not improve from 0.87218\n",
            "\n",
            "Epoch 00484: val_auc did not improve from 0.87218\n",
            "\n",
            "Epoch 00485: val_auc did not improve from 0.87218\n",
            "\n",
            "Epoch 00486: val_auc improved from 0.87218 to 0.87228, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00487: val_auc did not improve from 0.87228\n",
            "\n",
            "Epoch 00488: val_auc did not improve from 0.87228\n",
            "\n",
            "Epoch 00489: val_auc improved from 0.87228 to 0.87251, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00490: val_auc improved from 0.87251 to 0.87290, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00491: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00492: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00493: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00494: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00495: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00496: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00497: val_auc improved from 0.87290 to 0.87312, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00498: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00499: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00500: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00501: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00502: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00503: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00504: val_auc improved from 0.87312 to 0.87319, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00505: val_auc did not improve from 0.87319\n",
            "\n",
            "Epoch 00506: val_auc improved from 0.87319 to 0.87369, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00507: val_auc did not improve from 0.87369\n",
            "\n",
            "Epoch 00508: val_auc improved from 0.87369 to 0.87381, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00509: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00510: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00511: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00512: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00513: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00514: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00515: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00516: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00517: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00518: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00519: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00520: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00521: val_auc improved from 0.87381 to 0.87400, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00522: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00523: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00524: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00525: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00526: val_auc improved from 0.87400 to 0.87400, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00527: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00528: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00529: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00530: val_auc improved from 0.87400 to 0.87414, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00531: val_auc did not improve from 0.87414\n",
            "\n",
            "Epoch 00532: val_auc did not improve from 0.87414\n",
            "\n",
            "Epoch 00533: val_auc did not improve from 0.87414\n",
            "\n",
            "Epoch 00534: val_auc improved from 0.87414 to 0.87452, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00535: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00536: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00537: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00538: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00539: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00540: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00541: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00542: val_auc improved from 0.87452 to 0.87469, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00543: val_auc did not improve from 0.87469\n",
            "\n",
            "Epoch 00544: val_auc did not improve from 0.87469\n",
            "\n",
            "Epoch 00545: val_auc improved from 0.87469 to 0.87480, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00546: val_auc did not improve from 0.87480\n",
            "\n",
            "Epoch 00547: val_auc improved from 0.87480 to 0.87499, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00548: val_auc did not improve from 0.87499\n",
            "\n",
            "Epoch 00549: val_auc improved from 0.87499 to 0.87518, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00550: val_auc did not improve from 0.87518\n",
            "\n",
            "Epoch 00551: val_auc did not improve from 0.87518\n",
            "\n",
            "Epoch 00552: val_auc improved from 0.87518 to 0.87538, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00553: val_auc did not improve from 0.87538\n",
            "\n",
            "Epoch 00554: val_auc did not improve from 0.87538\n",
            "\n",
            "Epoch 00555: val_auc did not improve from 0.87538\n",
            "\n",
            "Epoch 00556: val_auc did not improve from 0.87538\n",
            "\n",
            "Epoch 00557: val_auc improved from 0.87538 to 0.87542, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00558: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00559: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00560: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00561: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00562: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00563: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00564: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00565: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00566: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00567: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00568: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00569: val_auc improved from 0.87542 to 0.87572, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00570: val_auc did not improve from 0.87572\n",
            "\n",
            "Epoch 00571: val_auc improved from 0.87572 to 0.87573, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00572: val_auc did not improve from 0.87573\n",
            "\n",
            "Epoch 00573: val_auc did not improve from 0.87573\n",
            "\n",
            "Epoch 00574: val_auc did not improve from 0.87573\n",
            "\n",
            "Epoch 00575: val_auc did not improve from 0.87573\n",
            "\n",
            "Epoch 00576: val_auc improved from 0.87573 to 0.87614, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00577: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00578: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00579: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00580: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00581: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00582: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00583: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00584: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00585: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00586: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00587: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00588: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00589: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00590: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00591: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00592: val_auc improved from 0.87614 to 0.87620, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00593: val_auc improved from 0.87620 to 0.87650, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00594: val_auc did not improve from 0.87650\n",
            "\n",
            "Epoch 00595: val_auc improved from 0.87650 to 0.87674, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00596: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00597: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00598: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00599: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00600: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00601: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00602: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00603: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00604: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00605: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00606: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00607: val_auc improved from 0.87674 to 0.87710, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00608: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00609: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00610: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00611: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00612: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00613: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00614: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00615: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00616: val_auc improved from 0.87710 to 0.87724, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00617: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00618: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00619: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00620: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00621: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00622: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00623: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00624: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00625: val_auc improved from 0.87724 to 0.87724, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00626: val_auc improved from 0.87724 to 0.87741, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00627: val_auc did not improve from 0.87741\n",
            "\n",
            "Epoch 00628: val_auc improved from 0.87741 to 0.87765, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00629: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00630: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00631: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00632: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00633: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00634: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00635: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00636: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00637: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00638: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00639: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00640: val_auc improved from 0.87765 to 0.87799, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00641: val_auc did not improve from 0.87799\n",
            "\n",
            "Epoch 00642: val_auc improved from 0.87799 to 0.87814, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00643: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00644: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00645: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00646: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00647: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00648: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00649: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00650: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00651: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00652: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00653: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00654: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00655: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00656: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00657: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00658: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00659: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00660: val_auc improved from 0.87814 to 0.87814, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00661: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00662: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00663: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00664: val_auc improved from 0.87814 to 0.87820, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00665: val_auc did not improve from 0.87820\n",
            "\n",
            "Epoch 00666: val_auc improved from 0.87820 to 0.87826, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00667: val_auc did not improve from 0.87826\n",
            "\n",
            "Epoch 00668: val_auc did not improve from 0.87826\n",
            "\n",
            "Epoch 00669: val_auc improved from 0.87826 to 0.87827, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00670: val_auc improved from 0.87827 to 0.87849, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00671: val_auc improved from 0.87849 to 0.87919, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00672: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00673: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00674: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00675: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00676: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00677: val_auc improved from 0.87919 to 0.87941, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00678: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00679: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00680: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00681: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00682: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00683: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00684: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00685: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00686: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00687: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00688: val_auc improved from 0.87941 to 0.87942, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00689: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00690: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00691: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00692: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00693: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00694: val_auc improved from 0.87942 to 0.87950, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00695: val_auc did not improve from 0.87950\n",
            "\n",
            "Epoch 00696: val_auc improved from 0.87950 to 0.87950, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00697: val_auc did not improve from 0.87950\n",
            "\n",
            "Epoch 00698: val_auc improved from 0.87950 to 0.87956, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00699: val_auc did not improve from 0.87956\n",
            "\n",
            "Epoch 00700: val_auc improved from 0.87956 to 0.87964, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00701: val_auc did not improve from 0.87964\n",
            "\n",
            "Epoch 00702: val_auc did not improve from 0.87964\n",
            "\n",
            "Epoch 00703: val_auc improved from 0.87964 to 0.87978, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00704: val_auc did not improve from 0.87978\n",
            "\n",
            "Epoch 00705: val_auc did not improve from 0.87978\n",
            "\n",
            "Epoch 00706: val_auc did not improve from 0.87978\n",
            "\n",
            "Epoch 00707: val_auc improved from 0.87978 to 0.88005, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00708: val_auc did not improve from 0.88005\n",
            "\n",
            "Epoch 00709: val_auc did not improve from 0.88005\n",
            "\n",
            "Epoch 00710: val_auc improved from 0.88005 to 0.88028, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00711: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00712: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00713: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00714: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00715: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00716: val_auc improved from 0.88028 to 0.88069, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00717: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00718: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00719: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00720: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00721: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00722: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00723: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00724: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00725: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00726: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00727: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00728: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00729: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00730: val_auc improved from 0.88069 to 0.88075, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00731: val_auc did not improve from 0.88075\n",
            "\n",
            "Epoch 00732: val_auc improved from 0.88075 to 0.88079, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00733: val_auc did not improve from 0.88079\n",
            "\n",
            "Epoch 00734: val_auc did not improve from 0.88079\n",
            "\n",
            "Epoch 00735: val_auc did not improve from 0.88079\n",
            "\n",
            "Epoch 00736: val_auc did not improve from 0.88079\n",
            "\n",
            "Epoch 00737: val_auc improved from 0.88079 to 0.88087, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00738: val_auc did not improve from 0.88087\n",
            "\n",
            "Epoch 00739: val_auc improved from 0.88087 to 0.88106, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00740: val_auc did not improve from 0.88106\n",
            "\n",
            "Epoch 00741: val_auc did not improve from 0.88106\n",
            "\n",
            "Epoch 00742: val_auc did not improve from 0.88106\n",
            "\n",
            "Epoch 00743: val_auc improved from 0.88106 to 0.88125, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00744: val_auc did not improve from 0.88125\n",
            "\n",
            "Epoch 00745: val_auc did not improve from 0.88125\n",
            "\n",
            "Epoch 00746: val_auc did not improve from 0.88125\n",
            "\n",
            "Epoch 00747: val_auc did not improve from 0.88125\n",
            "\n",
            "Epoch 00748: val_auc improved from 0.88125 to 0.88130, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00749: val_auc improved from 0.88130 to 0.88183, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00750: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00751: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00752: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00753: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00754: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00755: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00756: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00757: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00758: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00759: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00760: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00761: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00762: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00763: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00764: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00765: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00766: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00767: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00768: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00769: val_auc improved from 0.88183 to 0.88199, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00770: val_auc did not improve from 0.88199\n",
            "\n",
            "Epoch 00771: val_auc did not improve from 0.88199\n",
            "\n",
            "Epoch 00772: val_auc did not improve from 0.88199\n",
            "\n",
            "Epoch 00773: val_auc did not improve from 0.88199\n",
            "\n",
            "Epoch 00774: val_auc improved from 0.88199 to 0.88234, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00775: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00776: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00777: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00778: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00779: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00780: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00781: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00782: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00783: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00784: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00785: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00786: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00787: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00788: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00789: val_auc improved from 0.88234 to 0.88247, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00790: val_auc did not improve from 0.88247\n",
            "\n",
            "Epoch 00791: val_auc did not improve from 0.88247\n",
            "\n",
            "Epoch 00792: val_auc did not improve from 0.88247\n",
            "\n",
            "Epoch 00793: val_auc improved from 0.88247 to 0.88274, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00794: val_auc did not improve from 0.88274\n",
            "\n",
            "Epoch 00795: val_auc did not improve from 0.88274\n",
            "\n",
            "Epoch 00796: val_auc did not improve from 0.88274\n",
            "\n",
            "Epoch 00797: val_auc improved from 0.88274 to 0.88280, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00798: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00799: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00800: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00801: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00802: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00803: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00804: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00805: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00806: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00807: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00808: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00809: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00810: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00811: val_auc improved from 0.88280 to 0.88295, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00812: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00813: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00814: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00815: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00816: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00817: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00818: val_auc improved from 0.88295 to 0.88336, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00819: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00820: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00821: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00822: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00823: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00824: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00825: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00826: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00827: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00828: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00829: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00830: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00831: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00832: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00833: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00834: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00835: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00836: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00837: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00838: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00839: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00840: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00841: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00842: val_auc improved from 0.88336 to 0.88399, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00843: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00844: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00845: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00846: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00847: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00848: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00849: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00850: val_auc improved from 0.88399 to 0.88408, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00851: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00852: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00853: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00854: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00855: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00856: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00857: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00858: val_auc improved from 0.88408 to 0.88409, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00859: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00860: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00861: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00862: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00863: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00864: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00865: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00866: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00867: val_auc improved from 0.88409 to 0.88434, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00868: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00869: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00870: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00871: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00872: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00873: val_auc did not improve from 0.88434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsIE6_stkBAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_metrics(history):\n",
        "  metrics =  ['loss', 'auc', 'precision', 'recall']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1) \n",
        "    plt.plot(history.epoch,  history.history[metric], color='b', label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color='b', linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "plot_metrics(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ9tGRoYmd4y",
        "colab_type": "text"
      },
      "source": [
        "**F1 validation (From https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKjbrzEe2ISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model weights to drive\n",
        "!cp -r best_model.h5 '/content/gdrive/My Drive/Kaggle/best_model_20200828_METRICS.h5'\n",
        "\n",
        "#new_model = tf.keras.models.load_model('./best_model.h5', custom_objects={'LeakyReLU': tf.keras.layers.LeakyReLU(alpha=0.3)})\n",
        "new_model = tf.keras.models.load_model('./best_model.h5')\n",
        "#new_model = tf.keras.models.load_model('/content/gdrive/My Drive/Kaggle/best_model_20200816_METRICS.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMQtd0IsFspQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision_cal(y_pred, y_ref):\n",
        "  pre = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    if true_pos == len(indices_positive):\n",
        "      false_pos = 0\n",
        "    else:\n",
        "      false_pos = len(indices_positive) - true_pos\n",
        "\n",
        "    pre = true_pos/(true_pos + false_pos)\n",
        "  return pre\n",
        "\n",
        "def recall_cal(y_pred, y_ref):\n",
        "  recall = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    fals_neg = np.sum(y_ref[np.argwhere(y_pred == 0)])\n",
        "       \n",
        "    recall = true_pos/(true_pos + fals_neg)\n",
        "\n",
        "  return recall\n",
        "\n",
        "def F1_score(model, X_test, y_ref, test_size, threshold=0.5):\n",
        "  test_size = test_size\n",
        "  y_pred = (model.predict(X_test, batch_size=128)>threshold).astype(int)\n",
        "  y_pred = np.squeeze(y_pred, axis=1)\n",
        " \n",
        "  precision = precision_cal(y_pred, y_ref)\n",
        "  recall = recall_cal(y_pred, y_ref)\n",
        "\n",
        "  return precision, recall, 2*precision*recall/(precision+recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIe0Q-5JmbVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre = []\n",
        "re = []\n",
        "f1 = []\n",
        "\n",
        "pre_train = []\n",
        "re_train = []\n",
        "f1_train = []\n",
        "\n",
        "threshold_value = []\n",
        "indices = np.random.randint(0, len(X_to_train), size=(len(Y_test),))\n",
        "\n",
        "for i in range(90):\n",
        "  threshold_value.append(0.1+i*0.01)\n",
        "  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_test, Y_test, test_size=len(Y_test), threshold=threshold_value[-1])\n",
        "  \n",
        "  pre.append(temp_pre)\n",
        "  re.append(temp_re)\n",
        "  f1.append(temp_f1)\n",
        "\n",
        "  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_to_train[indices], Y_to_train[indices], test_size=len(Y_to_train[indices]), threshold=threshold_value[-1])\n",
        "\n",
        "  pre_train.append(temp_pre)\n",
        "  re_train.append(temp_re)\n",
        "  f1_train.append(temp_f1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CP4zuNU6WUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "b60eda78-a2c3-4552-c6ba-42dbf9c9113a"
      },
      "source": [
        "plt.plot(threshold_value, f1, 'b')\n",
        "plt.plot(threshold_value, pre, 'r')\n",
        "plt.plot(threshold_value, re, 'g')\n",
        "\n",
        "plt.plot(threshold_value, f1_train, '--b')\n",
        "plt.plot(threshold_value, pre_train, '--r')\n",
        "plt.plot(threshold_value, re_train, '--g')\n",
        "\n",
        "max_f1_indices = np.where(f1==np.max(f1))[0][0]\n",
        "max_f1_train_indices = np.where(f1_train==np.max(f1_train))[0][0]\n",
        "print(f1[max_f1_indices], f1[max_f1_indices-1], f1[max_f1_indices+1], threshold_value[max_f1_indices])\n",
        "print(f1_train[max_f1_train_indices], f1_train[max_f1_train_indices-1], f1_train[max_f1_train_indices+1], threshold_value[max_f1_train_indices])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8190789473684211 0.8166259168704157 0.8129139072847682 0.28\n",
            "0.835978835978836 0.8344947735191638 0.8294849023090586 0.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd1xW5fvH3wcQcIt7ghsHau6RmjkSzTRXjrRcWZlatm3pz76ZaZmlpilW2jJXjtyiZuLee4J7o4Ky4bl+f1wiqAgoG+7363Ve8DznPPe5D+NzrnPd17BEBIPBYDBkfOzSegIGg8FgSB6MoBsMBkMmwQi6wWAwZBKMoBsMBkMmwQi6wWAwZBIc0urEBQsWlNKlS6fV6Q0GgyFDsnPnzmsiUiiufWkm6KVLl2bHjh1pdXqDwWDIkFiWdfph+4zLxWAwGDIJRtANBoMhk2AE3WAwGDIJRtANBoMhk2AE3WAwGDIJCQq6ZVk/WZZ1xbKsAw/Zb1mW9b1lWScsy9pnWVat5J+mwWAwGBIiMRb6L4BnPPvbABXubAOBKUmflsFgMBgelQTj0EVkg2VZpeM5pAMwS7QO7xbLsvJZllVMRC4m0xwNBoMhfXL8OPz6673v3bwJ+fLp91euwKFD9+4vVAg+/BDq1k326SRHYlEJ4Gys1+fuvPeAoFuWNRC14nF1dU2GUxsMhgzB+fPw77+waRMEB4ObG4wYofv+9z84fSdXxrL0a8WK8O67+v3IkXD5su6L3jw84LXXdP9nn0Fg4L37a9aEXr10/6hREBEB9vYx49euDe3a6fdjxoCd3b1brVrQtKl+zssr5v3bt2HpUhgyBDp0AF9fnX80sftLWNa9r2PTqlW6FfREIyLTgGkAderUMZ01DIbkQkRFLzQ0RtQKFwZnZwgJgRs39L1oYbIstSIdHCA8XI+Be49xdtavNlvMvmhBvJ+QENi2Df77D3x8dB7r1um+nj3hzz/1+9y59bweHjGf9fGBffvuFb8GDWK+X7UKTpzQ/dHbM8/ECPrcuXDxos4zen+XLjGC/u23EBBw7/ivvKKCLgLDhz94PW+/rYIeGgqDBt27r3BhWLQILlzQeZcsCWfPxsy7c2fo1AnKlo37Z5WCWInpWHTH5fKPiHjEse9HYL2I/Hnn9VGgWUIulzp16ohJ/TcYHpPQUBWwHDlg/Xp48UUVmNisXQtPP61i2rPng2Ns26ZW4vTpMHDgg/sPH4ZKlWD8eHjnHX3PstTStbNT67RECRg9Wq3kqCg9xsMDypWDhQv19R9/wKVL0KwZ1Kihn09OIiNh507w9tYngJCQe6312DciOzs9v709ZMsWcy2xb3TRN7PcucHRUd0q//6rN8z7yZlTre1nn4W2baF48eS9tjiwLGuniNSJa19yWOiLgcGWZc0G6gMBxn9uMNxHYKB+tbdXqzhaVB5m8QYEqGgXKaKP+YMHq9CA+mR37YLJk9XSdHVVsaxXD/LkibFE3d31a9268OOP+r7NFmPJRrs9GzRQ0Y5tAdtsaokCNGwI//d/KtjRn4+Kgly5YsYfPlzP/+STkD//vdcS180kKURE6PX/+69uGzfG/HyrVtUngNjXEv3ziD336C0yUreIiHv3h4dDWJj+DlxcoGVLaN0amjfXn3H0511cwMkpea8vCSRooVuW9SfQDCgIXAZGANkARGSqZVkWMAmNhAkG+opIgqa3sdANmQ6bTd0M69fDjh1qpU6apPuKFVMrNTbdu8e4IooXh6CgGCvxxg14802YMAGuX1efbrTglC2rIvvCC+oLzgxERsLmzSqksW960ZZzYKC6Zv77T48LCtLPubvrzaxFC/1aKM4ihI9PtD4+7MabBiTJQheRHgnsF+CNx5ybwZA5mDEDvvpKH8/t7dVSrBPrf27kSLW0bTYVr6goqFIlZv9LL6lFGC3aRYvqozyoxXvqVGpeTeoREgK//ALjxoGfX/zHWhZUqwZ9+qh/u2lT/TmlJOlIyBNDmpXPNRgyJFFRcPSoPvLv3Kn+4+zZ9b2CBTVy4/nn1bcam1dfjX/cMWNSbs7JTUQE7N+vPuVo15GDg7oenJ3V73zyJGzfrpufn74Xe7+Tk/qwt2zR0L769eHLL/VJJtoVEtsF4uSkrp3ocEBDnBhBN2RtbLYY3/T9hIXpVycnXWD85BPYu1fD7kCFvH9/XQQcPVpFLaMhou6daEF2cFAB3r9fIzguXYpZSIyM1OvftUt9ywlhZ6dPIR4eKsqhofozDQ/Xp5XwcBXyd95RazuDWcPpkQz4F2gwJJHQUJg/XxcKe/bU8Lfdu1Vcoi1Oe3sV7rlz1eJ2dlaLcuBA9WfXrKkRINEinlpifuuWzivaKnZw0Hlly/bgjSkiQp8c9u/XsD87OxVtR0c4c0aFefduTYSJC8vSp45oKxnUlTRokC6AurrG7IuMjFlEDAvTUL6aNR98UjGkKEbQDRmPiAh9pL94UR/Ba9bU9y9cUGGxt4dr19SazJ4dunbV/a+8ou9v2KALjeXKqUCBLqa9806MOEVHcZQvr/sbNdKIitTm1CkN/9u+XRdajx17+LH29irW0QIfGKg/q7hwcoLq1aFbN11YtNlirOdSpdRXXbWqEeQMRqLi0FMCE+WSBbHZNAHjyBH1mzo7q7A8+6yKkZ8f+PvHpEsfOqTCGx3P/Pnn8NdfKmrRQuXhoRYoaOTHli33nrNRI42OAE1GuXhRhWrgQI2KeJi75VG5elVvIPv26UJf9uwaI549+4OWdLQP2dHxwS3at/zvv5qhuHq1ukVKltRF1tq1dZH0/pC7iAgV49hfc+dWYa5WTUXbslS0w8Igb149jyHDkdJx6AZD4vjwQ41muJ9ocR43DqbEqu1WrNi9YXmBgWpVP/ccVK6slqSzc8z+jz/WhbqoKI0VrlEDKlSI2b9qVeLmKQJr1qglH72Q5+ysAp0zp27+/nDgQIyv+WIKpF64umrCzssvQ5kyyTOmo6MKvSFTYix0Q8ohon7qRo308X7zZrViK1dWsY5O3ogW7YMHNfvQxUUX0+5PUEkN1q1TEd24MeFjnZxiFv2eeEJvIDVqqPUbHKxbSEjclnT0tUe/jnZ3RH9fsaLGVid3VqUhwxOfhW4E3ZC8iKgv+/BhmDgRFi/WLMeJE9N2XjabLgQeOKAun6NHdTt/PibCIzJS5128uFr7/furoIaExGxBQbrlzq3+9YwY2WLI0BiXiyFluXAhpobFiy/GZD86Omqm45AhqTuf06fVl37smG5Hj6o/Pjq7EDR6w91dI1uiU70jIjRe/NVX73Xl5M5t3BSGDIERdEP8iKgYliqlfulr11Qsoxctd+zQrxcvat2Rnj2hcWN1q1SrpsKZ0oSHq6tm8WKYN08jQqIpVUrdF/366WKoh4eGGxYokPLzMhhSGSPohgcRUVGcM0cF8vRpjbpo2hRWrowpS1q8uIpk//5qjUNMjenkJiwsxk0SbXmfOKFzu3AhpuZGnTqagt+6tS6I5siRMvMxGNIhRtAN9+Lrq+F8Z89qWNszz8Cnn8bUr27WTEuUVq6c9DTs4GCNs/b11e3kSf0aFKThfs7O6vs+ckRrpEQnt4CG8ZUvr/VOXF2hdGktFVu6dNLmZDBkYIygZ2UCAtTiXrJExXHECO0k06SJCnmHDg+KdokSuj0ugYF6g5gz58Hqg7lyaVhi7tx6XGioWt6VKmnDgqpV9UZSvrxJeDEY4sAIelYhMFB94ABDh6qQnzypVm+BAppFCRrV8fvvyX9+Efj7b10gvXhRMxQ9PLQUbJkyKuQFC5p6HgZDEjCCnpk5eRKmToXlyzXj8vx5FUwnJ12wfOEF9TU3bJi0eGcRrQmybJla/fny6ZYtmyb6XLyoMeYbNmi89sKFKdJP0WDI6hhBz4wcOaIdZubMUaF+6imtIR0ermIeV7ZmYonuXXnkiG67d2vT3OibRXQPy9jkz68LqF9/rU0bTOy2wZAimP+szIKI+pyzZ4dz5+Cff7TY1LBhmpWZFPz8tHzs2rWaSRk7zT13bl2YfO457alYuLBGpAQE6NfChdNViy6DITNjBD0jcu2atjZzdNTFQZtNu740b64dzlu0UFHPm/fxxg8PhxUr1M8e7WsHjTN/+ml10VSurIuVJUo8WODKySmmH6XBYEg1jKBnRAoU0HC/mTNj3vPw0BrVoK6PxxXz4GCtfrh+vcZwP/20uklatlQBN4uWBkO6xQh6RuLUKXVjuLvDzz/rgmdwsLpaihVLutgGB6vrZMMGmD4devc27hKDIQORqGLQlmV5WpZ11LKsE5ZlfRjHfjfLsrwty9pnWdZ6y7JKJv9UszjnzqlLpWNHDTWMXoCMXnBMqpiHhGhnnnXr1PIfMMCIucGQwUhQ0C3LsgcmA22AKkAPy7Kq3HfY18AsEakOjAK+TO6JZlkiI+Gnn9Rv7e+vYpucJVWjotRP3rq11gD/+eeY1H6DwZChSIzLpR5wQkR8ASzLmg10AA7FOqYK8Pad79cBC5NzklkWf38V8uPH1T/+999aqyQ5OHkSfv1VBfzMGbX0f/kFXnopecY3GAypTmJcLiWAs7Fen7vzXmz2Ap3ufN8RyG1Z1gPl7CzLGmhZ1g7LsnZcvXr1ceabNbh1S78WKKAhgYsWaYXDxxVzEb05HDyo5Wzr1dP0+VGj1B//119a4MqIucGQoUmuRdF3gUmWZfUBNgDngaj7DxKRacA00AYXj3uysMgwnBwyoX83IkKTfr7+WqsdlisHkycn/vP+/vrZDRt0gTMoCG7f1n6XkZExx9WsCWPHavq9q2vyX4fBYEgTEiPo54FSsV6XvPPeXUTkAncsdMuycgGdReRmck3yfjrN6YSTvRNjW42lfP7yKXWa1OHsWbWSw8Njqgl26aKFqhJLQIDGn48frwLeuLEKdXQPzMKFNYa8SBEVc3f3lLkWg8GQpiRG0LcDFSzLKoMKeXegZ+wDLMsqCFwXERswHPgpuScajU1sNCrZiC83fsk/x/5hcL3BfNr0U1yyu6TUKVMGm00TcvLkgTfe0CShbNnUHdK2beLGEIE//tA4cX9/6NxZU/6rVk3ZuRsMhvSJiCS4AW2BY8BJ4OM7740C2t/5vgtw/M4xXoBTQmPWrl1bHhebzSYXAi/IgEUDxBppSf6v8svG0xsfe7xUJzBQpF49kT/+ePwxzp0TaddOBEQaNBDZuTP55mcwGNItwA55iK4myocuIsuAZfe991ms7+cB85J4b0kUy44vY/R/o/Fq78X09tMZUn8In2/4HI/C2oDBP9if/NnzY6XXjMbISPVd79yZ+K72EREwfDjs3atWuYh+PjxcXS1Dhpju8AaDIXGJRemJkIgQDl09xBNTn+DL/76kcsHKzO06l7zOeYmyRdFsZjNa/tqSPZf2pPVUH+TGDS1Zu3w5/PCDxn4nRHi4fuabb9RXHhKi7z3zDOzbB2+9ZcTcYDAoDzPdU3pLisvl4q2L0mVOF2EkUnNqTVl6bKlERkVKRFSETNo6SQp8VUCskZb0W9hPrgdff+zzJCsBASJubiIODiLffpu4z4SGxrhVJk5M0ekZDIaMAfG4XCyRx44eTBJ16tSRHTt2JGmMBYcXMHjZYC7evkjJPCXp90Q/Xqn9Crkcc/HFhi/4but3lMtfjjW911AiTxLapiUXY8ZoJcTENHcICtJolxUrtGbLq6+m/PwMBkO6x7KsnSISZ1JKhhZ0gPCocJYcXYLXbi9WnliJS3YXNvffTMUCFdlwegMTtkzgz85/pk3cugh89hm0awf16yf+c97e2hLu1Cnw8oJ+/VJsigaDIWMRn6BnOB/6/TjaO9K5SmeWv7icg4MOYm/Z8+wfz+If7E9Tt6Ys6LYAJwcn/IP9mbh1IgGhAakzMRF491343/+05VpiCAhQS7xlS+3q8++/RswNBkOiyfCCHpvKhSqzsPtCzgacpeNfHQmLDLu77/ut3zN0xVBKjC/BoKWDOHjlYMpNJFrMx4/XCJTRo+M/PjhYMzzLl1eL/L33NKKlSZOUm6PBYMh8PMy5ntJbUhZFE+KPfX8II5FeC3qJzWa7+/7289ulz8I+4vS5k1gjLflg9Qf37E8WgoNFOnfWhcwhQ0TiGz80VGTCBJEiRfT4Z54R2bEjeedjMBgyFcSzKJqpLPRoelTrwahmo/ht32/U86rHqpOrEBHqFK/Dzx1+5tzb5xhQawCBYYHJH6/u7KwZoGPGwHffxV2nXATmzoUqVTTssEoV+O8/LWNbu3byzsdgMGQZMvyi6MMQEWbuncmI9SM4E3CGpm5NGdtyLPVLxixO2sSGnWXH9vPb2Xd5H/1r9X+8k9lsMHiwNmUuV04F+2E3in374PXXYdMmqFZNi3ElJh7dYDAYyOSLog/Dsiz6PNGHY4OPMbHNRI5eO0rDGQ15a8VbBIUHAWBn6eXP2D2DAUsG8O6qd4myPVAkMmE+/BCmTIG1a6NPHvdxq1bBk09qLfLp02H3biPmBoMh+XiYLyalt5T0ocdFYGigDPpnkDASKTOhjKw5uebuvoioCBmybIgwEmn/Z3u5FXYr8QNPmaL+70GD4veXz5qlSUXVq2sdFoPBYHgMyGo+9LjI7ZSbyc9O5t8+/+Jg50DLX1vysffHRNmicLBz4Ps23zOpzSSWHlvKE1Of4HrI9YQHXb5cKyU+++zD/eWgbpWXXtKolQ0boERMklMaebwMBkMmJMsIejRN3Zqy97W9DKg5gNEbR9Pm9zZcC74GwBv13mBFrxXUKlYLF2ctxztk2RB+3fvrgwOJaGGsGjVg9myNG4+D49/+w4T3z/NR5b95t8YqhnySl23bdJ+Pj66h9umjPaANBoMhKSRXx6IMRfZs2Znefjr1S9Zn8LLB1J5Wm5eqv3Q34qWxa2OuBF2hSK4inLpxlsnbJxNhi6Bf5Z7q+27cWBtFLFoEgYFEZc+FzwY4fVrrZpUrB82age+KY1R8ux3QDofjgtMZC0dHLVce3QXupZe0tedff8GwYTB0KBQtmqY/HoPBkEHJtFEuiWXnhZ30mN+DE9dP3H1PEBzsHHiu4nOcmzGevSUHEu62mgmr8/Gmz03O9P4I11lf3M0f+uMPuHQpZszevWHWpECoW5dfLnnSfM1HuNYt8tA5nD4NH38Mv/8Obm6a8Q+aZBoZCbVq6f0jKEhfe2ilYDZsgOrVIV++uMcV0ZylnDmT+EMyGAzphkxdyyW5kDt9lH194cdf/bGrPZ1FV8fz1BpnRvlE8G6HSyyrCO5LhhF27Rv8Tqk137mzus67dVPRdXKC3LmEfAO6qAW/di00bZqoOezdC8ePa00u0BIwy5drVGQ07drBkiUq7i4uuq9uXe0nbbOpxd+9u47j4aFPDGXLqvu+SRN195snAIMh4xKfoGdJl0tsLlxQAdy7FwID9T3LKsDUqR8yedgwDh98nqjcq7C3s8c9XxV6fPIE7UpZd2PY582LtRYqotURx42Ddes0nT8eMRfRFqC5cukYNWroFs0//6hw79sHmzerJV6vnu5zctIaXqtWwfr1cPGilkUPDtb9RYtqzlLu3NoLY+lSmDkT5s+HTp20TMygQVCxYsxWpIh6k/Ll09LtZ87oeKGhMYu3DRpoq9JLl/ScuXPrDcMuy63GGAzpjywn6CLqqrh4UYW8SBEVx5deUmEqV05F1c0NwIkavyzn0q2LZFs+mKOHF7DIeQLPN6jBt5vX4O3nzYeNP6RJqcZYc+aoj+TgQY1i+fZb7fV5h4gI2LJF9X7nThXLM2dUsJ2c9HylS0Px4trIKH9+XWfdvRu2b9cnh7JltWVo5cq6L9rqjohQAb55Uzc/PyhTBr766t7rPnIkxjp3doYKFeDoURX7iAh9f9s2tfj/+kvzn+7n6FEV/99+05IzoHNt2hSeekpvEo6OMee8cEF/JMeOQalS0L79w4OBDAZD0sgyLpfAQF18/OEHOHRIs+0PHHiIuAQEQIcOWlSrUaO7b887NI83lr3B9ZDrtCrTii3nt3Aj9AbVwvIxeNVNetk8yDHsffW/ODpis8GaNVpva+VKnYO9vd4wypQBV1cV2KtX1W9+6pRavjduqNCDHlO3rn5mwQLYs0cXVV9+WUVyxw69jsjIey+hXTt4+21dnE1IQCMj9eZy7ZqOnTOn3kD27FFrPLqaAUCdOvreyZOwf7+6qXx81OI/c0ateXt7jeb89Ve4dSvmPBUq6JwBfvlFb56NGxuBNxgehSzvQ9+0Sbu4nT+vpVLeeEM1N0eOOA4WUZ/EP/+oL+PJJ+/Z7R/sz9ur3mbW3lmUxI0XdgTgXfIme4tCNfuOvFFoAblyqWU6bRqcOAEFC+qQrVtrf4u8eROec1iYimPsY202mDcPPv1UhTF/fhXYWrWgZEl1leTLpxb95Mkq0DVqQKtWekzt2hpZk1LukUuXYp4AZs7Um427u94k3N3VfVO+PERF6RPJ+fNq7fftq2sRFSqkzLwMhsxEkgXdsixP4DvAHvASkTH37XcFZgL57hzzoWhj6YeSmoK+eTP0768Rh/fp84N89hl8/jlRX3/L+ifeYvlytVhLl9btzBkNO7/i+wVXn/2Ec3mgyJauXDrRD24Xg8s1INdFKLKfRkVbMOh1e7p0UbdKchEZCVeuQLFiD7duQ0LULTJjhrptwsP1/QIF1DXy9NNqHZcooTcGe3u9AWzcqJufn/rH8+bVm0SNGvqzK/LwYJ14S9jcT1CQ3pxmzNC6ZKAPRMOH680sKCjxPbQNhqxEkgTdsix74BjQCjgHbAd6iMihWMdMA3aLyBTLsqoAy0SkdHzjpoSgR/tsDx9Wf7G9fYwfOCoqEb2UR4+Gjz/Gx70vHf1ncPWaxo1HRNyb0dmw5FlW+9fkllthPvioIbN8f6JM3rKMe3oSDQt58tnG95lx+GtcnF14ptwzeJb3pFPlTuRxypOs15tYIiLUzbRzp4rnunUaKhmNnZ2K9vU7ybFOTuqvDwpS71NgYMz1ly+vbqCAgJh9oaG6hYer8A8bpusTib2J+fnBsmW6HlC9urqpWrXStYKGDWOeQp54InlvjAZDRiSpgt4QGCkire+8Hg4gIl/GOuZHwFdEvrpz/Dci0ijOAe+Q3ILu7w89e2rURzT586sfuFSphD9//qyNy407c+hMTl7PPpNn29vTtSu0aaMLkOfOqY87j3M4td9thnXggPoUKmqruwGLB3D8+nGauDbhs6afcS3kGitPrmTFiRVcun0Jt7xuHBtyDEd7x2S75qTg56eumcuX1Yd/9ao+gTRurAIaWzjDwmDXLvWV+/jo00HevLrlyRPjZ7e31+ZMBw+q6+X11/XJqMQjtnP19dWnoE2bdCHZ31/f37lThf3MGT3Xo45rMGQG4hP0BItoAV1QN0v0697ApPuOKQbsRy34G0Dth4w1ENgB7HB1dU3WgjWzZok4Oor8738ia9eKXLgQUysrKkpk0yaRZctEDh0SCQrS944dE/nrL5E3h0RJ9uwiObKFy7tvRYi/fzwneustLcY1Z849b4dFhsnkbZOl2NfFhJFIq1mtZOHhhRIWESY+Z3xkxq4ZIiJis9lk+/ntyXrt6QmbTWTlShFPT/0x2dmJtG0rMm+e/g6WLxeZPVtk4UKR8+cTN96pUyILFmg/EBGR117TsZ96Ss+V3D1KDIb0DPEU50ouQX8beOfO9w2BQ4BdfOMmV7XFixdjvj95Mub7kBCRDRtE3nxTpEQJvdLYm7OzfvVkmeyklrze/pz4+sZzosBAkfHj9UNDhz70sKDwIBm7cexdYS/6dVH5cPWHsv38domMipSVJ1YKI5FB/wySoPCgpP8A0jEnToh89JFI8eIP/vyjtxIlRDp2FBkzRm/EgYEJj3vkiMioUSKlSukYDRqIrFqV8tdjMKQH4hP05HK5HAQ8ReTsnde+QAMRufKwcZPD5bJwocaPb92q/tbt2+HHH9UTcvCgLh46OYGnJ3Ttqi6F06fVdXL9OtQtfJrOo2th51YKu82b4g57WbtWV+7+/ltXGps10xhEx/hdJ5G2SJYdX4bXLi+WHl+KTWzkc85HE9cmBEUEsdZvLe4F3Pm90+/ULp65uxRFRqrvPiwsxk0TGKi/r23b9Pd34k7lhegEq2ee0aigRo308zdvqs8+b15dDLa31/F++QW++AI6dtSCl6GhWkahenUNiyxXTt0/JjTSkFlIqg/dAV0UbQGcRxdFe4rIwVjHLAf+EpFfLMuqDHgDJSSewZMq6Dt2aDJLtWq6yBfdKyJbNs2mrFNHtxYtVEAeICxMHcbHjqlztnz5B4/56ittXpEvn67y9e6tq3SPqA6Xb19mrd9avP288fbz5tTNU4A22BARvmj+BcObDH/0H0Imwt9fBX7LFo0W9fF5MLY+mmzZdGG2alWtVNmqlYZ05smjMfl166qwR5Mzp0Y49eihN5KlS3UNwddXM3VbttRyCw+riWMwpCeSI2yxLTABDUn8SUS+sCxrFGr6L74T2TIdyAUI8L6IrHr4iEkT9NOnoX59yJ5dBeD0af2nLFZMxaBYsUQM8vrrMHWqWt7PP//g/v/9TwO+u3VTM9DZ+bHmGhe+N3xZ67eWZceXseTYEkSET5t+yvAmw9PNomlac+uWJivt3KkPTtGW/c2bMU9Z//2nsezFikG/fmrZu7houKWIHnvypN6z+/bVKJmFC9WaBw3BdHDQMQ4fhkqV9Gnh3Dk1BlxdjWVvSH9kqsSiwEB9DD93TqMgQkOheXONr76vd8TDCQlRS7t163vz40GVYORIGDUKevWCn39+aK3z5ODK7Su8tfIt/jzwJ5UKVGJWx1nULVE3xc6XmYiM1HDHH3/UImb3/ymXLau/5rp1VeizZ9dffa5cagDkyaOfOXxYXXaWBQMGqIcN1GKvUEGTombN0v2nTukNplAhI/aGtCFTCXp4uGZ69uih/5y9eqn19u+/0fVXEklAgD6L3y/Wn36q1nnfvvqcnmDwevIw1mcsH6z5AAuLdxq+w6inR5E9W/ZUOXdm4No1rc9z44Zux49rQtnmzfr+/eTOrU95Tz6p9/V69WL88vv2qUtv3z618MPD9ckPNIx1xQr9fPnyurVoAa++qvurV9f1mVFKWHQAACAASURBVOh95cppqKVpHWtILjKVoINaZp9+CmPG6GP033/rgmeCrF2rbpaZM9Vcu5/PP9dM0f79NW8/FUsIhkWG0WlOJ5Yd1wTbMvnK8Mvzv9DULXGldw1xI6Ix9rdu6dNccLAmnUWL/b596n93cdGF2GefVdEuWDDu8TZs0NyGEydiNhcXddUAjB+vY544oTeVK1fUazd7tp6nbVtdpO/Tx/jsDY9HkuLQU2p73LDF8+dFmjTRcLVXX9XwxESxY4dIrlwiVauKXL/+4P4xY3TQl1/WIPU0IMoWJRM2T5Bso7KJ3f/ZCSORhl4NZcauGY/WuNqQaPz9NRehTx+RokVjYueffFJk3Lh7w2Ifh9u3Ra5d0+8vXRJp1EjPkSOH9hVPTCy+wRAbkhKHnlLb4wr655+L5Mwp8ttvj/Ch8HCRcuVE3NxEzp17cH90fHnPniKRkY81r+Rk/+X94vGDh7T9va1UnlRZGInkGp1LxvmME5vJokkxoqJEtm8X+ewzkZo19U/C3l6kfXuRRYuS709j1y6Rfv1EHBxEsmcX2bkzecY1ZA0ylaBHRGjCyiMxfbpe6pIlD+779lvd16WLDp5OCI0IlcioSLHZbDJh8wRp8lMTYSTy5vI3JcqWNk8QWY0jR0Tef1+kSBH9E6lYUeSXX9Q+SA5OnhR5772YG8X48ZrpvGqVyC3zQGZ4CPEJeob0oT8SIroq5eSkTtPYoQnffqtFwzt3hj//1ADndIaIUGd6HfZd3odHIQ/2XN5Dz2o9+bnDzybEMZWIiNBwx9Gj1X9epowmtFWsqJE0pUvrImn27ElbdolecAWNpOnYUaNumjVLjqswZBYy3aLoI3Pzpq5OVawY8160mHfpol2e06GYR3Mj5AbvrnqXX/f9SoRNWwtVLVSVdhXbUSZfGcq6lKVuibrkczarbCmJiCYlffGF5j/ERfbsmvD26aeJKNUcBzdvavbsggXaNap7d5gyRRdU//tPx0zBKFpDBiDrCnpEhMai2dnpf8SOHfofuWyZfp8BxDw2F29dZPqu6Xy7+VtyZMvB1eCrdwXezrKjVrFatCjTgq5Vumb6cgJpTUiIZpuePBnTSjA4WEMm//xTI2tatID339e8iVy5Hv0coaGayVqwoN5AGjbU793dNeI2Z04YPFjzMAxZh6wr6BMmwE8/6fNy9+6aW25np52On39euyhnEDGPTURUBPZ29ogIQ5YP4afdP1EmXxkibZGcunkKGza+bPEl7zV6D8tkv6Q6QUGa7DR2rJYntizNQq1dW0W+bVsoXPjRxgwO1uSpRYs0szUoSLc//tDyF/PmafpE48b6592ggcbAm19/5iNrCvqFC1Czpv4nBQRo8PF336lVXqBAyp03ldl/eT8/7vyRf479w+kA7VqR3zk/10Ov07FSR7p7dKdFmRYUyJF5rjmjEBysqQ87d+q2fbu26bMsTWp67jndPDySLrzLl8M332g8/O3b+l6BAvpnX7Cg/jsUKpQh7RfDfWQtQRfR3mtDh2raX/HiatIsXJip0/VEhGP+x1h+YjmBYYHkcszF+6vfx97OHgc7Bz576jOGNRhmFlLTEBFdVF2yRLfoP383NxX29u21PWAChTzjJSpKu1Nt3qyFyr77Tm8WL76oov/889pft0ULI+4Zlawl6FOnauGt+vW1hN/587B4sRbvyGJsOL2BFxe8yLnAcwDkdcrLOw3f4fW6r1Mwx0NSIQ2pxoULuqSzZIm23QsJ0WgZT091mRQqpK6ZvHk10zW65V+JElo87FEeNNes0QTpxYt1DBcXGDRI3TSGjEXWEvTbt7U64pw5Gi6wfLl2RM6i2MTGOr91fL7hczac3oAgvFrrVSa2nciFWxcIiwqjYoGKCQ9kSFGCg8HbO8Z6v3Qp4c+UKaMLpe3aachjYkoJhIVpm8a5c7Xw2Kef6uJrrVpQsqRWmGzXTp8YUqmMkeERyRqCvnWr/oUXKqTBuz/9BL//ro1GDYBGyby88GVW+66mZtGalHMpx7zD82hdrjWD6w2mTfk22NuZ/+K0RkSt8atXNdo2IEAt97x59aufn7prtm/XonRXr2ooY7Nm0KGDum5cXRN/Pn9/LS529qxG7fj7a2GxGTM0BNOQvsj8gh4crIufZctqdaX339ciW//3f8kzfiZjweEFDFo6iMtBlynnUo7rIde5EXoDF2cXelXvxfdtvgfUL2+iZNI3UVFqyyxerMtER4/q+zVramDXwIGPVgQsMlKL3X37rbpoKlTQRiC5cj16ZI4hZcj8gj5ypIr3mDEwfLj2m/vzz1StlpjRuB5ynYlbJ/LTnp84E3CG3I65KZqrKO4F3Jn23DSK5ipK8fHFcXF2oaxL2bulfNuWb0vfmn0RERYcXoB7QXc8Cnuk8dUYojl6VEMbFy7UhdFcudT6fustdak8Dh07qufy5Zc1F8/dPXnnbHg0Mregnz6t1vlzz+kzaJ48moURV3lcwwNE2aJY47uGn/f8zKqTq7gRegOASgUqkT1bdhztHQmOCCZKogDoXb03Hzb+kGvB1yg0rhAAnuU9+brV11QtXDXNrsPwIHv2wLhxmnFqWVrh4o03NFb9UR68jh5Vi/2XX7Q2fIcO2pmxfv0Um7ohHjJV+dwHeOEFLVn35ZdaQWnZsuQZNwsSGRUpO87vkLEbx0rrX1tLji9yCCMRu/+zk14LeskJ/5iqaBFREbL30l4Z5zNO8o3JJ3b/ZyevLnlVbofdTsMrMMSFn5/IsGEi+fLpv0j16iJffaUVpR+lguTlyyKffiqSP79WpBQROXNG5MUX9fWhQykyfcN9kGmLc0VEaONmd3dtFVeihPalM37fZCE8Kpwt57bw9+G/mbpzKpG2SPrX7M9LNV7CwU4LijjYOZAjWw5+2P4Dv+37jUvvXsLR3pElR5dgWRaVClbCLa8b2exN0HNaExSknsgfftCm6qD+9ZYt1dfesmXi/nWCgtR3nycP7Nqllv+ZM1pdo0kTHatLl2Rtw2uIReZ2uQBMmgRDhsDq1Vky3jw1uHDrAl9s+ILpu6bfrR8Tm5zZclIqbym6Ve3G8MbDafJzE7Zf2A6AvWVP6XyleaHqC4xuMTq1p26IgwsXtK3e2rW6oHr1qnouBw/W7os5cjzaeJcv6yLq9OnarcnXV4POLl/WeHlTUCz5SLKgW5blCXwH2ANeIjLmvv3fAtHB3jmAwiIS79p6kgX98mVtJFm2rBatqFBB/0KNdZ6inA04y/4r++++Do8K50zAGfxu+HHg6gHW+K6hSqEqTG47mWx22Thx/QQnrp9g/5X9FM9dnB+e/QEAnzM+NCrVyETRpANCQzVtY+JEDYesWFGTres+Rq9ym02t9jp35KZDBy17MGmSZqkakk6SfOioiJ8EygKOwF6gSjzHDwF+SmjcJPvQP/hA28mMHKmOwfXrkzaeIVlYdmyZlBpfSqyRlgxbMewen3p0t6Wt57YKI5GWs1rK3kt702qqhjhYtUqkVKmYf62kNvNYskSkRo2YHjJJbelniN+HnhhBbwisjPV6ODA8nuM3Aa0SGjdJgh4YqCs8zz8vUriwSIsWjz+WIdkJCA2Q1/95XRiJlP2urHj7et+zPywyTL7b8p24jHERu/+zkwGLBtyz4GpIW27cEOnVS9WhfHmRAQNEvLxE9u9/PIEPD9eYBScn/bfdsiX555yVSKqgd0HdLNGvewOTHnKsG3ARsH/I/oHADmCHq6vr41/RhAk69a5dRSxLG0Ea0h3/nvpXyn9fXhjJXdGO3RPVP9hfhq0YJtlGZZMi44pIRFT6aQFoEJk3T6R1axEXF/13A+2DWqmSSMeOasGvWBF3z/W4OHpUrfSAAH29a5c2zjY8GvEJeoI+dMuyugCeIjLgzuveQH0RGRzHsR8AJUVkSLyDkgQfemSk5iW7uMC+fVphaOLERx/HkCqERIQwYv0Ivtn8DTax4ZbXjRZlWuBZ3pP27u1xcnDifOB5Dl87TMuyLYmyRdHm9za0rdCWPk/0MV2Y0gE2Gxw/rmkehw7B4cO6HTumMg9aAnj4cM1OTUw+n4jWcT94EKpW1eiYJk201MDjJkBlFZK0KGpZVkNgpIi0vvN6OICIfBnHsbuBN0RkU0KTemxB371bMyOKFdP4qSNHtMiFIV1z8vpJVpxYgbefN+tOreNm6E0KZC/ASzVeon/N/neTki7eukiXuV3YdHYTObLloKdHT56v9DxPl3maHNkeMfTCkKIEBuoi6pYtWuxrzx5t4vH114nrg3r4sGa0btgAPj5aUbJTJ5g/X/evXKki/6gRN5mdpC6KOgC+QBliFkWrxnFcJeAUd24SCW1J8qFHJxHNnv34YxjSjMioSFl5YqV0ndNVso3KJoxEGno1lBm7ZsitMG13v/PCTum3sJ9k/192YSSy5uQaEREJjQi9x21jSB9ERYnMmqULqiDi6SmyeXPiPx8ZKbJzp7phRER8fXWc3LlF+vQRWbdOxPzaFZLiQ9fP0xY4hka7fHznvVFA+1jHjATGJGY8SYqgnz+vv+XWrc1vOBNw5fYV+drna6k0qZIwEsk1Ope8svgV2Xpuq9hsNgmJCJFVJ1ZJaESoiIi8veJtaejVUDaffQS1MKQawcGahVqggKpL69aPJuzRREWJrF0r0rev/ruDSL16IgcPJv+cMxrxCXrGSyz67DNt1njwoMafGzIFIsLmc5uZvms6cw7OITgimGqFq9HDo8c9fvRTN08xc+9MLgddpme1nnzv+b1pr5cOuX1bM1LHjdN0ka5dtXZe2bKPPlZIiMbFT5qkiVAFCmh9meLFtZxwViNzZYrabLB3r9YHNWRKAsMCmX1gNl67vO5mm8bG0c6RYrmLcS7wHIVzFmZu17k86fpkGszUkBC3b2uv07FjNZ7hzTfhgw8er62vSEzeYIMGsH+/+txfeSVr1W3PXIJuyFL4B/sTaYsEIEqi2HNpD96+3nj7ebP38l6cHZz5teOvdKnShYioCFMzJp1y/jx88omWB8ieHfr1g2HDHs9iBy3ZNGuWVpK8eRO6ddOKkMWKJe+80yNG0A2ZkqXHljJwyUAuBV1iWINh+Jz1IdIWiWc5TzzLe1K/ZP27RcQM6YODB9Vi/+03LfDVqRO89x7Uq/d444WEqFtn9GiNXn7lleSdb3rECLoh0xIQGsAHaz7gx50/ApDdITuhkaEIQl6nvLzb6F0+afpJGs/ScD8XLqgAT52qFnbTpirsbdo8Xi9TPz9wc9MY+MWL9fsaNZJ/3ukBI+iGTM/BKwfvxrn/e+pfgiODyZEtB0+XfprvPL8jr1NeWv7akmfKPUOF/BXuFgVrXqY5ZV0e87nfkGRu3QIvL3WXnD0LRYrACy9Ajx7qJ3/U2m1RUZqodOKEdlcaMQJy5kyZuacVRtANWYrwqHCWHV+G1y4vlp9Yjk1s5MyWE8uyCAoPQoj5m/+ry1+8UPUFLt66SEhkiBH3NCIiQi3rP/6ApUshLEz7vT/5pG7NmmnSUmIE/vp1XXj18tKqjz4+4OiY4peQahhBN2RZzgWe4+/Df3P8+nF8b/hyzP8Yx68fx8Fy4JnyzzCw1kDaVWzHB2s+YPzm8TQs1fCuD7528drYWaYvbWoTEKB9UdeuhY0b4eRJfd/DA15/HXr10uYaCTF3rlr7772nUTaZBSPoBkMsDl09xIxdM5i1bxbXgq/hmteVLpW7gAUbz2xk+/ntCEJZl7KcGHICy7IIjQzF2cG04EkLLl2CJUvU375rl7pQevXS/qjVqsX/2cGD1dIfMSJ15poaGEE3GOIgPCqcRUcWMWP3DFadXAVA3yf6MrzxcLZd2Ma14GsMrT8UAI8fPHC0d8SzvFrvDUs2NCGSqYyIFgibMgVmz9bGHE2awMsvq2ulUiVwcnrwM5mth4oRdIMhAU7fPM3EbROZsGUChXMW5odnf+D5StpixyY2vtr4FStOrsDnjA9REkVux9yMbDaStxu+TURUBFeDr94dq3DOwiZcMoXx99c2wlOmaLs70DZ3lSpBw4Yx1Rvd3FTQV6+GBQs0siajt8Mzgm4wJJJdF3fRb1E/9l7eS+fKnRndYjQVC1S8uz8gNABvP29WnlhJ6/Kt6VS5E3su7aHmjzGZy3md8tKybEuGNx5O7eK10+Iysgw2m5YB2LdPt927NekoIED358+voh4erjHwhQpB//66lS+ftnN/XIygGwyPQERUBOM2jWP0f6MJjQylzxN9+Oypz3DN6xrn8deCr7Hg8AIAomxR7Lq4ixUnVzC361walGzA/EPz+WTdJ1TIX4GXa7xMp8qdTC/VFCQqCg4cgP/+UxE/cwZOndL67ZGRarGLwFtvabhkRsMIusHwGFy+fZkvN37JlB1TAPjwyQ/5uOnHONonHAMX/X9lWRbevt5M3j6Z3Zd2c+rmKRq7Nmb8M+OpW+IxujAbHpsrV2DCBHW73L4NLVtq7fXERMykJ4ygGwxJ4GzAWYZ7D+f3/b9TtVBVfurwE/VKPHqueqQtkp92/8Sn6z6lQPYCHBh0wIRFpgE3b2oTjjFj1B3Tt69Gw+TLIM2xjKAbDMnA0mNLeW3pa1y4dYGe1XriWc6T5mWaUyz3o1WECgwL5GzAWaoWrkpwRDB7Lu2hUalGKTRrw8Pw8dE49QsXNEN13TqoXDmtZ5UwRtANhmQiMCyQj70/5vf9v3Mj9AYA7gXccS/oTpl8ZSjrUpZ2FdslOuN0xLoRfL7hc95r9B7DGg6jaK6iKTl9w33cuAHt22sCE2gtmUGDoG3bxPVGTQuMoBsMyUyU7U4pXz9vfM764HvDF78bfgRFBOHs4MznT3/OWw3eSjB88Xb4bd5e+TbTd00H4ImiT9Ctajc+bPxhalyGAV0gnTkTXntNSxDYbBoFM316+oxhN4JuMKQCIsKpm6cYtnIYi44uom7xukx/bjo1iiZc9m//5f0sO76MFSdXUCpPKWZ1nAXAzdCb93RsMqQc+/fDM89A9eqwahVMnqzWenrDCLrBkIqICHMPzWXwssFcDb5K+fzlaV66OS3KtqBN+Tbkdoq/b5qIYFkWm89uptWvrXiv0XsMrjfYtNpLBW7e1KiXDh1g+XKtJ5PeuiEZQTcY0gD/YH9+2/cba0+tZf2p9QSGBZIzW066e3RnQK0B1C9RP954dL8bfry/5n3mHZqHs4MzPTx6MLjeYGoVq5WKV5E12bFDm244O2tM++N2VkoJkizolmV5At8B9oCXiIyJ45gXgJGAAHtFpGd8YxpBN2QlIm2RbDm3hZl7ZvLngT8JigiiaqGqDKg1gF7Ve1EwR8GHfvbAlQNM3jaZWftm4eLswrm3zwEwYcsERITeNXrH+3nDoxMZCQMGqG89Z07YvDnhQmCpRZIE3bIse+AY0Ao4B2wHeojIoVjHVADmAM1F5IZlWYVF5Ep84xpBN2RVboXd4q+Df+G1y4ut57fiaO9Ix0odGVBrAM3LNH9obPrN0Jv8d/o/nnN/DoAWs1qw1m8tTvZOdPfozuB6g6ldrLbJQk1G3n9fW9zZ22vbvO7d03pGSRf0hsBIEWl95/VwABH5MtYxY4FjIuKV2EkZQTcYdDF0xu4ZzNo7ixuhNyidrzT9a/anh0cPyrqUTVCcD145yA/bf2Dm3pkERQQx4qkRjGw2kihbFCGRIeRyzJVKV5J5+eMPeOkl/f7XX7WbUlqSVEHvAniKyIA7r3sD9UVkcKxjFqJW/JOoW2akiKyIY6yBwEAAV1fX2qdPn368KzIYMhmhkaH8ffhvvHZ7sdZvLQBued1oUaYFjUo1uqcWu3tBd2oWrYm9XUzzzYDQAGYfmE3dEnWpVawWG89spPnM5jR2bYxneU/alG9DtSLpxGeQATlwQMMafXxU0CdOhAJptEadGoL+DxABvACUBDYA1UTk5sPGNRa6wRA3vjd8WX58Od5+3qw7tY6boQ/+G+Vzzkez0s3wLOdJN49uD4Q2nrh+guk7p7Pi5Ar2Xd4HQN3idZnTdQ6l85VOjcvIdISHqwvmu++07vrUqVqLPbU9XKnhcpkKbBWRn++89gY+FJHtDxvXCLrBkDBRtihOB5wmyhalr0WrOa71W4u3nzenbp7C2cGZrlW6MqDWAJq4NnnATXPh1gUWHF7A/MPzWdlrJY72jqw/tZ6yLmUfWkHSEDci8NFH8NVX+n2XLtrqLjVJqqA7oO6UFsB5dFG0p4gcjHWMJ7pQ+rJlWQWB3cATIuL/sHGNoBsMSWfXxV147fLi9/2/ExgWSMUCFelfsz8v13iZIrmKxPkZEaHs92U5E3CGDu4dGFBrANWLVKd47uKmWFgi8fGB1q0hKAhmzYLevVPv3MkRttgWmID6x38SkS8syxoF7BCRxZaaBN8AnkAU8IWIzI5vTCPoBkPyERwRzNyDc/Ha7cXGMxtxsHOgh0cPvnnmGwrlLPTA8advnmbqjqlM3zUd/xC1u95r9B5jW2k35YioCNNiLwFmzVKXS/bsqRurbhKLDIYsxJFrR5i2cxqTtk0ij1Mevm/zPT08esQZMRMaGYrPGR9OXD9B9SLVaViqIf+e+peXF77MmJZj6Fa1mwmDfAjh4TB2rIY1VqqkBb6ypcI9MD5BN89XBkMmo1LBSoxvPZ7dr+6mfP7yvLjgRZ778zmO+R974FhnB2dalG3Bq3VepWGphgBkz5ad/Nnz02N+DxrOaMims5tS+xIyBI6O8Mkn4OUF27bBiBFpPSMj6AZDpqVq4ar49PPh29bfsv7UeqpMrkL/Rf05fTP+cOF6Jeqx/ZXt/NzhZ84GnuXJn57ktX9eS6VZZzxCQ6FOHW2YsXJl2s7FCLrBkImxt7PnrQZvcXLoSQbXG8xv+3+j4qSKDFg8gK3ntvIwl6u9nT19nujDscHHGPHUCGoU0YqRNrERGBaYmpeQ7vnvP/WhV6oEPXtCWqbXGEE3GLIARXIVYYLnBI4POU7fJ/ry54E/aTCjAdWnVmfi1omERITE+bmcjjkZ2Wwkr9d9HYBf9/5Kue/LMWX7FCJtkal5CemWoUPVSm/TRmvAdOmir9MCI+gGQxbCNa8rU9tN5eI7F5nWbho5suVg6Iqhd0U6PCo83s9XL1KdqoWqMmjZIPKNyccTU5+g76K+qTT79ImHhzacnj0bfvpJKzUOHZo2czGCbjBkQfI45eGV2q+wdcBW1r+sSUaDlg3CfZL73dIDcVGzWE3WvbyOJT2W8EqtVyiVtxS3wm7d3f/34b8fau1nZoYN096kt27B8OHa7ejXX1N/HiZs0WAwICKsOLGCd1a9w4nrJ/it02+8UPWFRxrj6LWjVJpciVJ5SvFxk4/pVb0XOR1zptCM0xcimlzUqxe0agXNmsGhQ3D0KBRM5srGJmzRYDDEi2VZtKnQhk39N9GgZAO6z+vO5G2TH2kM94LurHt5HUVyFeG1pa9RYnwJ3l75NteCr6XQrNMPlqXldT09tdTulCkQEKDWempiBN1gMNwln3M+VvZayXPuzzF4+WAGLxvMprObiIiKSNTnm5VuxrYB29jYdyNtKrTh5z0/J9goOzNx8yb88ANUqaJuGC8vbY6RWhiXi8FgeIBIWySDlw1m2s5pCEIux1w0dWtKizItaFGmBdWKVEtU3Zeg8CByOuYkyhbFH/v/4MXqL2bqejG//aaul4ULoUULDWUsWFAXSh2S6b5mUv8NBsNj4R/sz7pT6+5Wd4zONi2YoyBPl36a5mWa06JMC8rnLx9viYC/DvxF9/nd6VqlKz93+DnT+tYjI8HdXWulb90K8+dD165acje5Il+MoBsMhmThbMBZ1p1ah7efN96+3py/dR6Asi5lGddqHJ0qd4rzcyLCN5u/4f3V71MsdzFGNx9N7xq9M6W1Pm0avPqqZo22aqXx6Zs3w6VLWsgrqRhBNxgMyY6IcPz6cbx9vZm2axp7Lu2hc+XOTGo7iaK5isb5GZ8zPgxbOYztF7bT74l+zOgwI5VnnfKEhUH58lCsmFrp3t4q7PPnQ6e473ePhIlyMRgMyY5lWVQsUJHX677OtgHb+KL5Fyw5toQqk6swa++sOMsKPOn6JFsGbOH3Tr8zsPZAQPuitvm9Dd9t+Y6j144+tBxBRsHJCT7/HFxcdJG0WTP1o8+Zk/LnNha6wWBINo5cO0L/xf3ZdHYTbcq3YWq7qQl2RVrrt5ZBSwdx1P8oAKXzlcaznCcfNv4Qt3xuqTHtZEfk3tZ0r72mC6ZXrkCOHEkb21joBoMhVahUsBIb+mzge8/v2XB6A1V/qMqU7VOwie2hn2lepjlHBh/Bd6gvU56dQo0iNVh4dOHdPqmHrh7KcAXBosX81ClYtUoXRoOCYPnyFD6vsdANBkNKcOrmKQYuGchq39U85fYU05+bToUCFRL1WZvYsLPsEBFqTauF7w1fPm7yMUPrD8XZwTmFZ558tGmjIYtHjkDlytC8udZ8SQrGQjcYDKlO6XylWdlrJTPaz2DPpT1Un1qdcT7jElWlMTr6xbIsfmz3I01cm/DBmg+oPLkycw7OyTB+9v/9D65dg/HjoXNnWLIEgoNT7nxG0A0GQ4phWRb9avbj0BuH8Czvyftr3qfqD1WZfWB2vG6Y2NQrUY9/ev7D6t6ryeOUh27zurH46OIUnnnyULs29OgBEyZA27Yq5suWpdz5jKAbDIYUp3ju4ix4YQGLui/C0d6RHvN7UPPHmiw/nnincsuyLdk1cBe/d/qdNhXaADBx60Q+WP0BwREpaPYmkcGDVcj9/aFwYZg7N+XOlShBtyzL07Kso5ZlnbAs68M49vexLOuqZVl77mwDkn+qBoMhI2NZFu3d27Pn1T383ul3giOCaftHW15c8CJXg64magx7O3t6VuuJo70jAKcDTjN201hqT6vNrou7UnL6j03DhlC1Kly9qm6Xf/5JObdLgoJuWZY9MBloA1QBeliWVSWOQ/8SkSfubF7JfrvSGAAADm9JREFUPE+DwZBJiBblg4MOMvKpkcw9OJcqP1Thz/1/PrJv/OtnvmZN7zXcCrtFfa/6fPnfl0TZolJo5o+HZcG+ffDee/DCCynrdkmMhV4POCEiviISDswGOqTMdAwGQ1bB0d6REc1GsOvVXZTJV4aeC3pScVJFxmwcw8VbFxM9TouyLdj3+j46VurIR2s/Ytv5bSk468fD7o7S1qypxbuKFEmZ8yQYtmhZVhfAU0QG3HndG6gvIoNjHdMH+BK4ChwDhonI2TjGGggMBHB1da19Oi27qRoMhnRDdDVGr91ebDi9AXvLnqfLPE2LMi1oXqY5tYvVxt7OPt4xRISdF3dSp7hG9O27vI9qhavFWzQsNenRA86ehY0bkzZOaoQtLgFKi0h1YDUwM66DRGSaiNQRkTqFChVKplMbDIaMjr2dPb1r9ObfPv9y5I0jvNvoXS7dvsRw7+HU96pP0W+KMtZnbLyLn5Zl3RXz3Rd3U/PHmryx7I3UuoQEqV4dfHwgJe3YxAj6eaBUrNcl77x3FxHxF5GwOy+9gNrJMz2DwZDVcC/ozpiWY9j/+n4uvXOJPzv/Sd3idflgzQeU+74ck7dNTlQz68F1BzNlxxT+OfZPKs08frp3169JTSyKj8S4XBxQN0oLVMi3Az1F5GCsY4qJyMU733cEPhCRBvGNazJFDQbDo7DxzEY+XvsxG05vwC2vGyObjaRX9V4P7YgUHhVO7Wm1uRFyg0NvHCKPU55UnvGDNGqkJQD27n38MZLkchGRSGAwsBI4DMwRkYOWZY2yLKv9ncOGWpZ10LKsvcBQoM/jT9dgMBgepLFrY9a/vJ6VvVZSKGch+i7qi8cPHszcM5MrQVceON7R3pEZ7Wdw8fZFPlj9QRrM+EF69tSIl4MHEz72cTC1XAwGQ4ZDRFh4ZCGfrPuEQ1cPAVCtcLW7i6hPlX7qrkX+ydpPKJSjEG82eDMtpwxoLPrKlfD885Ar1+ONYRpcGAyGTIlNbOy4sONui7yNZzYSGhmKvWVP3RJ1qV+iPmVdylImXxkqFqiIvZ095fOXT+tpJwkj6AaDIUsQFhnG5nOb8fb1xtvPm32X9xEUEXTPMfWK1+OjJh/RrmK7BEMh0yNG0A0GQ5ZERLgafBW/G34sPb6Urzd9TUhkCAANSzZkde/VGa5htSmfazAYsiSWZVE4Z2Hql6zPqKdHcendS3zW9DOcHZzZfG4zzX5pltZTTFaMoBsMhixDHqc8/N/T/8fxIccp71KeHRd38P7q9xNVoz0jYATdYDBkOUrmKcmBQQcYVGcQ4zaNo+oPVfnrwF8ZXtiNoBsMhiyJk4MTk5+dzNetvuaY/zG6z+9OyfEl+dj7Y26E3Ejr6T0WRtANBkOW5p1G7zCv6zwc7BwIjQzly41f0mlOpwxprRtBNxgMWZ7OVTrzd7e/CYkMwTWvK+tPrefTtZ+m9bQeGSPoBoPBALSr2I6F3RZy6fYlmpduzhifMSw5uiStp/VIGEE3GAyGO7Sp0Iajg4+y9MWl1CpWi15/98L3hm9aTyvRGEE3GAyGWLjlc8PZwZmRT40kMCyQpj835fLty2k9rURhBN1gMBjioKlbU+oUr8P5W+dxn+TOcf/jaT2lBDGCbjAYDHGQ1zkvm/tvpkuVLgSEBVBtSjU2n92c1tOKFyPoBoPB8BAc7ByY23UuHzX5iLCoMJ6e+TRzDs4hrWpgJYQRdIPBYEiAL5p/waJui/Ao7EG3ed14/q/nuXDrQlpP6wGMoBsMBkMiaF+pPVsGbOGTJp+w5OgSKnxfgQWHF6T1tO7BCLrBYDAkEgc7B4bWH0rNYjUJjgym27xuHL56OK2ndRcj6AaDwfAIFMpZiE39NtHMrRlRtih6zO9BeFR4Wk8LMIJuMBgMj4yTgxNjW41FEPZe3suof0el9ZSARAq6ZVmelmUdtSzrhGVZH8ZzXGfLssSyrDi7aRgMBkNmoW6JujRxbULFAhX5cuOXbDq7Ka2nlLCgW5ZlD0wG2gBVgB6WZVWJ47jcwJvA1uSepMFgMKRHVvVexY5XduCW141eC3oRGBaYpvNJjIVeDzghIr4iEg7MBjrEcdznwFdAaDLOz2AwGNItzg7O5HbKzbetv+VMwBn6LeqXpjHqiRH0EsDZWK/P3XnvLpZl1QJKicjS+AayLGugZVk7LMvacfXq1UeerMFgMKQ3lh1fRuc5nXm9zuvMPzyf77Z+l2ZzSfKiqGVZdsB44J2EjhWRaSJSR0TqFCpUKKmnNhgMhjSniWsTcjnm4krQFZ6v9DzvrX4PnzM+aTKXxAj6eaBUrNcl77wXTW7AA1hvWdYpoAGw2CyMGgyGrEBup9wMrD2Q+YfnM+KpEbjldaPbvG5cCbqS6nNJjKBvBypYllXGsixHoDuwOHqniASISEERKS0ipYEtQHsR2ZEiMzYYDIZ0xlsN3sLBzoGJWycy74V5+If488qSV1Ldn56goItIJDAYWAkcBuaIyEHLskZZltU+pSdoMBgM6Z3iuYvzWp3X+OvgX7jldePzpz9n8dHFzD88P1XnYaXVimydOnVkxw5jxBsMhszBteBrhESEUCpvKSJtkdT3qs/5wPMcfuMwLtldku08lmXtFJE4XdomU9RgMBiSgYI5ClIqry43Rtmi8HrOi2vB13h/9fupNgcj6AaDwZBMiAjPz36evov6UrNYTd5t9C5eu71Y57cuVc5vBN1gMBiSCcuyqFywMrMPzObglYOMeGoE5VzK8eo/rxL1/+3df2wfdR3H8edrLWVlq53ZarIAheF+uDqILlVX/5iKYmqFzsRk2jgUQ0pkYogT4xJHNBr+cKIhJkt0RjA1mThDRgpsIWGyLKIlLsDGtkw22cRtxIIgkBLt1r79476alrX9Xsf37urt9UiafG/f633eeef66vVz331udCTz8R3oZmY1dMeH72Buw1w27t5I40WN3HXtXRx95Sh7TuzJfGwHuplZDc2/ZD53rr6Th597mJ1Hd7LmPWtovriZvgN9mY/tQDczq7HbV93OsvnL2PzEZmbXz2bte9fywOEHGBoeynRcB7qZWY011DWw43M7eKjnIQBuvOZGhs4MsePIjkzHdaCbmWVgectymi5uYnhkmLaWNhbNW0Tf/mynXRzoZmYZGRkdoeMXHazfuZ5116xj9/HdnHr9VPVvPE8OdDOzjNTNqqNrcRfbD21ndetqRmOUbc9uy2w8B7qZWYbWf2A9darjseOP0XFZB30H+jJbtMuBbmaWoYVNC7l+6fXc98x99Kzo4eDgQfb/fX8mYznQzcwy1ruyl8GhQeY1zqOxvpEnT2bz6OX6TI5qZmb/07m4k11f2MV1V11H99Jummc3ZzKOA93MLGN1s+roXNwJkFmYg6dczMxyERFs+t0m7hm4J7MxHOhmZjmQxFMvPsXdf7ibs6NnMxnDgW5mlpPelb28MfwGR14+ksnxPYduZpaTG5bdwOkNp5nTMCeT4zvQzcxyUj+rnvqG7GI31ZSLpE5Jf5Z0TNLGCd7/iqRnJT0j6feS2mpfqpmZTaVqoEuqA7YAnwLagJ4JAntbRFwdEe8DNgM/rnmlZmY2pTRX6B8EjkXE8xExDNwPrBm7Q0S8PmZzDpDNQgVmZjapNJM5lwJ/G7N9EvjQW3eS9FVgA9AAXDvRgSTdAtwC0NraOt1azcxsCjX72GJEbImIdwPfAjZNss/WiGiPiPaWlpZaDW1mZqQL9FPA5WO2L6v822TuBz7zdooyM7PpSxPofwKWSFokqQH4PNA/dgdJS8Zsfho4WrsSzcwsjapz6BFxVtJtwKNAHXBvRByS9D1gX0T0A7dJ+gRwBngV+FKWRZuZ2bmU1ZMzqg4svQT8tZDBa2cB8HLRRcww7sl47se53JPxptuPKyJiwpuQhQV6GUjaFxHtRdcxk7gn47kf53JPxqtlP7w4l5lZSTjQzcxKwoH+9mwtuoAZyD0Zz/04l3syXs364Tl0M7OS8BW6mVlJONDNzErCgZ5CivXgN0g6LOmApN2SriiizjxV68mY/T4rKSSV+mNqafohaW3lPDkkaVveNeYpxc9Mq6THJT1d+bnpKqLOvEi6V9KgpIOTvC9JP6n064Cklec1UET4a4ovkv8d+xfgKpKVJPcDbW/Z52PAJZXXtwK/KbruontS2a8J2AsMAO1F113wObIEeBp4Z2X7XUXXXXA/tgK3Vl63ASeKrjvjnqwGVgIHJ3m/C9gFCFgFPHk+4/gKvbo068E/HhFvVjYHSBYwK7OqPan4PvAD4F95FleANP3oBbZExKsAETGYc415StOPAN5Red0MnM6xvtxFxF7glSl2WQP0RWIAmCdp4XTHcaBXN9F68JdOsf/NJL9py6xqTyp/Ml4eEY/kWVhB0pwjS4Glkp6QNCCpM7fq8pemH98F1kk6CewEvpZPaTPWdHNmQn5IdA1JWge0Ax8pupYiSZpF8hjCmwouZSapJ5l2+SjJX3B7JV0dEf8stKri9AC/jIgfSeoAfiVpRUSMFl3Y/zNfoVeXaj34ymqT3wa6I+LfOdVWlGo9aQJWAHsknSCZE+wv8Y3RNOfISaA/Is5ExHHgOZKAL6M0/bgZ2A4QEX8EZpMsUnWhmu5zJybkQK8uzXrw7wd+RhLmZZ4b/a8pexIRr0XEgoi4MiKuJLmv0B0R+4opN3NVzxHgQZKrcyQtIJmCeT7PInOUph8vAB8HkLScJNBfyrXKmaUf+GLl0y6rgNci4sXpHsRTLlVEuvXgfwjMBX4rCeCFiOgurOiMpezJBSNlPx4FPinpMDACfDMi/lFc1dlJ2Y9vAD+X9HWSG6Q3ReXjHmUk6dckv9AXVO4bfAe4CCAifkpyH6ELOAa8CXz5vMYpcQ/NzC4onnIxMysJB7qZWUk40M3MSsKBbmZWEg50M7OScKCbmZWEA93MrCT+A95l117Eu5VUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhwhX0d2C_c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_cm(labels, predictions, p=0.5, display=True):\n",
        "  cm = confusion_matrix(labels, predictions > p)\n",
        "  if display:\n",
        "    plt.figure(figsize=(5,5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
        "    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
        "    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
        "    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
        "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n",
        "  pre = cm[1][1]/(cm[1][1] + cm[0][1])\n",
        "  recall = cm[1][1]/(cm[1][1] + cm[1][0])\n",
        "  f1_score = 2*pre*recall/(pre+recall)\n",
        "  return pre, recall, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2H3PvUGb8KX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "e5817feb-caae-46b0-f992-33e4ac7993e8"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "baseline_results = new_model.evaluate(X_test, Y_test,\n",
        "                                  batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(new_model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "predictions = new_model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
        "\n",
        "plot_cm(Y_test, predictions, p=threshold_value[max_f1_indices], display=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss :  0.5232799053192139\n",
            "tp :  432.0\n",
            "fp :  24.0\n",
            "tn :  2796.0\n",
            "fn :  218.0\n",
            "accuracy :  0.9302593469619751\n",
            "precision :  0.9473684430122375\n",
            "recall :  0.6646153926849365\n",
            "auc :  0.9595742225646973\n",
            "\n",
            "Legitimate Transactions Detected (True Negatives):  2752\n",
            "Legitimate Transactions Incorrectly Detected (False Positives):  68\n",
            "Fraudulent Transactions Missed (False Negatives):  152\n",
            "Fraudulent Transactions Detected (True Positives):  498\n",
            "Total Fraudulent Transactions:  650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8798586572438163, 0.7661538461538462, 0.8190789473684211)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A5VYg4_-NrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "c44f6f32-cdd9-4994-ec2e-c2d39605fc49"
      },
      "source": [
        "# Test with X_test_2 and Y_test_2, should all be 0\n",
        "predictions2 = new_model.predict(X_test_2, batch_size=BATCH_SIZE, verbose=0)\n",
        "\n",
        "plot_cm(Y_test_2, predictions2, p=threshold_value[max_f1_indices], display=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Legitimate Transactions Detected (True Negatives):  277545\n",
            "Legitimate Transactions Incorrectly Detected (False Positives):  7393\n",
            "Fraudulent Transactions Missed (False Negatives):  0\n",
            "Fraudulent Transactions Detected (True Positives):  0\n",
            "Total Fraudulent Transactions:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, nan, nan)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAFNCAYAAABfS5fmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debzVVb3/8dcbEESUQXFAQHEAFf2VlhlZt4uUiGhhXTPTEtNEzaHRoeE6d6/dBkszC9OcckxLMhQJc7qmgeUAaICCyhFEBZHBq8D5/P74rnPcHM45bLZrn4n308f3wd7rO619tud91vqu76CIwMzM3rtOrV0BM7OOwoFqZpaJA9XMLBMHqplZJg5UM7NMHKhmZpk4UM3MMnGgtkGSukv6k6Slkm57D9s5WtK9OevWWiT9m6R/tXY9zJrjQH0PJB0laZqk5ZIWSLpb0scybPpwYFtgq4j4XKUbiYjfRcTIDPWpKkkhadfmlomIhyJit/e4n5HpD9VCSa9KeljScZI6NVhuS0l/kLRC0guSjmpmm2dImi5pmaS5ks5oMH9vSQ+lP47zJf3ne/kM1rY5UCsk6ZvAz4D/ogi/HYBfAmMybH5HYFZErM6wrXZPUpcM2/gfiu/qN8DuwHbAqcAI4C5J3UoWvxx4h+J7PRq4QtKeTW0aOAboA4wCTpV0ZMn8G4EHgS2Bfwe+KunT7/XzWBsVEZ42cAJ6AcuBzzWzTDeKwH05TT8DuqV5w4H5wLeARcAC4Mtp3vkUv8yr0j6OB84DbijZ9iAggC7p/bHA88AyYC5wdEn5wyXr7Q9MBZamf/cvmXc/cCHwv2k79wJ9m/hsdfU/s6T+hwGjgVnAYuC7JcvvB/wNeCMt+wuga5r3YPosK9Ln/XzJ9s8CFgLX15WldXZJ+/hAer898CowvIn6HpM+T7cm5v8IOCe97pF+/kNK5l8PXFzm/xuXApeVvF8JDC15fxvwndb+f9hTdaZWr0B7nChaIqvrAq2JZS4AHgW2AbYGHgEuTPOGp/UvADZJQbQS6JPmNwzQJgM1BcCbwG5pXj9gz/S6PlApWkhLgC+l9b6Q3m+V5t8PPAcMAbqn942GSEn9z0n1PyEF2o3AFsCewFvATmn5DwLD0n4HAc8AXy/ZXgC7NrL9H1L8YepeGqhpmROAmcBmwCTgx818F7OBgen1DylC+h/AJenn0R14Ls3fB1jZYP1vA38q4/8LAf8ETiop+y/g4vRz2o3iD8WHWvv/YU/Vmdzlr8xWwGvRfJf8aOCCiFgUEa9StDy/VDJ/VZq/KiImUrTOKj1GWAvsJal7RCyIiBmNLHMIMDsiro+I1RFxE/As8KmSZX4bEbMi4i3gVmDvZva5CvhBRKwCbgb6Aj+PiGVp/zOB9wNExOMR8Wja7zzg1xTd3/V9pnMj4u1Un7VExJXAHOAxij8i32tsI+nY7MsR8ZKkg4GDgfdR/FH8BNA5bX+xpL7A5hR/oEotpfhDsT7nURxG+21J2V0Ux8Tfovh5XxURU8vYlrVDDtTKvA70Xc+xve2BF0rev5DK6rfRIJBXUvwyb5CIWEHRTT4JWCDpz5J2L6M+dXXqX/J+4QbU5/WIWJNe1wXeKyXz36pbX9IQSXelwaA3KVptfZvZNsCrEfF/61nmSmAvii72200ssw1Qk17/P+Ce9EduEXBPql8nimOgiyn+sPVssI2eFIdBmiTpVIpDC4fU1UXSlmkfFwCbAgOBgyR9dT2fy9opB2pl/ga8TXHcsCkvUwwu1dkhlVViBUXXts52pTMjYlJEHEjRUnuWImjWV5+6OtU0smxuV1DUa3BE9AS+S9E9bk6z95WUtDnFcemrgPNSeDXmNYqfC8DTFIG2jaRtKFqpPYD/BiZGRC3FMeAukgaXbOP9QGOt/rq6HAecDXwiIuaXzNoZWBMR16XW+XyK1vzo5j6btV8O1ApExFKK44eXSzpM0maSNpF0cBpNBrgJ+L6krVNX8hzghgp3+QTwcUk7SOoFfKduhqRtJY2R1IMi5JdTdJcbmggMSad6dZH0eWAoRZe02rag6EYvT63nkxvMf4UifDbEz4FpEfEV4M/ArxpbKCJmAQMl9YuIuylajE8CEygGxE6maH1+Oy2/ArgDuEBSD0kfpThz4/rGti/paIoW94ER8XyD2bOKRXSUpE6StqPoTTy1gZ/V2ovWPojbnieK46TTKFqQCyl+sfdP8zalGPFdkKZLgU3TvOGUDLCksnnAJ9Pr8ygZhEpll1OMks+hGJCpG5TqBzxAcZzvDYrBpKFpnWNZe5T/Y8DjadnHgY+VzLsf+ErJ+7XWbVCXteqf6hHAoJKyh4Evptcfp2ihLgceougCl9brpPQzegM4oomfT30ZRcDVAFum95unn8vRTdR3XPpu1hlEbKJsS+CP6Xt9ETiqZN6/ActL3s/l3TMy6qZflcwfwbtnViyk6D1s1tr/73qqzqT0pZt1aJJ+QdF1P4fikE0nYCRwEcVxz4bHl802mAPVNhqSPgOcQjr7gOJUth9GxCOtVyvrSByoZmaZeFDKzCwTB6qZWSbv+aYT1bLqted9LKKd6r3DiNaugr0HK1bOW985wo2q9Hd2k747V7S/tsgtVDOzTNpsC9XM2pnaNetfpoNzoJpZHtHYBXobFweqmeVR60B1oJpZFuEWqgPVzDJxC9WBamaZuIXqQDWzTDzK70A1s0zcQnWgmlkmPobqQDWzPDzK70A1s1zcQnWgmlkmbqE6UM0sE4/yO1DNLBO3UB2oZpaJj6E6UM0sE7dQfYNpM7Nc3EI1szzc5XegmlkeER7ld6CaWR4+hupANbNM3OX3oJSZZRK1lU3rIWmgpL9KmilphqSvpfLzJNVIeiJNo0vW+Y6kOZL+JemgkvJRqWyOpLNLyneS9Fgqv0VS11TeLb2fk+YPaq6uDlQzy6N2TWXT+q0GvhURQ4FhwCmShqZ5l0TE3mmaCJDmHQnsCYwCfimps6TOwOXAwcBQ4Asl2/lh2tauwBLg+FR+PLAklV+SlmuSA9XM8qhSCzUiFkTEP9LrZcAzQP9mVhkD3BwRb0fEXGAOsF+a5kTE8xHxDnAzMEaSgBHA79P61wKHlWzr2vT698An0vKNcqCaWR61tZVNGyB1ufcBHktFp0p6StLVkvqksv7ASyWrzU9lTZVvBbwREasblK+1rTR/aVq+UQ5UM8ujwhaqpHGSppVM4xrbvKTNgduBr0fEm8AVwC7A3sAC4Cct9lmb4FF+M8ujwlH+iBgPjG9uGUmbUITp7yLijrTeKyXzrwTuSm9rgIElqw9IZTRR/jrQW1KX1AotXb5uW/MldQF6peUb5RaqmeVRpS5/OmZ5FfBMRPy0pLxfyWKfAaan1xOAI9MI/U7AYODvwFRgcBrR70oxcDUhIgL4K3B4Wn8scGfJtsam14cD96XlG+UWqpllUcUrpT4KfAl4WtITqey7FKP0ewMBzANOLOoRMyTdCsykOEPglEiVk3QqMAnoDFwdETPS9s4CbpZ0EfBPigAn/Xu9pDnAYooQbpKaCdtWteq159tmxWy9eu8worWrYO/BipXzmhzFbs5b919d0e9s9+HHVbS/tsgtVDPLw5eeOlDNLBNfeupANbNM3EL1KL+ZWS5uoZpZHu7yO1DNLBN3+R2oZpaJW6gOVDPLxIHqQDWzTNzld6CaWSZuoTpQzSwTt1AdqGaWiVuoDlQzy8QtVAeqmWXiFqoD1cwycaA6UM0skzZ6b+WW5EA1szzcQnWgmlkmDlQHqpll4lF+B6qZZeIWqm8wbWaWi1uoZpaHR/kdqGaWibv8DlQzy8SB6kA1s0w8yu9ANbM8otbHUB2oZpaHu/wOVDPLxF1+B6qZZeIuvwPVzDJxl9+BamaZOFAdqBtqwSuv8t0Lf8zrS5YgxOFjDuZLRxzGt/7zv5n34nwAli1fzhabb87t117OXZPu47c33l6//qzn5nLb1Zex+5BdOPbUM3nttcV069YNgPE/+wFb9eldv+zkvz7MN77/A27+zc/Za48h1Cx4hU8fNY5BOwwA4H177s65Z57Wgp++4xo8eGeuu/4X9e8HDRrIRRdewpZb9ebQQw6kNoJXF73GuBO/zcIFi+jduydX/OpH7LzTDvzf229z8klnMnPmLLp168a9k2+hW9dudO7SmT/+8W5+cNElrfjJWpCvlHKgbqgunTtzxmknMHS3XVmxYiVHHH86+39oH35y4Xfql/nRZVeyeY/NADj0oBEcetAIoAjT08++gN2H7FK/7MXnnsleewxZZz8rVqzkhtvu5H1Dd1urfGD/ftx+7eXV+Ggbtdmzn+cjw0YD0KlTJ+Y89xgTJkzijTeWcuEFPwXg5JOP5Tvf+RpfO/17nHHGKTz11Ey+cOSJDBmyC5dccgGHHHI0b7/9NqMPPooVK1bSpUsX/jLl99w76X6mTv1na368luEWavVujiJpd0lnSbo0TWdJ2qNa+2spW/fdkqG77QpAjx6bsfOOA3nl1dfr50cE99z3IKMPHL7OuhMnP8DBn/z3svZz2ZXXcdwXP0fXbl2z1NvKd8ABH+X551/gpZdqWLZseX15jx6bEakVtvseg3ng/kcAmDXrOXbYcQDbbNMXKP4YAmyySRc22aQLwUbScquNyqYOpCqBKuks4GZAwN/TJOAmSWdXY5+toWbBKzwz+znet+e7rcjHn5zOVn36sOPA/ussf8+UB9YJ2v/8r0v4j7Gn8Kvf3lj/yzrzX3NYuOg1/n3//RrZ50IOP/YUjj3lDB5/YnreD2QAHP65T3HbbRPq35973rf516xH+Pznx3DRhUVr9emnn2HMmFEAfHDf97PDDv3Zvv92QNHC/dujE5n3wuPcN+Vhpk19ouU/RGuI2sqmDqRaLdTjgQ9FxMURcUOaLgb2S/PavZUr3+Ib37uIs04/kc179Kgvnzj5fkYfuG4r9KkZz9J9000ZvPOg+rIfnnsmf7j+Cq775Y94/MnpTLhnCrW1tfzPZeM547QT1tnG1lv1YfId1/H7ay7njNPGceb5P2T5ihVV+Xwbq0022YTRoz/JH+6YWF92/nk/Zrch+3PLLXdy4kljAfjJj6+gV++e/O3RiZx80liefHIGtWuKcKitreUjw0YzZPBH+OC+72fo0HUP6XRIbqFWLVBrge0bKe+X5jVK0jhJ0yRN+811N1Wpau/dqtWr+fr3LuKQkQdw4PCP1pevXr2GvzzwCKM+8fF11rn7L+t297fduugi9uixGYcceADTZ85ixcq3mPP8C3z51DMZ+R9jeWrGs5x21vlMf2YWXbt2pXevngDsuftgBvbvx7wXa6r4STc+Iw8azpNPTGfRotfWmXfzzX/ksNQqXbZsOSedeAYfGTaar3zlm/TtuxVz57641vJLl77Jgw/+jQMb+QPbEUVtbUVTR1KtQamvA1MkzQZeSmU7ALsCpza1UkSMB8YDrHrt+Tb5pysiOOe/f8bOOw5k7JGfXWveo9P+yc47DmC7bbZeq7y2tpZJ9z3Etb/8UX3Z6tVrWLZ8OX1692LV6tU88MhjDNt3H7bYvAcPT7ylfrljTz2Tb5/yFfbaYwiLl7xBr55b0LlzZ16qWcCLL73MwP79qvuBNzKf+9ynue22P9W/32WXQTz33DwADj30QP416zkAevXqycqVb7Fq1SqO/fKR/O/Dj7Fs2XL69t2SVatWs3Tpm2y6aTdGjPgYP/3pr1rjo1grqEqgRsQ9koZQdPHrDibWAFMjYk019tlS/vnUDP50zxQG7zKI/xh7CgBfO3EsH99/v9QKHb7OOtOemM522/RdK/zeWbWKE7/5fVatXk3tmlqGfWgfDv/0qGb3/fgT0/nFb66nS5cudOokzjnjVHr13CLr59uYbbZZd0aM+Binn/bd+rILLjyLIYN3pra2lhdfquH0078HwG677cr4K39MRPDMM7P56slnArDddtsw/sqf0LlTJzp16sTtd/yZe+6+r1U+T4vrYN33Sija6LljbbWFauvXe4cRrV0Few9WrJynita76IsV/c72+P4NFe2vLfIzpcwsjyoNSkkaKOmvkmZKmiHpa6l8S0mTJc1O//ZJ5Uqnas6R9JSkD5Rsa2xafraksSXlH5T0dFrnUklqbh9NcaCaWR61tZVN67ca+FZEDAWGAadIGgqcDUyJiMHAlPQe4GBgcJrGAVdAEY7AucCHKQ5HnlsSkFcAJ5SsV3f8ral9NMqBamZ5VKmFGhELIuIf6fUy4BmKsZkxwLVpsWuBw9LrMcB1UXgU6C2pH3AQMDkiFkfEEmAyMCrN6xkRj0ZxDPS6BttqbB+N8qWnZpZHC5ykL2kQsA/wGLBtRCxIsxYC26bX/Xn37CKA+amsufL5jZTTzD4a5RaqmeVRYQu19PzzNI1rbPOSNgduB74eEW+Wzksty6oOZJezD7dQzSyLSk/SLz3/vCmSNqEI099FxB2p+BVJ/SJiQeq2L0rlNcDAktUHpLIaYHiD8vtT+YBGlm9uH41yC9XM8qjeKL+Aq4BnIuKnJbMmAHUj9WOBO0vKj0mj/cOApanbPgkYKalPGowaCUxK896UNCzt65gG22psH41yC9XM8qjeif0fBb4EPC2p7k4z3wUuBm6VdDzwAnBEmjcRGA3MAVYCXwaIiMWSLgSmpuUuiIjF6fVXgWuA7sDdaaKZfTTKgWpmeVRpUCoiHqa4W11jPtHI8gGc0sS2rgaubqR8GrBXI+WvN7aPpjhQzSwPX3rqQDWzPMKB6kA1s0wcqA5UM8ukg93btBIOVDPLwy1UB6qZZeJA9Yn9Zma5uIVqZlm01ZvVtyQHqpnl4S6/A9XMMnGgOlDNLA+f2O9ANbNcHKgOVDPLxOf1O1DNLA93+R2oZpaLA9WBamaZuMvvQDWzPNzld6CaWS5uoTpQzSwPt1AdqGaWi1uoDlQzy6NKz+hrVxyoZpaHA9WBamZ5uIXqG0ybmWXjFqqZ5eEWqgPVzPJwl9+BamaZOFAdqGaWiQO1mUCVtAyou/RB6d9IryMiela5bmbWnoTWv0wH12SgRsQWLVkRM2vf3EIts8sv6WPA4Ij4raS+wBYRMbe6VTOz9iRq3UJdb6BKOhfYF9gN+C3QFbgB+Gh1q2Zm7YlbqOW1UD8D7AP8AyAiXpbkwwFmtpbwMdSyAvWdiAhJASCpR5XrZGbtkFuo5QXqrZJ+DfSWdAJwHHBldatlZu2Nj6GWEagR8WNJBwJvAkOAcyJictVrZmbtSvj+0mWf2P800J3iPNSnq1cdM2uv3EIt425Tkr4C/B34LHA48Kik46pdMTNrX6JWFU0dSTkt1DOAfSLidQBJWwGPAFdXs2Jm1r64y19eoL4OLCt5vyyVmZnV62itzUo02eWX9E1J3wTmAI9JOi+d5P8oMKulKmhmGzdJV0taJGl6Sdl5kmokPZGm0SXzviNpjqR/STqopHxUKpsj6eyS8p0kPZbKb5HUNZV3S+/npPmD1lfX5o6hbpGm54A/8u6NUu4EfNmpma0lQhVNZbgGGNVI+SURsXeaJgJIGgocCeyZ1vmlpM6SOgOXAwcDQ4EvpGUBfpi2tSuwBDg+lR8PLEnll6TlmtXczVHOX+/HNDNLqnVif0Q8WE7rMBkD3BwRbwNzJc0B9kvz5kTE8wCSbgbGSHoGGAEclZa5FjgPuCJt67xU/nvgF5IU0fTR4nKu5d8aOJMi8TetK4+IEWV+QDPbCNS2/KWnp0o6BpgGfCsilgD9KQ5L1pmfygBealD+YWAr4I2IWN3I8v3r1omI1ZKWpuVfa6pC5Tyk73fAs8BOwPnAPGBqGeuZ2Uak0i6/pHGSppVM48rY3RXALsDewALgJ1X9cGUqZ5R/q4i4StLXIuIB4AFJDlQzW0ulo/wRMR4Yv4HrvFL3WtKVwF3pbQ0wsGTRAamMJspfp7isvktqpZYuX7et+ZK6AL1YzxlO5bRQV6V/F0g6RNI+wJZlrGdmG5GIyqZKSOpX8vYzQN0ZABOAI9MI/U7AYIoLk6YCg9OIfleKgasJ6XjoXykuWgIYSzHwXretsen14cB9zR0/hfJaqBdJ6gV8C7gM6Al8o4z1zGwjUq3zUCXdBAwH+kqaD5wLDJe0N8XZR/OAEwEiYoakW4GZwGrglIhYk7ZzKjAJ6AxcHREz0i7OAm6WdBHwT+CqVH4VcH0a2FpMEcLN13U9gdtqVr32fNusmK1X7x08XtmerVg5r6JknL7zoRX9zu71/F0d5oqA5h7Sdxnvnnu6jog4vSo1MrN2yTeYbr7LP63FamFm7V4b7ey2qOZO7L+2JStiZu1bK5yH2uaUez9UM7NmucvvQDWzTNzlb8OB2n37f2vtKpjZBnCX36P8ZpaJu/we5TezTNxC9Si/mVk25d6+7yyKm7L69n1m1iiPSZV/+75n8O37zKwZtaGKpo6knEDdKiKuAlZFxAMRcRzFHa7NzOpV8REo7UY5p02tdfs+4GV8+z4za6BKT0BpV3z7PjPLIuhYrc1KrDdQI6LuTthLgQOqWx0za69qPSpV1ij/b2lkAC8dSzUzA6DWLdSyuvx3lbzelOJxAy9Xpzpm1l65y19el//20vfpcQQPV61GZtYueVCqspujDAa2yV0RM2vf3EIt7xjqMtY+hrqQ4sopM7N6bqGW1+XfoiUqYmbtmwO1jCulJE0pp8zMNm6BKpo6kubuh7opsBnFs7D7QP0n7wn0b4G6mVk7UtuxsrEizXX5TwS+DmwPPM67gfom8Isq18vM2hmfh9r8/VB/Dvxc0mkRcVkL1snM2iFfKFXe3aZqJfWueyOpj6SvVrFOZmbtUjmBekJEvFH3JiKWACdUr0pm1h7VVjh1JOWc2N9ZkiKKh8RK6gx0rW61zKy9qZWPoZYTqPcAt0j6dXp/YiozM6vnY6jlBepZwDjg5PR+MnBl1WpkZu1SR+u+V2K9x1AjojYifhURh0fE4cBMihtNm5nVq1VlU0dS1s1RJO0DfAE4ApgL3FHNSplZ++PzUJu/UmoIRYh+AXgNuAVQRPiu/Wa2Dh9Dbb6F+izwEHBoRMwBkORnSZlZozpa970SzR1D/SywAPirpCslfQLcpjezxvk81GYCNSL+GBFHArsDf6W4rn8bSVdIGtlSFTSz9iEqnDqSckb5V0TEjRHxKWAA8E98g2kza8Cj/OVdelovIpZExPiI+ES1KmRm7ZO7/JU9U8rMbB0dLRwr4UA1syyig3XfK7FBXX4zs6ZUq8sv6WpJiyRNLynbUtJkSbPTv31SuSRdKmmOpKckfaBknbFp+dmSxpaUf1DS02mdS6XiLi9N7aM5DlQzy6KKx1CvAUY1KDsbmBIRg4Ep6T3AwRSPuh9McQ+SK6AIR+Bc4MPAfsC5JQF5BcUtSevWG7WefTTJgWpmWVTrtKmIeBBY3KB4DHBten0tcFhJ+XVReBToLakfcBAwOSIWp3s6TwZGpXk9I+LRdIvS6xpsq7F9NMmBambt0bYRsSC9Xghsm173B14qWW5+KmuufH4j5c3to0kOVDPLotLzUCWNkzStZBq3IftNLcuqXiNQ7j48ym9mWVR62lREjAfGb+Bqr0jqFxELUrd9USqvAQaWLDcgldUAwxuU35/KBzSyfHP7aJJbqGaWRQuf2D8BqBupHwvcWVJ+TBrtHwYsTd32ScDI9JDRPsBIYFKa96akYWl0/5gG22psH01yC9XMsqhWn1vSTRSty76S5lOM1l8M3CrpeOAFins1A0wERgNzgJXAlwEiYrGkC4GpabkLIqJuoOurFGcSdAfuThPN7KPpuqZn77U5Xbr2b5sVM+vgVr9TU9Ep+v+z4xcr+p0984UbOswlAW6hmlkWvvTUgWpmmbhL6UA1s0xqHakOVDPLw11+B6qZZeL2qQPVzDJxC9WBamaZdLTHmVTCgWpmWXhQyoFqZpk4Th2oZpaJj6E6UM0sE3f5fbcpM7Ns3EI1syzcPnWgmlkmPobqQDWzTHwM1YFqZpk4Th2oZpaJu/wOVDPLJNxGdaCaWR5uoTpQzSwTD0r5xP5WcdDI4cyY/iDPznyYM884pbWrYxvA313TosKpI3GgtrBOnTpx6c9/wKGf+iL/7/0H8PnPH8Yeewxu7WpZGfzdNa+WqGjqSByoLWy/D+3Dc8/NY+7cF1m1ahW33nonn/7UQa1dLSuDv7vm1VY4dSQtHqiSvtzS+2xLtu+/HS/Nf7n+/fyaBWy//XatWCMrl7+75kWF/3UkrdFCPb8V9mlmVeYWapVG+SU91dQsYNtm1hsHjANQ51506tSjCrVrXS/XLGTggO3r3w/o34+XX17YijWycvm7a15Ha21WolqnTW0LHAQsaVAu4JGmVoqI8cB4gC5d+3fIb2fqtCfYddedGDRoIDU1CzniiDF86RiPFrcH/u6a19Fam5WoVqDeBWweEU80nCHp/irts11Ys2YNX/v695n45xvp3KkT11x7CzNnzmrtalkZ/N01rzY6ZBtogyja6A+ho7ZQzdq61e/UVPT80i/t+NmKfmevf+GODvO8VF8pZWZZuAXkQDWzTDraSfqVcKCaWRYe5XegmlkmHuV3oJpZJu7yO1DNLBN3+R2oZpaJu/wOVDPLpK2e096SHKhmloWPoTpQzSwTd/kdqGaWiQelfMd+M8ukmo9AkTRP0tOSnpA0LZVtKWmypNnp3z6pXJIulTRH0lOSPlCynbFp+dmSxpaUfzBtf05at6L7CzhQzSyLiKho2gAHRMTeEbFven82MCUiBgNT0nuAg4HBaRoHXAFFAAPnAh8G9gPOrQvhtMwJJeuNquRn4EA1syxa4Y79Y4Br0+trgcNKyq+LwqNAb0n9KO7RPDkiFkfEEmAyMCrN6xkRj0aR8NeVbGuDOFDNLIsqP1MqgHslPZ6e7AGwbUQsSK8X8u7TQPoDL5WsOz+VNVc+v5HyDeZBKTPLotLTpkoffZSMT0/vKPWxiKiRtA0wWdKzpTMjIiS1+qiYA9XMWlXpo4+aWaYm/btI0h8ojoG+IqlfRCxI3fZFafEaYGDJ6gNSWQ0wvEH5/al8QCPLbzB3+c0si2oNSknqIWmLutfASGA6MAGoG6kfC9yZXk8Ajkmj/cOApenQwCRgpKQ+aTpXLz0AAAY0SURBVDBqJDApzXtT0rA0un9MybY2iFuoZpZFFa+U2hb4QzqTqQtwY0TcI2kqcKuk44EXgCPS8hOB0cAcYCXwZYCIWCzpQmBqWu6CiFicXn8VuAboDtydpg3mZ0qZ2VoqfabU8AGfrOh39v75f/EzpczMSvmppw5UM8vEcepANbNMfLcpB6qZZeJAdaCaWSZtdYC7JTlQzSwLt1AdqGaWie+H6kA1s0zc5Xegmlkm7vI7UM0sE7dQHahmlolbqA5UM8vEg1IOVDPLxNfy+36oZmbZuIVqZlm4y+9ANbNM3OV3oJpZJm6hOlDNLBO3UB2oZpaJW6gOVDPLxC1UB6qZZeIWqgPVzDKJqG3tKrQ6B6qZZeFr+R2oZpaJ7zblQDWzTNxCdaCaWSZuoTpQzSwTnzblQDWzTHzalAPVzDJxl9+BamaZeFDKgWpmmbiF6jv2m5ll4xaqmWXhUX4Hqpll4i6/A9XMMvGglAPVzDJxC9WBamaZ+BiqA9XMMvGVUg5UM8vELVQHqpll4mOoPrHfzDKJCv8rh6RRkv4laY6ks6v8USrmFqqZZVGtFqqkzsDlwIHAfGCqpAkRMbMqO3wPHKhmlkUVu/z7AXMi4nkASTcDY4A2F6ju8ptZFlHhVIb+wEsl7+ensjanzbZQV79To9auQzVJGhcR41u7HlYZf3/rqvR3VtI4YFxJ0fj2+rN1C7X1jFv/ItaG+fvLJCLGR8S+JVPDMK0BBpa8H5DK2hwHqpm1dVOBwZJ2ktQVOBKY0Mp1alSb7fKbmQFExGpJpwKTgM7A1RExo5Wr1SgHautpl8eIrJ6/vxYUEROBia1dj/WRr24wM8vDx1DNzDJxoLaC9nIZna1L0tWSFkma3tp1sbbHgdrCSi6jOxgYCnxB0tDWrZVtgGuAUa1dCWubHKgtr/4yuoh4B6i7jM7agYh4EFjc2vWwtsmB2vLazWV0ZrZhHKhmZpk4UFteu7mMzsw2jAO15bWby+jMbMM4UFtYRKwG6i6jewa4ta1eRmfrknQT8DdgN0nzJR3f2nWytsNXSpmZZeIWqplZJg5UM7NMHKhmZpk4UM3MMnGgmpll4kDtICStkfSEpOmSbpO02XvY1jWSDk+vf9PczVskDZe0fwX7mCepb7nlDZZZvoH7Ok/Stze0jmYbyoHacbwVEXtHxF7AO8BJpTMlVfR0hoj4SkQ09/zz4cAGB6pZR+RA7ZgeAnZNrceHJE0AZkrqLOlHkqZKekrSiQAq/CLdo/UvwDZ1G5J0v6R90+tRkv4h6UlJUyQNogjub6TW8b9J2lrS7WkfUyV9NK27laR7Jc2Q9BtgvY8clvRHSY+ndcY1mHdJKp8iaetUtouke9I6D0naPccP06xcfqZUB5NaogcD96SiDwB7RcTcFEpLI+JDkroB/yvpXmAfYDeK+7NuC8wErm6w3a2BK4GPp21tGRGLJf0KWB4RP07L3QhcEhEPS9qB4oqwPYBzgYcj4gJJhwDlXGF0XNpHd2CqpNsj4nWgBzAtIr4h6Zy07VMpnvN0UkTMlvRh4JfAiAp+jGYVcaB2HN0lPZFePwRcRdEV/3tEzE3lI4H31R0fBXoBg4GPAzdFxBrgZUn3NbL9YcCDdduKiKbuCfpJYKhU3wDtKWnztI/PpnX/LGlJGZ/pdEmfSa8Hprq+DtQCt6TyG4A70j72B24r2Xe3MvZhlo0DteN4KyL2Li1IwbKitAg4LSImNVhudMZ6dAKGRcT/NVKXskkaThHOH4mIlZLuBzZtYvFI+32j4c/ArCX5GOrGZRJwsqRNACQNkdQDeBD4fDrG2g84oJF1HwU+LmmntO6WqXwZsEXJcvcCp9W9kVQXcA8CR6Wyg4E+66lrL2BJCtPdKVrIdToBda3soygOJbwJzJX0ubQPSXr/evZhlpUDdePyG4rjo/9ID5n7NUUv5Q/A7DTvOoq7Ka0lIl4FxlF0r5/k3S73n4DP1A1KAacD+6ZBr5m8e7bB+RSBPIOi6//ieup6D9BF0jPAxRSBXmcFsF/6DCOAC1L50cDxqX4z8KNlrIX5blNmZpm4hWpmlokD1cwsEweqmVkmDlQzs0wcqGZmmThQzcwycaCamWXiQDUzy+T/Az7CG8v19LqTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmUuAUMBb_9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a46a17be-fce1-448f-ea8b-fa35f32cf527"
      },
      "source": [
        "def plot_roc(name, labels, predictions, **kwargs):\n",
        "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
        "\n",
        "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
        "  plt.xlabel('False positives [%]')\n",
        "  plt.ylabel('True positives [%]')\n",
        "  plt.xlim([-0.5,30])\n",
        "  plt.ylim([70,100.5])\n",
        "  plt.grid(True)\n",
        "  ax = plt.gca()\n",
        "  ax.set_aspect('equal')\n",
        "\n",
        "indices = np.random.randint(0, len(X_to_train), size=(len(Y_test),))\n",
        "\n",
        "train_prediction = new_model.predict(X_to_train[indices], batch_size=BATCH_SIZE, verbose=0)\n",
        "plot_roc(\"Train Baseline\", Y_to_train[indices], train_prediction, color='b')\n",
        "plot_roc(\"Test Baseline\", Y_test, predictions, color='b', linestyle='--')\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6a1a063780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI3GaND0T5HF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a90dc24f-82e0-4d06-f1cf-1f5484350d2d"
      },
      "source": [
        "prediction = np.squeeze(predictions, axis=1)\n",
        "threshold = threshold_value[max_f1_indices]\n",
        "plt.subplot(211)\n",
        "plt.hist(Y_test, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist((prediction>threshold).astype('int'), bins=[0,1,2])\n",
        "\n",
        "fraud_predict = np.unique((prediction>threshold).astype('int'), return_counts=True)\n",
        "fraud_real = np.unique(Y_test, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_predict[1][1]/np.sum(fraud_predict[1])*100,2)) + \"% \" + str(round(fraud_real[1][1]/np.sum(fraud_real[1])*100,2)) + \"%\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 16.31% 18.73%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw9zr52D5agr",
        "colab_type": "text"
      },
      "source": [
        "# ***Output the result into a file for a validation with Kaggle***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tvlyv5V5fsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "26e99796-e5ae-40bb-c56b-82d159b5ada8"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content\")\n",
        "test_transaction = pd.read_csv('test_transaction.csv')\n",
        "test_identity = pd.read_csv('test_identity.csv', names=saved_columns, header=0)\n",
        "test_identity.head(5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663586</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>280290.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3579.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Android 6.0.1</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1280x720</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>LGLS676 Build/MXB48T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663597</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>185210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>271.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie 11.0 for tablet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Trident/7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663601</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>252944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663602</td>\n",
              "      <td>-95.0</td>\n",
              "      <td>328680.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>567.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SM-G9650 Build/R16NW</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  id_01     id_02  ...  id_38  DeviceType                   DeviceInfo\n",
              "0        3663586  -45.0  280290.0  ...      F      mobile  MYA-L13 Build/HUAWEIMYA-L13\n",
              "1        3663588    0.0    3579.0  ...      T      mobile         LGLS676 Build/MXB48T\n",
              "2        3663597   -5.0  185210.0  ...      F     desktop                  Trident/7.0\n",
              "3        3663601  -45.0  252944.0  ...      F      mobile  MYA-L13 Build/HUAWEIMYA-L13\n",
              "4        3663602  -95.0  328680.0  ...      F      mobile         SM-G9650 Build/R16NW\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8CCDZ5bl8V6p",
        "colab": {}
      },
      "source": [
        "dataset_transaction = None\n",
        "to_remove_id = ['DeviceInfo', 'id_30', 'id_31', 'id_33']\n",
        "for column in to_remove_id:\n",
        "  a = test_identity.pop(column)\n",
        "  "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozVs1d5a_wMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a6d12536-7349-42a4-c9b3-391bfbb32307"
      },
      "source": [
        "test_identity.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663586</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>280290.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3579.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>24.0</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663597</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>185210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>271.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>desktop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663601</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>252944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663602</td>\n",
              "      <td>-95.0</td>\n",
              "      <td>328680.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>567.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  id_01     id_02  id_03  ...  id_36  id_37  id_38  DeviceType\n",
              "0        3663586  -45.0  280290.0    NaN  ...      F      T      F      mobile\n",
              "1        3663588    0.0    3579.0    0.0  ...      F      T      T      mobile\n",
              "2        3663597   -5.0  185210.0    NaN  ...      T      T      F     desktop\n",
              "3        3663601  -45.0  252944.0    0.0  ...      F      T      F      mobile\n",
              "4        3663602  -95.0  328680.0    NaN  ...      F      T      F      mobile\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybm-P5WqcRiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove the columns in to_remove_NaN_dataset_transaction and to_remove_NaN_dataset_identity\n",
        "#for column in to_remove_NaN_dataset_transaction:\n",
        "#  test_transaction.pop(column)\n",
        "\n",
        "#for column in to_remove_NaN_dataset_identity:\n",
        "#  test_identity.pop(column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "du0_nSm48V63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a19ab24-3435-48fc-f1be-7962a916e849"
      },
      "source": [
        "merged_data = pd.merge(left=test_transaction, right=test_identity, how='left', left_on='TransactionID', right_on='TransactionID')\n",
        "\n",
        "TransactionID = merged_data.pop('TransactionID')\n",
        "test_transaction = None\n",
        "merged_data.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506691, 428)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkoViKsx6cZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3fa4d58-8b2c-416a-9396-8299560d0ef7"
      },
      "source": [
        "test_transaction = copy.copy(merged_data)\n",
        "merged_data = None\n",
        "float_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "int_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('int64'))].to_list()\n",
        "obj_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "print(len(float_columns_test), len(int_columns_test), len(obj_columns_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "399 2 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrzQZ6nR6wOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_normalization(X, indices, cache_min, cache_max, cache_mean, cache_median):\n",
        "  X_out = copy.copy(X)\n",
        "  #X_out[indices] = (X_out[indices] - cache_mean)/(cache_max - cache_min)\n",
        "  X_out[np.where(np.isnan(X_out))[0]] = cache_median\n",
        "  X_out = (X_out - cache_min)/(cache_max - cache_min)\n",
        "  #X_out[np.where(np.isnan(X_out))[0]] = 0.0\n",
        "  return X_out.astype('float16')  \n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXM75lh_6lhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in float_columns_test:\n",
        "  # Set to float 16\n",
        "  test_transaction[column].astype('float32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  # test_transaction[column + \"_NaN_Code\"] = np.isnan(test_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = test_transaction[column]\n",
        "  indices = np.where(np.isnan(test_transaction[column]) == False)[0]\n",
        "  test_transaction[column] = apply_normalization(X.to_numpy(), indices, cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], cache[column+'_median'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjog0oM7p4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in int_columns_test:\n",
        "  # Set to int 32\n",
        "  test_transaction[column].astype('int32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  # test_transaction[column + \"_NaN_Code\"] = np.isnan(test_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = test_transaction[column]\n",
        "  indices = np.where(np.isnan(test_transaction[column]) == False)[0]\n",
        "  test_transaction[column] = apply_normalization(X.to_numpy(), indices, cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], cache[column+'_median'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egMTT8KB74NL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16146733-a63b-4c79-f9e1-15407c34dfc0"
      },
      "source": [
        "encoded_column = 0\n",
        "for column in obj_columns_test:\n",
        "  ohc = OneHotEncoder(handle_unknown='ignore')\n",
        "  ohc.fit(cache[column])\n",
        "  test_transaction.loc[np.where(test_transaction[column].isnull())[0], column] = 'Null'\n",
        "  encoded = ohc.transform(test_transaction[column].values.reshape(-1,1)).toarray()    \n",
        "  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(cache[column])))])\n",
        "  test_transaction = pd.concat([test_transaction, pd_encoded], axis=1)\n",
        "  encoded_column += len(pd_encoded.columns)\n",
        "\n",
        "print(\"Encoded columns: \" + str(encoded_column))\n",
        "\n",
        "\n",
        "for column in obj_columns_test:\n",
        "  try:\n",
        "    test_transaction.pop(column)\n",
        "  except KeyError:\n",
        "    pass\n",
        "\n",
        "#for column in to_remove:\n",
        "#  try:\n",
        "#    test_transaction.pop(column)\n",
        "#  except KeyError:\n",
        "#    pass\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded columns: 207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC_OOqFi8HrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b25ca5f-25a9-4454-8e4d-86cdff54d104"
      },
      "source": [
        "# Check if we have the same shape with the X_train\n",
        "#print(test_transaction.shape, X_train.shape)\n",
        "print(test_transaction.shape, np.any(np.isnan(test_transaction)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506691, 608) False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTvYWAcGZEGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "0418d63b-8994-46ba-c990-7640babfac19"
      },
      "source": [
        "test_transaction.head(5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>V1</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.000999</td>\n",
              "      <td>0.541016</td>\n",
              "      <td>0.022003</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.159058</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.001055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007980</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010490</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.039398</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.653809</td>\n",
              "      <td>0.653809</td>\n",
              "      <td>0.025085</td>\n",
              "      <td>0.428711</td>\n",
              "      <td>0.024811</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.383057</td>\n",
              "      <td>0.273438</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.419189</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.001534</td>\n",
              "      <td>0.188110</td>\n",
              "      <td>0.022003</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.452393</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.004112</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.232422</td>\n",
              "      <td>0.232422</td>\n",
              "      <td>0.006504</td>\n",
              "      <td>0.623047</td>\n",
              "      <td>0.006435</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.211792</td>\n",
              "      <td>0.733887</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.610840</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.005352</td>\n",
              "      <td>0.199829</td>\n",
              "      <td>0.948242</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.845215</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.256104</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006992</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007538</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.213745</td>\n",
              "      <td>0.213745</td>\n",
              "      <td>0.009293</td>\n",
              "      <td>0.180542</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.124634</td>\n",
              "      <td>0.201904</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.153320</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.008919</td>\n",
              "      <td>0.574219</td>\n",
              "      <td>0.520020</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.238647</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001653</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002659</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002399</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.065552</td>\n",
              "      <td>0.065552</td>\n",
              "      <td>0.038116</td>\n",
              "      <td>0.300049</td>\n",
              "      <td>0.037689</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.221802</td>\n",
              "      <td>0.315186</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.276855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.002127</td>\n",
              "      <td>0.978027</td>\n",
              "      <td>0.704102</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.372803</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000583</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.001055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005318</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004799</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.034332</td>\n",
              "      <td>0.034332</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.020172</td>\n",
              "      <td>0.080139</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.089417</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 608 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionDT  TransactionAmt  ...  DeviceType_1  DeviceType_2\n",
              "0       0.536621        0.000999  ...             0             0\n",
              "1       0.536621        0.001534  ...             0             0\n",
              "2       0.536621        0.005352  ...             0             0\n",
              "3       0.536621        0.008919  ...             0             0\n",
              "4       0.536621        0.002127  ...             0             0\n",
              "\n",
              "[5 rows x 608 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY9vDvpDZdpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "01c36fa5-4730-4c77-d420-b812dc959a8d"
      },
      "source": [
        "# Make the prediction and submit the output\n",
        "#threshold = threshold_value[max_f1_indices]\n",
        "threshold = 0.3\n",
        "#result = (new_model.predict(test_transaction, batch_size=BATCH_SIZE)>threshold).astype('int8')\n",
        "xgboost_used = True\n",
        "result = np.array([])\n",
        "\n",
        "if xgboost_used:\n",
        "  batch_size = 32768 #115200\n",
        "  evaluate_input = np.array(test_transaction)\n",
        "  subset = np.floor(len(evaluate_input)/batch_size).astype('int')\n",
        "  print(\"Batch_size and number of subset: \", batch_size, subset)\n",
        "\n",
        "  for i in range(subset+1):\n",
        "    print(\"Subset: \", i)\n",
        "    if i < subset + 1:\n",
        "      dvalid = xgboost.DMatrix(evaluate_input[batch_size*i:batch_size*(i+1)])\n",
        "    else:\n",
        "      dvalid = xgboost.DMatrix(evaluate_input[batch_size*i:len(evaluate_input)])\n",
        "\n",
        "    if i==0:\n",
        "      result = (new_model.predict(dvalid)>threshold).astype('int8')\n",
        "    else:\n",
        "      temp_result = (new_model.predict(dvalid)>threshold).astype('int8')\n",
        "      result = np.hstack((result, temp_result))\n",
        "else:\n",
        "  result = (new_model.predict(test_transaction, batch_size=BATCH_SIZE)>threshold).astype('int8')\n",
        "\n",
        "print(result.shape)\n",
        "result_pd = pd.DataFrame(result, columns=['isFraud'])\n",
        "data_to_file = pd.concat([TransactionID, result_pd], axis=1)\n",
        "data_to_file.head(5)\n",
        "data_to_file.to_csv(\"./submission.csv\", index=False)\n",
        "#data_to_file.to_csv('/content/gdrive/My Drive/Kaggle/submission.csv', index=False)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch_size and number of subset:  32768 15\n",
            "Subset:  0\n",
            "Subset:  1\n",
            "Subset:  2\n",
            "Subset:  3\n",
            "Subset:  4\n",
            "Subset:  5\n",
            "Subset:  6\n",
            "Subset:  7\n",
            "Subset:  8\n",
            "Subset:  9\n",
            "Subset:  10\n",
            "Subset:  11\n",
            "Subset:  12\n",
            "Subset:  13\n",
            "Subset:  14\n",
            "Subset:  15\n",
            "(506691,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dva2F6mLjpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "932fc583-fb86-4564-9855-445606c88dbc"
      },
      "source": [
        "print(result.shape, temp_result.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15, 32768) (15171,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9099XTi4s2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cff7645a-991c-4bbc-c58c-522a047ab72e"
      },
      "source": [
        "!kaggle competitions submit -c ieee-fraud-detection -f submission.csv -m \"New submission with model_20200915 with threshold {threshold}\""
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 4.83M/4.83M [00:08<00:00, 570kB/s]\n",
            "Successfully submitted to IEEE-CIS Fraud Detection"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORvQlPDjMsaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "3d6a1798-d129-461b-d4d3-859d5fa3bdd5"
      },
      "source": [
        "# Try with a higher threshold\n",
        "threshold = threshold_value[max_f1_indices]\n",
        "xgboost_used = True\n",
        "result = np.array([])\n",
        "\n",
        "if xgboost_used:\n",
        "  batch_size = 32768 #115200\n",
        "  evaluate_input = np.array(test_transaction)\n",
        "  subset = np.floor(len(evaluate_input)/batch_size).astype('int')\n",
        "  print(\"Batch_size and number of subset: \", batch_size, subset)\n",
        "\n",
        "  for i in range(subset+1):\n",
        "    print(\"Subset: \", i)\n",
        "    if i < subset + 1:\n",
        "      dvalid = xgboost.DMatrix(evaluate_input[batch_size*i:batch_size*(i+1)])\n",
        "    else:\n",
        "      dvalid = xgboost.DMatrix(evaluate_input[batch_size*i:len(evaluate_input)])\n",
        "\n",
        "    if i==0:\n",
        "      result = (new_model.predict(dvalid)>threshold).astype('int8')\n",
        "    else:\n",
        "      temp_result = (new_model.predict(dvalid)>threshold).astype('int8')\n",
        "      result = np.hstack((result, temp_result))\n",
        "else:\n",
        "  result = (new_model.predict(test_transaction, batch_size=BATCH_SIZE)>threshold).astype('int8')\n",
        "\n",
        "print(result.shape)\n",
        "result_pd = pd.DataFrame(result, columns=['isFraud'])\n",
        "data_to_file = pd.concat([TransactionID, result_pd], axis=1)\n",
        "data_to_file.head(5)\n",
        "data_to_file.to_csv(\"./submission.csv\", index=False)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch_size and number of subset:  32768 15\n",
            "Subset:  0\n",
            "Subset:  1\n",
            "Subset:  2\n",
            "Subset:  3\n",
            "Subset:  4\n",
            "Subset:  5\n",
            "Subset:  6\n",
            "Subset:  7\n",
            "Subset:  8\n",
            "Subset:  9\n",
            "Subset:  10\n",
            "Subset:  11\n",
            "Subset:  12\n",
            "Subset:  13\n",
            "Subset:  14\n",
            "Subset:  15\n",
            "(506691,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE4PA454M2rh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d9155bd8-7db2-4506-ba6f-aeb41a0f8268"
      },
      "source": [
        "!kaggle competitions submit -c ieee-fraud-detection -f submission.csv -m \"New submission with model_20200915 with threshold {threshold}\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 4.83M/4.83M [00:08<00:00, 587kB/s] \n",
            "Successfully submitted to IEEE-CIS Fraud Detection"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGezGr2PkCbt",
        "colab_type": "text"
      },
      "source": [
        "# ***Debug zone***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gICp4sPm6brq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cabf1835-6318-410e-f196-4382a3037755"
      },
      "source": [
        "print(np.sum(result==[1]), np.sum(result==[1])/len(result)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53593 10.577057812355065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3e2nvzrHir4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fe4ae314-d9e2-483a-9baa-e8b9302f14bf"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohc = OneHotEncoder()\n",
        "a = {'a': ['Null', 'A', 'B', 'C', 'D']}\n",
        "df = pd.DataFrame(a)\n",
        "df\n",
        "encoded = ohc.fit_transform(df['a'].values.reshape(-1,1)).toarray()    \n",
        "pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[\"a\"+\"_\"+str(i) for i in range(len(np.unique(df['a'].astype('str'))))])\n",
        "pd_encoded\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a_0</th>\n",
              "      <th>a_1</th>\n",
              "      <th>a_2</th>\n",
              "      <th>a_3</th>\n",
              "      <th>a_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a_0  a_1  a_2  a_3  a_4\n",
              "0    0    0    0    0    1\n",
              "1    1    0    0    0    0\n",
              "2    0    1    0    0    0\n",
              "3    0    0    1    0    0\n",
              "4    0    0    0    1    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT1lZERzxxsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the similarity of the Object type columns\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "os.chdir(\"/content\")\n",
        "dataset_transaction = pd.read_csv('train_transaction.csv')\n",
        "testset_transaction = pd.read_csv('test_transaction.csv')\n",
        "#dataset_transaction = pd.read_csv('train_identity.csv')\n",
        "#saved_columns = dataset_transaction.columns.to_list()\n",
        "#testset_transaction = pd.read_csv('test_identity.csv', names=saved_columns, header=0)\n",
        "obj_columns_data = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "obj_columns_test = testset_transaction.columns[np.where(testset_transaction.dtypes == np.dtype('O'))].to_list()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3tGlBhr1L4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "8ba7acdc-f221-4e8c-8ed4-9f3cdb4aec71"
      },
      "source": [
        "testset_transaction.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663586</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>280290.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3579.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Android 6.0.1</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1280x720</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>LGLS676 Build/MXB48T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663597</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>185210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>271.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie 11.0 for tablet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Trident/7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663601</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>252944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663602</td>\n",
              "      <td>-95.0</td>\n",
              "      <td>328680.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>567.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SM-G9650 Build/R16NW</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  id_01     id_02  ...  id_38  DeviceType                   DeviceInfo\n",
              "0        3663586  -45.0  280290.0  ...      F      mobile  MYA-L13 Build/HUAWEIMYA-L13\n",
              "1        3663588    0.0    3579.0  ...      T      mobile         LGLS676 Build/MXB48T\n",
              "2        3663597   -5.0  185210.0  ...      F     desktop                  Trident/7.0\n",
              "3        3663601  -45.0  252944.0  ...      F      mobile  MYA-L13 Build/HUAWEIMYA-L13\n",
              "4        3663602  -95.0  328680.0  ...      F      mobile         SM-G9650 Build/R16NW\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y93MXNirztmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "64e681f4-bc1f-438d-e079-90615598fe5e"
      },
      "source": [
        "print(len(obj_columns_data), len(obj_columns_test), set(obj_columns_data) == set(obj_columns_test))\n",
        "print(obj_columns_data)\n",
        "print(obj_columns_test)\n",
        "ignore_columns = ['DeviceInfo', 'id_30', 'id_31', 'id_33']\n",
        "for column in obj_columns_data:\n",
        "  data = np.unique(dataset_transaction[column].to_list())\n",
        "  test = np.unique(testset_transaction[column].to_list())\n",
        "  if not (set(data)==set(test)):\n",
        "    print(column)\n",
        "    if column not in ignore_columns:\n",
        "      print(data, test)\n",
        "      for each_data in test:\n",
        "        if each_data not in data:\n",
        "          print(each_data)\n",
        "    else:\n",
        "      print(column in ignore_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14 14 True\n",
            "['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
            "['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
            "card6\n",
            "['charge card' 'credit' 'debit' 'debit or credit' 'nan'] ['charge card' 'credit' 'debit' 'nan']\n",
            "P_emaildomain\n",
            "['aim.com' 'anonymous.com' 'aol.com' 'att.net' 'bellsouth.net'\n",
            " 'cableone.net' 'centurylink.net' 'cfl.rr.com' 'charter.net' 'comcast.net'\n",
            " 'cox.net' 'earthlink.net' 'embarqmail.com' 'frontier.com'\n",
            " 'frontiernet.net' 'gmail' 'gmail.com' 'gmx.de' 'hotmail.co.uk'\n",
            " 'hotmail.com' 'hotmail.de' 'hotmail.es' 'hotmail.fr' 'icloud.com'\n",
            " 'juno.com' 'live.com' 'live.com.mx' 'live.fr' 'mac.com' 'mail.com'\n",
            " 'me.com' 'msn.com' 'nan' 'netzero.com' 'netzero.net' 'optonline.net'\n",
            " 'outlook.com' 'outlook.es' 'prodigy.net.mx' 'protonmail.com' 'ptd.net'\n",
            " 'q.com' 'roadrunner.com' 'rocketmail.com' 'sbcglobal.net' 'sc.rr.com'\n",
            " 'servicios-ta.com' 'suddenlink.net' 'twc.com' 'verizon.net' 'web.de'\n",
            " 'windstream.net' 'yahoo.co.jp' 'yahoo.co.uk' 'yahoo.com' 'yahoo.com.mx'\n",
            " 'yahoo.de' 'yahoo.es' 'yahoo.fr' 'ymail.com'] ['aim.com' 'anonymous.com' 'aol.com' 'att.net' 'bellsouth.net'\n",
            " 'cableone.net' 'centurylink.net' 'cfl.rr.com' 'charter.net' 'comcast.net'\n",
            " 'cox.net' 'earthlink.net' 'embarqmail.com' 'frontier.com'\n",
            " 'frontiernet.net' 'gmail' 'gmail.com' 'gmx.de' 'hotmail.co.uk'\n",
            " 'hotmail.com' 'hotmail.de' 'hotmail.es' 'hotmail.fr' 'icloud.com'\n",
            " 'juno.com' 'live.com' 'live.com.mx' 'live.fr' 'mac.com' 'mail.com'\n",
            " 'me.com' 'msn.com' 'nan' 'netzero.com' 'netzero.net' 'optonline.net'\n",
            " 'outlook.com' 'outlook.es' 'prodigy.net.mx' 'protonmail.com' 'ptd.net'\n",
            " 'q.com' 'roadrunner.com' 'rocketmail.com' 'sbcglobal.net' 'sc.rr.com'\n",
            " 'scranton.edu' 'servicios-ta.com' 'suddenlink.net' 'twc.com'\n",
            " 'verizon.net' 'web.de' 'windstream.net' 'yahoo.co.jp' 'yahoo.co.uk'\n",
            " 'yahoo.com' 'yahoo.com.mx' 'yahoo.de' 'yahoo.es' 'yahoo.fr' 'ymail.com']\n",
            "scranton.edu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3srvivP2Lap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af6d2251-e790-44fc-ce39-049663c1d3c4"
      },
      "source": [
        "np.where(testset_transaction['P_emaildomain'] == \"scranton.edu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([480814, 480819]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obkPTsTh-prG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4028c33b-0d20-4649-de29-2f82099dba3b"
      },
      "source": [
        "# Check the similarity of the Float columns\n",
        "float_columns_data = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "float_columns_test = testset_transaction.columns[np.where(testset_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "for column in float_columns_data:\n",
        "  if np.max(dataset_transaction[column]) < np.max(testset_transaction[column]):\n",
        "    print(column, np.max(dataset_transaction[column]), np.max(testset_transaction[column]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "card3 231.0 232.0\n",
            "C3 26.0 31.0\n",
            "C5 349.0 376.0\n",
            "C9 210.0 572.0\n",
            "D1 640.0 641.0\n",
            "D2 640.0 641.0\n",
            "D3 819.0 1076.0\n",
            "D4 869.0 1091.0\n",
            "D5 819.0 1088.0\n",
            "D6 873.0 1091.0\n",
            "D7 843.0 1088.0\n",
            "D8 1707.7916259765625 2029.5833740234373\n",
            "D10 876.0 1091.0\n",
            "D11 670.0 883.0\n",
            "D12 648.0 879.0\n",
            "D13 847.0 1066.0\n",
            "D14 878.0 1085.0\n",
            "D15 879.0 1091.0\n",
            "V2 8.0 11.0\n",
            "V3 9.0 11.0\n",
            "V4 6.0 10.0\n",
            "V5 6.0 10.0\n",
            "V6 9.0 13.0\n",
            "V7 9.0 13.0\n",
            "V8 8.0 11.0\n",
            "V9 8.0 11.0\n",
            "V10 4.0 5.0\n",
            "V11 5.0 7.0\n",
            "V12 3.0 4.0\n",
            "V15 7.0 13.0\n",
            "V16 15.0 25.0\n",
            "V19 7.0 13.0\n",
            "V20 15.0 25.0\n",
            "V23 13.0 15.0\n",
            "V24 13.0 29.0\n",
            "V25 7.0 13.0\n",
            "V26 13.0 25.0\n",
            "V27 4.0 7.0\n",
            "V28 4.0 7.0\n",
            "V31 7.0 13.0\n",
            "V32 15.0 25.0\n",
            "V33 7.0 13.0\n",
            "V34 13.0 25.0\n",
            "V35 3.0 4.0\n",
            "V36 5.0 6.0\n",
            "V39 15.0 30.0\n",
            "V40 24.0 31.0\n",
            "V43 8.0 11.0\n",
            "V45 48.0 69.0\n",
            "V46 6.0 8.0\n",
            "V49 5.0 7.0\n",
            "V50 5.0 7.0\n",
            "V51 6.0 8.0\n",
            "V54 6.0 7.0\n",
            "V55 17.0 49.0\n",
            "V60 16.0 17.0\n",
            "V63 7.0 8.0\n",
            "V64 7.0 10.0\n",
            "V66 7.0 8.0\n",
            "V67 8.0 10.0\n",
            "V68 2.0 7.0\n",
            "V70 6.0 8.0\n",
            "V73 7.0 8.0\n",
            "V74 8.0 10.0\n",
            "V75 4.0 5.0\n",
            "V76 6.0 7.0\n",
            "V77 30.0 80.0\n",
            "V78 31.0 80.0\n",
            "V84 7.0 10.0\n",
            "V85 7.0 10.0\n",
            "V86 30.0 80.0\n",
            "V87 30.0 80.0\n",
            "V89 2.0 7.0\n",
            "V91 6.0 8.0\n",
            "V100 28.0 30.0\n",
            "V104 15.0 59.0\n",
            "V106 55.0 80.0\n",
            "V108 7.0 8.0\n",
            "V109 7.0 8.0\n",
            "V110 7.0 8.0\n",
            "V114 6.0 9.0\n",
            "V115 6.0 9.0\n",
            "V116 6.0 9.0\n",
            "V120 3.0 4.0\n",
            "V121 3.0 4.0\n",
            "V122 3.0 4.0\n",
            "V126 160000.0 519038.5\n",
            "V127 160000.0 544500.0\n",
            "V128 160000.0 519038.5\n",
            "V129 55125.0 64800.0\n",
            "V130 55125.0 167200.0\n",
            "V131 55125.0 167200.0\n",
            "V132 93736.0 519038.5\n",
            "V133 133915.0 519038.5\n",
            "V134 98476.0 519038.5\n",
            "V135 90750.0 302500.0\n",
            "V136 90750.0 302500.0\n",
            "V137 90750.0 302500.0\n",
            "V140 33.0 59.0\n",
            "V141 5.0 6.0\n",
            "V142 9.0 11.0\n",
            "V144 62.0 85.0\n",
            "V151 57.0 58.0\n",
            "V159 55125.0 284129.8125\n",
            "V160 641511.4375 3867868.5\n",
            "V162 3300.0 4000.0\n",
            "V163 3300.0 4000.0\n",
            "V164 93736.0 928882.0\n",
            "V165 98476.0 928882.0\n",
            "V166 104060.0 453750.0\n",
            "V169 19.0 39.0\n",
            "V170 48.0 63.0\n",
            "V171 61.0 68.0\n",
            "V172 31.0 37.0\n",
            "V173 7.0 9.0\n",
            "V175 14.0 22.0\n",
            "V176 48.0 239.0\n",
            "V180 83.0 179.0\n",
            "V181 24.0 85.0\n",
            "V182 83.0 125.0\n",
            "V183 41.0 106.0\n",
            "V186 38.0 39.0\n",
            "V188 30.0 44.0\n",
            "V189 30.0 44.0\n",
            "V190 42.0 224.0\n",
            "V195 16.0 18.0\n",
            "V196 38.0 41.0\n",
            "V198 21.0 29.0\n",
            "V199 45.0 224.0\n",
            "V200 45.0 47.0\n",
            "V202 104060.0 1065496.5\n",
            "V203 139777.0 1065496.5\n",
            "V204 104060.0 1065496.5\n",
            "V205 55125.0 64800.0\n",
            "V206 55125.0 64800.0\n",
            "V207 55125.0 167200.0\n",
            "V208 3300.0 4000.0\n",
            "V209 8050.0 10000.0\n",
            "V210 3300.0 4000.0\n",
            "V211 92888.0 928882.0\n",
            "V212 129006.0 958320.0\n",
            "V213 97628.0 928882.0\n",
            "V214 104060.0 453750.0\n",
            "V215 104060.0 756250.0\n",
            "V216 104060.0 756250.0\n",
            "V220 25.0 47.0\n",
            "V225 51.0 58.0\n",
            "V226 242.0 870.0\n",
            "V228 54.0 239.0\n",
            "V229 176.0 262.0\n",
            "V230 65.0 262.0\n",
            "V234 121.0 322.0\n",
            "V236 45.0 57.0\n",
            "V242 20.0 27.0\n",
            "V244 22.0 33.0\n",
            "V246 45.0 224.0\n",
            "V257 48.0 224.0\n",
            "V258 66.0 269.0\n",
            "V260 8.0 14.0\n",
            "V261 49.0 89.0\n",
            "V262 20.0 34.0\n",
            "V263 153600.0 1065496.5\n",
            "V264 153600.0 1065496.5\n",
            "V265 153600.0 1065496.5\n",
            "V266 55125.0 64800.0\n",
            "V267 55125.0 64800.0\n",
            "V268 55125.0 64800.0\n",
            "V269 55125.0 64800.0\n",
            "V270 4000.0 10791.5703125\n",
            "V271 4000.0 10791.5703125\n",
            "V272 4000.0 10791.5703125\n",
            "V273 51200.0 928882.0\n",
            "V274 66000.0 928882.0\n",
            "V275 51200.0 928882.0\n",
            "V276 104060.0 453750.0\n",
            "V277 104060.0 756250.0\n",
            "V278 104060.0 756250.0\n",
            "V281 22.0 30.0\n",
            "V282 32.0 63.0\n",
            "V296 93.0 179.0\n",
            "V297 12.0 85.0\n",
            "V298 93.0 125.0\n",
            "V299 49.0 106.0\n",
            "V300 11.0 14.0\n",
            "V301 13.0 14.0\n",
            "V304 16.0 17.0\n",
            "V306 108800.0 718740.0\n",
            "V307 145765.0 958320.0\n",
            "V308 108800.0 718740.0\n",
            "V309 55125.0 64800.0\n",
            "V310 55125.0 167200.0\n",
            "V311 55125.0 64800.0\n",
            "V312 55125.0 167200.0\n",
            "V314 7519.8701171875 7539.75\n",
            "V316 93736.0 718740.0\n",
            "V317 134021.0 958320.0\n",
            "V318 98476.0 718740.0\n",
            "V319 104060.0 453750.0\n",
            "V320 104060.0 605000.0\n",
            "V321 104060.0 605000.0\n",
            "V327 18.0 31.0\n",
            "V328 15.0 85.0\n",
            "V329 99.0 125.0\n",
            "V330 55.0 106.0\n",
            "V331 160000.0 1040657.5\n",
            "V332 160000.0 1040657.5\n",
            "V333 160000.0 1040657.5\n",
            "V334 55125.0 64800.0\n",
            "V335 55125.0 64800.0\n",
            "V336 55125.0 64800.0\n",
            "V337 104060.0 375000.0\n",
            "V338 104060.0 612500.0\n",
            "V339 104060.0 612500.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNMYlhLE0XBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e2be45f-af44-477a-bc67-2c0ef26a7733"
      },
      "source": [
        "print(data, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['C' 'H' 'R' 'S' 'W'] ['C' 'H' 'R' 'S' 'W']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vsaGKlzMUlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "69213f3a-42cb-4edc-cbc8-5bc6c0bb5a7e"
      },
      "source": [
        "b = {'a': ['Null', 'A', 'B', 'C', 'E']}\n",
        "df_b = pd.DataFrame(b)\n",
        "ohc_b = OneHotEncoder(handle_unknown='ignore')\n",
        "ohc_b.fit(df['a'].values.reshape(-1,1))\n",
        "encoded_b = ohc_b.transform(df_b['a'].values.reshape(-1,1)).toarray()    \n",
        "pd_encoded_b = pd.DataFrame(encoded_b.astype('int8'), columns=[\"a\"+\"_\"+str(i) for i in range(len(np.unique(df['a'].astype('str'))))])\n",
        "pd_encoded_b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a_0</th>\n",
              "      <th>a_1</th>\n",
              "      <th>a_2</th>\n",
              "      <th>a_3</th>\n",
              "      <th>a_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a_0  a_1  a_2  a_3  a_4\n",
              "0    0    0    0    0    1\n",
              "1    1    0    0    0    0\n",
              "2    0    1    0    0    0\n",
              "3    0    0    1    0    0\n",
              "4    0    0    0    0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvykuaRPMpZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "20c01d2a-8a3b-41b6-a7ae-b6d7a36f327f"
      },
      "source": [
        "for column in obj_columns:\n",
        "  dataset_transaction.loc[np.where(dataset_transaction[column].isnull())[0], column] = 'Null'\n",
        "  print(column, len(np.unique(dataset_transaction[column].astype(\"str\"))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ProductCD 5\n",
            "card4 5\n",
            "card6 5\n",
            "P_emaildomain 60\n",
            "R_emaildomain 61\n",
            "M1 3\n",
            "M2 3\n",
            "M3 3\n",
            "M4 4\n",
            "M5 3\n",
            "M6 3\n",
            "M7 3\n",
            "M8 3\n",
            "M9 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj_RMIz3NTTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2e5b2844-8bdd-45ee-f5ec-83cd54c9cba7"
      },
      "source": [
        "for column in obj_columns_test:\n",
        "  test_transaction.loc[np.where(test_transaction[column].isnull())[0], column] = 'Null'\n",
        "  print(column, len(np.unique(test_transaction[column].astype(\"str\"))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ProductCD 5\n",
            "card4 5\n",
            "card6 4\n",
            "P_emaildomain 61\n",
            "R_emaildomain 61\n",
            "M1 3\n",
            "M2 3\n",
            "M3 3\n",
            "M4 4\n",
            "M5 3\n",
            "M6 3\n",
            "M7 3\n",
            "M8 3\n",
            "M9 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvnTtZ-WUmWS",
        "colab_type": "text"
      },
      "source": [
        "**Train val dataset**"
      ]
    }
  ]
}