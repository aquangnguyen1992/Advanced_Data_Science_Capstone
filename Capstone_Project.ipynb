{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquangnguyen1992/Advanced_Data_Science_Capstone/blob/master/Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE4qbNACq5vY",
        "colab_type": "text"
      },
      "source": [
        "# ***Get the dataset from Kaggle***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28TmZY-0q4mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c302e44-4141-4abe-b44d-2ee2984b6e8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0mVq898tzNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-VLOPU9zZii",
        "colab_type": "text"
      },
      "source": [
        "# ***Analyzing the dataset and doing the cleansing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYzy-sxDzdFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e106312b-0ad0-4fe6-d1c3-90c8600e9723"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBOSTwRzj4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "584580a5-5468-4902-d07d-d40cc0f6c5ac"
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "dataset_transaction = pd.read_csv('train_transaction.csv')\n",
        "dataset_transaction.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoApMJ8vz3IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_identity = pd.read_csv('train_identity.csv')\n",
        "dataset_identity.head(5)\n",
        "saved_columns= np.array(dataset_identity.columns)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmudmokF4Ath",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "75b80361-28ab-4349-8dc8-49d25316f5d6"
      },
      "source": [
        "dataset_identity.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06',\n",
              "       'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14',\n",
              "       'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22',\n",
              "       'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30',\n",
              "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
              "       'DeviceType', 'DeviceInfo'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NesEY-44N6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fe487e80-ac1b-4b38-89f1-501167351676"
      },
      "source": [
        "dataset_transaction.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
              "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
              "       ...\n",
              "       'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338',\n",
              "       'V339'],\n",
              "      dtype='object', length=394)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsvf-Mk5_i_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data transaction\n",
        "float_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "to_remove_NaN_dataset_transaction = []\n",
        "removed = 0\n",
        "for column in float_columns:\n",
        "  count_NaN = np.sum(np.isnan(dataset_transaction[column].values))\n",
        "  if count_NaN/len(dataset_transaction[column].values) > 0.9:\n",
        "    to_remove_NaN_dataset_transaction.append(column)\n",
        "    dataset_transaction.pop(column)\n",
        "    removed += 1\n",
        "print(\"Removed: \" + str(removed))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8KDqiGwlzq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "0188a68b-55de-49ef-9a56-82fd42af0b2a"
      },
      "source": [
        "float_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "to_remove_NaN_dataset_transaction = []\n",
        "removed = 0\n",
        "for column in float_columns:\n",
        "  count_NaN = np.sum(np.isnan(dataset_transaction[column].values))\n",
        "  if count_NaN/len(dataset_transaction[column].values) > 0.9:\n",
        "    to_remove_NaN_dataset_transaction.append(column)\n",
        "\n",
        "for column in to_remove_NaN_dataset_transaction:\n",
        "  print(column)\n",
        "  data_test = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(data_test) == False)[0]\n",
        "  data_b = dataset_transaction.iloc[indices]\n",
        "  indices_fraud = np.where(data_b['isFraud'] == 1)[0]\n",
        "  print(\"Not NaN:\" + str(len(indices)) + \"; \" + str(len(indices_fraud)) + \"; \" + str(len(indices_fraud)/len(indices)*100))\n",
        "\n",
        "  indices = np.where(np.isnan(data_test) == True)[0]\n",
        "  data_b = dataset_transaction.iloc[indices]\n",
        "  indices_fraud = np.where(data_b['isFraud'] == 1)[0]\n",
        "  print(\"% NaN: \" + str(len(indices)/len(data_test)*100))\n",
        "  print(\"NaN:\" + str(len(indices)) + \"; \" + str(len(indices_fraud)) + \"; \" + str(len(indices_fraud)/len(indices)*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dist2\n",
            "Not NaN:37627; 3731; 9.915751986605363\n",
            "% NaN: 93.62837403054831\n",
            "NaN:552913; 16932; 3.0623262610935176\n",
            "D7\n",
            "Not NaN:38917; 5790; 14.877816892360665\n",
            "% NaN: 93.40992989467267\n",
            "NaN:551623; 14873; 2.6962255018373056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUG2UY-KB_Uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset Identity\n",
        "float_columns = dataset_identity.columns[np.where(dataset_identity.dtypes == np.dtype('float64'))].to_list()\n",
        "to_remove_NaN_dataset_identity = []\n",
        "removed = 0\n",
        "for column in float_columns:\n",
        "  count_NaN = np.sum(np.isnan(dataset_identity[column].values))\n",
        "  if count_NaN/len(dataset_identity[column]) > 0.75:\n",
        "    to_remove_NaN_dataset_identity.append(column)\n",
        "    dataset_identity.pop(column)\n",
        "    removed += 1\n",
        "print(\"Removed: \" + str(removed))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4MWdmZ8wBEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_remove_id = ['DeviceInfo', 'id_30', 'id_31', 'id_33']\n",
        "for column in to_remove_id:\n",
        "  dataset_identity.pop(column)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS60VEEMwgHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "591a98db-0ef7-4093-9547-2b8c4db393bd"
      },
      "source": [
        "merged_data = pd.merge(left=dataset_transaction, right=dataset_identity, how='left', left_on='TransactionID', right_on='TransactionID')\n",
        "\n",
        "dataset_transaction = None\n",
        "dataset_identity = None\n",
        "merged_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 430)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa6FhtemGMc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "524c8cc8-8b48-4e1f-c94e-f82fc3701c60"
      },
      "source": [
        "################################# Test ##########################################\n",
        "test_transaction = pd.read_csv('test_transaction.csv')\n",
        "test_identity = pd.read_csv('test_identity.csv', names=saved_columns, header=0)\n",
        "\n",
        "for column in to_remove_id:\n",
        "  test_identity.pop(column)\n",
        "\n",
        "test_merged_data = pd.merge(left=test_transaction, right=test_identity, how='left', left_on='TransactionID', right_on='TransactionID')\n",
        "\n",
        "TransactionID = test_merged_data.pop('TransactionID')\n",
        "test_transaction = None\n",
        "test_identity = None\n",
        "test_merged_data.shape\n",
        "\n",
        "################################################################################"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506691, 428)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIAS8CbdwwET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "82bc08b1-9cc3-44e6-932f-cb89aaa7e8c7"
      },
      "source": [
        "merged_data.tail(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>590535</th>\n",
              "      <td>3577535</td>\n",
              "      <td>0</td>\n",
              "      <td>15811047</td>\n",
              "      <td>49.00</td>\n",
              "      <td>W</td>\n",
              "      <td>6550</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>272.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590536</th>\n",
              "      <td>3577536</td>\n",
              "      <td>0</td>\n",
              "      <td>15811049</td>\n",
              "      <td>39.50</td>\n",
              "      <td>W</td>\n",
              "      <td>10444</td>\n",
              "      <td>225.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>204.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590537</th>\n",
              "      <td>3577537</td>\n",
              "      <td>0</td>\n",
              "      <td>15811079</td>\n",
              "      <td>30.95</td>\n",
              "      <td>W</td>\n",
              "      <td>12037</td>\n",
              "      <td>595.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>231.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590538</th>\n",
              "      <td>3577538</td>\n",
              "      <td>0</td>\n",
              "      <td>15811088</td>\n",
              "      <td>117.00</td>\n",
              "      <td>W</td>\n",
              "      <td>7826</td>\n",
              "      <td>481.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>387.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aol.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590539</th>\n",
              "      <td>3577539</td>\n",
              "      <td>0</td>\n",
              "      <td>15811131</td>\n",
              "      <td>279.95</td>\n",
              "      <td>W</td>\n",
              "      <td>15066</td>\n",
              "      <td>170.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>299.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        TransactionID  isFraud  TransactionDT  ...  id_37 id_38  DeviceType\n",
              "590535        3577535        0       15811047  ...    NaN   NaN         NaN\n",
              "590536        3577536        0       15811049  ...    NaN   NaN         NaN\n",
              "590537        3577537        0       15811079  ...    NaN   NaN         NaN\n",
              "590538        3577538        0       15811088  ...    NaN   NaN         NaN\n",
              "590539        3577539        0       15811131  ...    NaN   NaN         NaN\n",
              "\n",
              "[5 rows x 430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDu1rWAkUafP",
        "colab_type": "text"
      },
      "source": [
        "**Check NaN, Null, and OneHotEncoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtNPHQ2NCbGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a0fd5bf-7345-40c7-a392-4aa49216bbbc"
      },
      "source": [
        "dataset_transaction = copy.copy(merged_data)\n",
        "merged_data = None\n",
        "dataset_identity = None\n",
        "\n",
        "float_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "int_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('int64'))].to_list()\n",
        "obj_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "skip_int_columns = ['TransactionID', 'isFraud']\n",
        "for column in skip_int_columns:\n",
        "  int_columns.remove(column)\n",
        "\n",
        "skip_obj_colums = ['']\n",
        "cache = dict()\n",
        "print(len(float_columns), len(int_columns), len(obj_columns))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "399 2 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4AzwRzqEfth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization_data(X, indices, max_test, min_test):\n",
        "  X_out = copy.copy(X)\n",
        "  X_temp = X[indices]\n",
        "  max_X = np.max([np.max(X_temp), max_test])\n",
        "  min_X = np.min([np.min(X_temp), min_test])\n",
        "  mean_X = np.mean(X_temp)\n",
        "  median_X = np.median(X_temp)\n",
        "  #X_out.iloc[indices] = (X_temp - mean_X)/(max_X - min_X)\n",
        "  X_out.iloc[np.where(np.isnan(X_out))[0]] = median_X\n",
        "  X_out = (X_out - min_X)/(max_X - min_X) # So from -1 to 1\n",
        "\n",
        "  return min_X, max_X, mean_X, median_X, X_out.astype('float16')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-sce8WEFqWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "b4aedace-2b83-45a2-996c-f3daebc51dc3"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70787.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-480.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>32.0</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  id_37 id_38  DeviceType\n",
              "0        2987000        0          86400  ...    NaN   NaN         NaN\n",
              "1        2987001        0          86401  ...    NaN   NaN         NaN\n",
              "2        2987002        0          86469  ...    NaN   NaN         NaN\n",
              "3        2987003        0          86499  ...    NaN   NaN         NaN\n",
              "4        2987004        0          86506  ...      T     T      mobile\n",
              "\n",
              "[5 rows x 430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIIYOrO74QbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1: Detect the columns with NaN and code it with an extra features\n",
        "# Task 2: Apply normalizationn\n",
        "# Task 3: Remove the irrelevant columns\n",
        "for column in float_columns:\n",
        "  # Set to float 16\n",
        "  dataset_transaction[column].astype('float32')\n",
        "\n",
        "  # Code the NaN column for every features\n",
        "  #dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(X) == False)[0]\n",
        "  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], cache[column+'_median'], dataset_transaction[column] = normalization_data(X, indices, np.max(test_merged_data[column]), np.min(test_merged_data[column]))\n",
        "  dataset_transaction[column].astype('float16')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZY_88yeGGSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "49dbf47e-e3fa-4499-c660-67b0a91cd077"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>discover</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>visa</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.070801</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.166626</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.773926</td>\n",
              "      <td>0.078430</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.666504</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  id_37 id_38  DeviceType\n",
              "0        2987000        0          86400  ...    NaN   NaN         NaN\n",
              "1        2987001        0          86401  ...    NaN   NaN         NaN\n",
              "2        2987002        0          86469  ...    NaN   NaN         NaN\n",
              "3        2987003        0          86499  ...    NaN   NaN         NaN\n",
              "4        2987004        0          86506  ...      T     T      mobile\n",
              "\n",
              "[5 rows x 430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43g5UKZPg32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in int_columns:\n",
        "  # Set to int 32\n",
        "  dataset_transaction[column].astype('float32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  #dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(dataset_transaction[column]) == False)[0]\n",
        "  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], cache[column+'_median'], dataset_transaction[column] = normalization_data(X, indices, np.max(test_merged_data[column]), np.min(test_merged_data[column]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW7scgn0-mD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "7fcaa1fd-e9cc-48c4-e927-16929f952d0d"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>W</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>discover</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>W</td>\n",
              "      <td>0.100891</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>W</td>\n",
              "      <td>0.210571</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>visa</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>W</td>\n",
              "      <td>0.984863</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950195</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.422119</td>\n",
              "      <td>0.663086</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>H</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.070801</td>\n",
              "      <td>0.541504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.560547</td>\n",
              "      <td>0.660156</td>\n",
              "      <td>0.590332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.166626</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.511719</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>0.773926</td>\n",
              "      <td>0.078430</td>\n",
              "      <td>0.201538</td>\n",
              "      <td>0.117676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.422363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>0.666504</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 430 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  id_37 id_38  DeviceType\n",
              "0        2987000        0       0.000000  ...    NaN   NaN         NaN\n",
              "1        2987001        0       0.000000  ...    NaN   NaN         NaN\n",
              "2        2987002        0       0.000002  ...    NaN   NaN         NaN\n",
              "3        2987003        0       0.000003  ...    NaN   NaN         NaN\n",
              "4        2987004        0       0.000003  ...      T     T      mobile\n",
              "\n",
              "[5 rows x 430 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDGnSj678SaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f95b1163-39ba-45b5-df49-b8bb49c1f993"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoded_column = 0\n",
        "for column in obj_columns:\n",
        "  ohc = OneHotEncoder()\n",
        "  dataset_transaction.loc[np.where(dataset_transaction[column].isnull())[0], column] = 'Null'\n",
        "  encoded = ohc.fit_transform(dataset_transaction[column].values.reshape(-1,1)).toarray()    \n",
        "  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(dataset_transaction[column].astype('str'))))])\n",
        "  dataset_transaction = pd.concat([dataset_transaction, pd_encoded], axis=1)\n",
        "  cache[column] = dataset_transaction[column].values.reshape(-1,1)\n",
        "  encoded_column += len(pd_encoded.columns)\n",
        "\n",
        "print(\"Encoded columns: \" + str(encoded_column))\n",
        "for column in obj_columns:\n",
        "  try:\n",
        "    dataset_transaction.pop(column)\n",
        "  except KeyError:\n",
        "    pass\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded columns: 207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuvQmMmLRnM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "0d0e20aa-d4e5-4aa0-e827-30ee7a706af6"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>0.070496</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.100891</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.210571</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.393066</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.984863</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.076965</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.013748</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 610 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  DeviceType_1  DeviceType_2\n",
              "0        2987000        0  ...             0             0\n",
              "1        2987001        0  ...             0             0\n",
              "2        2987002        0  ...             0             0\n",
              "3        2987003        0  ...             0             0\n",
              "4        2987004        0  ...             0             1\n",
              "\n",
              "[5 rows x 610 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e626putLzCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b6cbefb-ac4d-4863-a139-fbbd2274e642"
      },
      "source": [
        "print(np.any(np.isnan(dataset_transaction)), np.any(dataset_transaction.isnull()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2H9ryz7bHU",
        "colab_type": "text"
      },
      "source": [
        "**Apply Seaborn to preliminary analyze the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoc4TuIx1zoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8ac64e9a-144f-4b81-8eb1-998c86136164"
      },
      "source": [
        "out = ['isFraud']\n",
        "for column in dataset_transaction.columns:\n",
        "  if column.find('R_emaildomain') != -1:\n",
        "    out.append(column)\n",
        "  if column.find('P_emaildomain') != -1:\n",
        "    out.append(column)\n",
        "print(out)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['isFraud', 'P_emaildomain_0', 'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'P_emaildomain_4', 'P_emaildomain_5', 'P_emaildomain_6', 'P_emaildomain_7', 'P_emaildomain_8', 'P_emaildomain_9', 'P_emaildomain_10', 'P_emaildomain_11', 'P_emaildomain_12', 'P_emaildomain_13', 'P_emaildomain_14', 'P_emaildomain_15', 'P_emaildomain_16', 'P_emaildomain_17', 'P_emaildomain_18', 'P_emaildomain_19', 'P_emaildomain_20', 'P_emaildomain_21', 'P_emaildomain_22', 'P_emaildomain_23', 'P_emaildomain_24', 'P_emaildomain_25', 'P_emaildomain_26', 'P_emaildomain_27', 'P_emaildomain_28', 'P_emaildomain_29', 'P_emaildomain_30', 'P_emaildomain_31', 'P_emaildomain_32', 'P_emaildomain_33', 'P_emaildomain_34', 'P_emaildomain_35', 'P_emaildomain_36', 'P_emaildomain_37', 'P_emaildomain_38', 'P_emaildomain_39', 'P_emaildomain_40', 'P_emaildomain_41', 'P_emaildomain_42', 'P_emaildomain_43', 'P_emaildomain_44', 'P_emaildomain_45', 'P_emaildomain_46', 'P_emaildomain_47', 'P_emaildomain_48', 'P_emaildomain_49', 'P_emaildomain_50', 'P_emaildomain_51', 'P_emaildomain_52', 'P_emaildomain_53', 'P_emaildomain_54', 'P_emaildomain_55', 'P_emaildomain_56', 'P_emaildomain_57', 'P_emaildomain_58', 'P_emaildomain_59', 'R_emaildomain_0', 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3', 'R_emaildomain_4', 'R_emaildomain_5', 'R_emaildomain_6', 'R_emaildomain_7', 'R_emaildomain_8', 'R_emaildomain_9', 'R_emaildomain_10', 'R_emaildomain_11', 'R_emaildomain_12', 'R_emaildomain_13', 'R_emaildomain_14', 'R_emaildomain_15', 'R_emaildomain_16', 'R_emaildomain_17', 'R_emaildomain_18', 'R_emaildomain_19', 'R_emaildomain_20', 'R_emaildomain_21', 'R_emaildomain_22', 'R_emaildomain_23', 'R_emaildomain_24', 'R_emaildomain_25', 'R_emaildomain_26', 'R_emaildomain_27', 'R_emaildomain_28', 'R_emaildomain_29', 'R_emaildomain_30', 'R_emaildomain_31', 'R_emaildomain_32', 'R_emaildomain_33', 'R_emaildomain_34', 'R_emaildomain_35', 'R_emaildomain_36', 'R_emaildomain_37', 'R_emaildomain_38', 'R_emaildomain_39', 'R_emaildomain_40', 'R_emaildomain_41', 'R_emaildomain_42', 'R_emaildomain_43', 'R_emaildomain_44', 'R_emaildomain_45', 'R_emaildomain_46', 'R_emaildomain_47', 'R_emaildomain_48', 'R_emaildomain_49', 'R_emaildomain_50', 'R_emaildomain_51', 'R_emaildomain_52', 'R_emaildomain_53', 'R_emaildomain_54', 'R_emaildomain_55', 'R_emaildomain_56', 'R_emaildomain_57', 'R_emaildomain_58', 'R_emaildomain_59', 'R_emaildomain_60']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9BKg6gZ8qS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#columns_to_analyze = ['isFraud', 'DeviceType_0', 'DeviceType_1', 'DeviceType_2', 'id_15_0', 'id_15_1', 'id_15_2', 'id_15_3']#, 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3', 'P_emaildomain_4', 'addr1', 'addr2', 'dist1', 'dist2', 'card1', 'card2', 'card3']\n",
        "columns_to_analyze = out\n",
        "\n",
        "analyzing_data = dataset_transaction[columns_to_analyze]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtWkHi4N7kKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = analyzing_data.corr()\n",
        "to_display = False\n",
        "\n",
        "if to_display:\n",
        "  mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
        "  # Set up the matplotlib figure\n",
        "  f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "  # Generate a custom diverging colormap\n",
        "  cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "  # Draw the heatmap with the mask and correct aspect ratio\n",
        "  sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "              square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD5CKASq2rzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "adbd3dc7-0c3e-47ea-bd2c-19656e24e120"
      },
      "source": [
        "# Remove the weak correlation features\n",
        "col = corr.columns\n",
        "is_fraud = np.where(col=='isFraud')[0][0]\n",
        "col = col.to_list()\n",
        "col.pop(is_fraud)\n",
        "to_remove = []\n",
        "for each_col in col:\n",
        "  if abs(corr['isFraud'][each_col]) < 0.005: # Weak correlation\n",
        "    to_remove.append(each_col)\n",
        "    a = dataset_transaction.pop(each_col)\n",
        "print(len(to_remove))\n",
        "analyzing_data = None\n",
        "\n",
        "\n",
        "dataset_transaction.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>0.070496</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.100891</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.210571</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.393066</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.984863</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.076965</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.013748</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 522 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  DeviceType_1  DeviceType_2\n",
              "0        2987000        0  ...             0             0\n",
              "1        2987001        0  ...             0             0\n",
              "2        2987002        0  ...             0             0\n",
              "3        2987003        0  ...             0             0\n",
              "4        2987004        0  ...             0             1\n",
              "\n",
              "[5 rows x 522 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rf6--7Dn6PZ",
        "colab_type": "text"
      },
      "source": [
        "# ***Creat the train/val dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV-8fmFWoOnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a69d2845-9871-462e-e636-2e5cad9095b8"
      },
      "source": [
        "# Create a copy\n",
        "dataset = copy.copy(dataset_transaction)\n",
        "\n",
        "# Remove the irrelevant columns\n",
        "a = dataset.pop('TransactionID')\n",
        "dataset.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>0.488525</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.021835</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.012085</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>0.070496</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.100891</td>\n",
              "      <td>0.607910</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.511230</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001847</td>\n",
              "      <td>0.210571</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.522949</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.393066</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.339111</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.984863</td>\n",
              "      <td>0.934082</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.001748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.174683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.076965</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.165283</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.201050</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.014595</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151367</td>\n",
              "      <td>0.007435</td>\n",
              "      <td>0.122009</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.013748</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.114990</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 609 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   isFraud  TransactionDT  ...  DeviceType_1  DeviceType_2\n",
              "0        0       0.000000  ...             0             0\n",
              "1        0       0.000000  ...             0             0\n",
              "2        0       0.000002  ...             0             0\n",
              "3        0       0.000003  ...             0             0\n",
              "4        0       0.000003  ...             0             1\n",
              "\n",
              "[5 rows x 609 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7KODCOzZbOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = dataset['isFraud']\n",
        "dataset.pop('isFraud')\n",
        "X = dataset\n",
        "X_train = X\n",
        "Y_train = Y"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyHSb5S3bDdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "32139a9e-8b7d-4a3f-ac68-a962e6e23a1d"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.hist(Y_train, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist(Y_train, bins=[0,1,2])\n",
        "\n",
        "fraud_count = np.unique(Y_train, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 3.5%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FZY_7rXajHM",
        "colab_type": "text"
      },
      "source": [
        "**Downsampling and upsampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYnuyBs27aRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8805e067-cc40-4f51-b796-d8ed73daffdd"
      },
      "source": [
        "downsampling_factor = 1\n",
        "indices_1 = np.argwhere(np.array(Y_train)==1)\n",
        "indices_0_new = np.argwhere(np.array(Y_train)==0)\n",
        "indices = np.arange(0,len(indices_0_new),downsampling_factor)\n",
        "#indices_test = [i for i in range(len(indices_0_new)) if i not in indices]\n",
        "indices_0_train = indices_0_new[indices]\n",
        "#indices_0_test = indices_0_new[indices_test]\n",
        "indices_0_test = np.delete(indices_0_new, indices)\n",
        "print(indices_0_train.shape, indices_0_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569877, 1) (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_kQE1U9amFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3a72549-f563-41f8-c899-363c3982a1e9"
      },
      "source": [
        "'''downsampling_factor = 2\n",
        "indices_1 = np.argwhere(np.array(Y_train)==1)\n",
        "indices_0_new = np.argwhere(np.array(Y_train)==0)\n",
        "indices = np.arange(0,len(indices_0_new),downsampling_factor)\n",
        "indices_0_new = indices_0_new[indices]\n",
        "\n",
        "print(indices_0_new.shape)'''\n",
        "\n",
        "upsampling_factor = 5\n",
        "indices_1_new = indices_1\n",
        "for i in range(upsampling_factor):\n",
        "  indices_1_new = np.concatenate((indices_1_new, indices_1), axis=0)\n",
        "\n",
        "indices_0_new = np.concatenate((indices_1_new, indices_0_train), axis=0)\n",
        "\n",
        "indices_0_new = tf.random.shuffle(indices_0_new)\n",
        "\n",
        "X_new = np.array(X_train)[indices_0_new]\n",
        "Y_new = np.array(Y_train)[indices_0_new]\n",
        "\n",
        "X_test_2 = np.array(X_train)[indices_0_test]\n",
        "Y_test_2 = np.array(Y_train)[indices_0_test]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y_new, test_size=0.01)\n",
        "\n",
        "X_to_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[2]))\n",
        "Y_to_train = np.squeeze(Y_train, axis=1)\n",
        "\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[2]))\n",
        "Y_test = np.squeeze(Y_test, axis=1)\n",
        "\n",
        "#X_test_2 = np.squeeze(X_test_2, axis=1)\n",
        "#Y_test_2 = np.squeeze(Y_test_2, axis=1)\n",
        "\n",
        "print(X_to_train.shape, X_test.shape, X_test_2.shape, Y_test_2.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(625547, 608) (6319, 608) (0, 608) (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC9Foj6lbEvL",
        "colab_type": "text"
      },
      "source": [
        "**Check the imbalane of the train/test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvCbtngmd6iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "be130236-d411-48f0-84bb-27d9d17b8fde"
      },
      "source": [
        "X_new = None\n",
        "Y_new = None\n",
        "test_merged_data = None\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.hist(Y_to_train, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist(Y_test, bins=[0,1,2])\n",
        "\n",
        "X_train = None\n",
        "Y_train = None\n",
        "X = None\n",
        "Y = None\n",
        "\n",
        "fraud_count = np.unique(Y_to_train, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 9.81%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrhLRRCb6fLl",
        "colab_type": "text"
      },
      "source": [
        "# ***XGBoost***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb8DlzmI6hoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "#import joblib\n",
        "\t\n",
        "# fit model no training data\n",
        "param_dist = {'objective':'binary:logistic', 'n_estimators':5000, 'max_depth': 20,\n",
        "              'learning_rate':0.1, 'alpha': 0.0001,\n",
        "              'eval_metric': 'auc'}\n",
        "model = XGBClassifier(**param_dist)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G06XxGJ4832M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "610b99e8-0227-414a-9002-cf4c02a0867a"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(alpha=0.0001, base_score=0.5, booster='gbtree',\n",
            "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
            "              eval_metric='auc', gamma=0, learning_rate=0.1, max_delta_step=0,\n",
            "              max_depth=20, min_child_weight=1, missing=None, n_estimators=5000,\n",
            "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
            "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
            "              seed=None, silent=None, subsample=1, verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1qYg2ccLs4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "845eb3be-6420-4918-9df4-5ead54cc8a2b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "batch_size = 32768 #115200\n",
        "subset = np.floor(len(X_to_train)/batch_size).astype('int')\n",
        "print(\"Batch_size and number of subset: \", batch_size, subset)\n",
        "pre_list = []\n",
        "re_list = []\n",
        "f1_list = []\n",
        "try:\n",
        "  !mkdir models\n",
        "except:\n",
        "  pass\n",
        "\n",
        "XGB_MODEL_FILE = \"./models/saved_model.pkl.z\"\n",
        "dvalid = xgboost.DMatrix(X_test, label=Y_test)\n",
        "\n",
        "early_stop = 30\n",
        "verbose_eval = False\n",
        "rounds = 100\n",
        "\n",
        "for i in range(subset+1):\n",
        "  print(\"Subset: \", i)\n",
        "  if i < subset + 1:\n",
        "    dtrain = xgboost.DMatrix(X_to_train[batch_size*i:batch_size*(i+1)], \n",
        "                            label = Y_to_train[batch_size*i:batch_size*(i+1)])\n",
        "  else:\n",
        "    dtrain = xgboost.DMatrix(X_to_train[batch_size*i:len(X_to_train)], \n",
        "                              label = Y_to_train[batch_size*i:len(X_to_train)])\n",
        "  if i==0:  \n",
        "    my_model = xgboost.train(param_dist, \n",
        "                            dtrain = dtrain, \n",
        "                            num_boost_round=rounds,\n",
        "                            evals=[(dvalid,'valid'), (dtrain,'train')], \n",
        "                            early_stopping_rounds=early_stop, \n",
        "                            verbose_eval=verbose_eval)\n",
        "  else:\n",
        "    my_model = xgboost.train(param_dist, \n",
        "                            dtrain = dtrain,\n",
        "                            num_boost_round=rounds,\n",
        "                            evals=[(dvalid,'valid'), (dtrain,'train')], \n",
        "                            early_stopping_rounds=early_stop, \n",
        "                            verbose_eval=verbose_eval,\n",
        "                            xgb_model=XGB_MODEL_FILE)    \n",
        "\n",
        "  my_model.save_model(XGB_MODEL_FILE)\n",
        "  \n",
        "  # Evaluate the performance after each subset\n",
        "  predictions = (my_model.predict(dvalid)>0.5).astype('int')\n",
        "  actuals = Y_test\n",
        "  tn, fp, fn, tp = confusion_matrix(actuals, predictions).ravel()\n",
        "  pre = tp*1.0/(tp + fp)\n",
        "  re = tp*1.0/(tp + fn)\n",
        "  f1 = 2.0*pre*re/(pre+re)\n",
        "  print(tn, fp, fn, tp, f1)\n",
        "  pre_list.append(pre)\n",
        "  re_list.append(re)\n",
        "  f1_list.append(f1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch_size and number of subset:  32768 19\n",
            "Subset:  0\n",
            "5651 40 275 353 0.6914789422135162\n",
            "Subset:  1\n",
            "5653 38 235 393 0.7422096317280454\n",
            "Subset:  2\n",
            "5653 38 188 440 0.7956600361663653\n",
            "Subset:  3\n",
            "5648 43 164 464 0.8176211453744492\n",
            "Subset:  4\n",
            "5641 50 147 481 0.8300258843830889\n",
            "Subset:  5\n",
            "5649 42 135 493 0.8478073946689596\n",
            "Subset:  6\n",
            "5649 42 128 500 0.8547008547008549\n",
            "Subset:  7\n",
            "5648 43 120 508 0.8617472434266329\n",
            "Subset:  8\n",
            "5640 51 114 514 0.8616932103939647\n",
            "Subset:  9\n",
            "5646 45 105 523 0.8745819397993311\n",
            "Subset:  10\n",
            "5652 39 96 532 0.8874061718098415\n",
            "Subset:  11\n",
            "5655 36 84 544 0.9006622516556292\n",
            "Subset:  12\n",
            "5648 43 87 541 0.8927392739273927\n",
            "Subset:  13\n",
            "5651 40 84 544 0.8976897689768977\n",
            "Subset:  14\n",
            "5657 34 70 558 0.9147540983606557\n",
            "Subset:  15\n",
            "5661 30 72 556 0.9159802306425042\n",
            "Subset:  16\n",
            "5671 20 66 562 0.9289256198347108\n",
            "Subset:  17\n",
            "5659 32 60 568 0.9250814332247558\n",
            "Subset:  18\n",
            "5664 27 57 571 0.9314845024469821\n",
            "Subset:  19\n",
            "5649 42 58 570 0.9193548387096774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KXVRSmDml44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "478a62e5-e32e-4cdf-dd8d-309fcb51512c"
      },
      "source": [
        "plt.plot(f1_list)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6fe034bf60>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh8RewOYA1Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation solutions\n",
        "def precision_cal(y_pred, y_ref):\n",
        "  pre = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    if true_pos == len(indices_positive):\n",
        "      false_pos = 0\n",
        "    else:\n",
        "      false_pos = len(indices_positive) - true_pos\n",
        "\n",
        "    pre = true_pos/(true_pos + false_pos)\n",
        "  return pre\n",
        "\n",
        "def recall_cal(y_pred, y_ref):\n",
        "  recall = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    fals_neg = np.sum(y_ref[np.argwhere(y_pred == 0)])\n",
        "       \n",
        "    recall = true_pos/(true_pos + fals_neg)\n",
        "\n",
        "  return recall\n",
        "\n",
        "def F1_score(model, X_test, y_ref, test_size, threshold=0.5):\n",
        "  test_size = test_size\n",
        "  dtest = xgboost.DMatrix(X_test)\n",
        "  y_pred = (model.predict(dtest)>threshold).astype(int)\n",
        "  \n",
        "  precision = precision_cal(y_pred, y_ref)\n",
        "  recall = recall_cal(y_pred, y_ref)\n",
        "  \n",
        "  return precision, recall, 2*precision*recall/(precision+recall)\n",
        "  #return 0, 0, 0"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edl7rXGkA9K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre = []\n",
        "re = []\n",
        "f1 = []\n",
        "\n",
        "pre_train = []\n",
        "re_train = []\n",
        "f1_train = []\n",
        "\n",
        "new_model = xgboost.Booster({'nthread': 1})\n",
        "new_model.load_model(XGB_MODEL_FILE)\n",
        "\n",
        "threshold_value = []\n",
        "indices = np.random.randint(0, len(X_to_train), size=(len(Y_test),))\n",
        "\n",
        "for i in range(90):\n",
        "  threshold_value.append(0.1+i*0.01)\n",
        "  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_test, Y_test, test_size=len(Y_test), threshold=threshold_value[-1])\n",
        "  \n",
        "  pre.append(temp_pre)\n",
        "  re.append(temp_re)\n",
        "  f1.append(temp_f1)\n",
        "\n",
        "  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_to_train[indices], Y_to_train[indices], test_size=len(Y_to_train[indices]), threshold=threshold_value[-1])\n",
        "\n",
        "  pre_train.append(temp_pre)\n",
        "  re_train.append(temp_re)\n",
        "  f1_train.append(temp_f1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKobGaRwGBAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6a1af334-d1f9-4964-b15f-da72323272ab"
      },
      "source": [
        "plt.plot(threshold_value, f1, 'b')\n",
        "plt.plot(threshold_value, pre, 'r')\n",
        "plt.plot(threshold_value, re, 'g')\n",
        "\n",
        "plt.plot(threshold_value, f1_train, '--b')\n",
        "plt.plot(threshold_value, pre_train, '--r')\n",
        "plt.plot(threshold_value, re_train, '--g')\n",
        "\n",
        "max_f1_indices = np.where(f1==np.max(f1))[0][0]\n",
        "max_f1_train_indices = np.where(f1_train==np.max(f1_train))[0][0]\n",
        "print(max_f1_indices, 0.1+max_f1_indices*0.01, \n",
        "      max_f1_train_indices, 0.1+max_f1_train_indices*0.01,\n",
        "      f1[max_f1_indices],\n",
        "      f1_train[max_f1_train_indices])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26 0.36 40 0.5 0.9261006289308177 0.9553719008264463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geeGh4HLc0Xg",
        "colab_type": "text"
      },
      "source": [
        "# ***The model using NN***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3MD1cOJcye2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrkPujj1hlrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "\n",
        "def create_model(dense1=128, dense2=64, dense3=32, dropout_rate=0.4, l1_rate=0.001, l2_rate=0.001, init_std=0.01, lr=0.001):\n",
        "  out_model = Sequential()\n",
        "  \n",
        "  out_model.add(Dense(dense1, activation='relu',\n",
        "                      input_shape=(X_to_train.shape[1],),\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dense(dense1, activation='relu',\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(dense2, activation='relu',\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(dense3, activation='relu',\n",
        "                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n",
        "                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  out_model.compile(\n",
        "            optimizer=Adam(learning_rate=lr),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=[METRICS])\n",
        "  \n",
        "  return out_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B8icGb9id1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "63babd42-552d-4207-919a-04f9ed5d01c9"
      },
      "source": [
        "#my_model = create_model(dense1=256, dense2=256, dropout_rate=0.4, l1_rate=1e-4, l2_rate=5e-4, init_std=0.1, lr=0.00008)\n",
        "my_model = create_model(dense1=256, dense2=64, dense3=16, dropout_rate=0.425, l1_rate=5e-4, l2_rate=5e-4, init_std=0.01, lr=0.0000001)\n",
        "#my_model = tf.keras.models.load_model('./best_model.h5')\n",
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 256)               155904    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 240,545\n",
            "Trainable params: 239,873\n",
            "Non-trainable params: 672\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UTsRGUjjzpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4023feef-a03d-4451-8c1a-c94491171af1"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "NB_EPOCH = 2000\n",
        "PATIENCE = 25\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_auc', patience=PATIENCE, verbose=0, mode='max',\n",
        "    baseline=None)\n",
        "\n",
        "best_model_hold = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='./best_model.h5', monitor='val_auc', verbose=1, save_best_only=True,\n",
        "    save_weights_only=False, mode='max')\n",
        "\n",
        "history = my_model.fit(X_to_train, Y_to_train, verbose=0,\n",
        "             batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "             validation_split=0.01, shuffle=True,\n",
        "             callbacks=[early_stop, best_model_hold])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_auc improved from -inf to 0.69593, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00002: val_auc improved from 0.69593 to 0.72392, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00003: val_auc improved from 0.72392 to 0.74232, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00004: val_auc improved from 0.74232 to 0.75332, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00005: val_auc improved from 0.75332 to 0.76131, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00006: val_auc improved from 0.76131 to 0.76751, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00007: val_auc improved from 0.76751 to 0.77188, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00008: val_auc improved from 0.77188 to 0.77643, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00009: val_auc improved from 0.77643 to 0.78053, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00010: val_auc improved from 0.78053 to 0.78484, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00011: val_auc improved from 0.78484 to 0.78870, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00012: val_auc improved from 0.78870 to 0.79245, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00013: val_auc improved from 0.79245 to 0.79454, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00014: val_auc improved from 0.79454 to 0.79766, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00015: val_auc improved from 0.79766 to 0.79980, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00016: val_auc improved from 0.79980 to 0.80247, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00017: val_auc improved from 0.80247 to 0.80421, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00018: val_auc improved from 0.80421 to 0.80645, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00019: val_auc improved from 0.80645 to 0.80755, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00020: val_auc improved from 0.80755 to 0.80941, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00021: val_auc improved from 0.80941 to 0.81027, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00022: val_auc improved from 0.81027 to 0.81198, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00023: val_auc improved from 0.81198 to 0.81252, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00024: val_auc improved from 0.81252 to 0.81375, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00025: val_auc improved from 0.81375 to 0.81469, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00026: val_auc improved from 0.81469 to 0.81574, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00027: val_auc improved from 0.81574 to 0.81665, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00028: val_auc improved from 0.81665 to 0.81736, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00029: val_auc improved from 0.81736 to 0.81818, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00030: val_auc improved from 0.81818 to 0.81916, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00031: val_auc improved from 0.81916 to 0.81960, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00032: val_auc improved from 0.81960 to 0.82024, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00033: val_auc improved from 0.82024 to 0.82118, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00034: val_auc improved from 0.82118 to 0.82185, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00035: val_auc improved from 0.82185 to 0.82223, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00036: val_auc improved from 0.82223 to 0.82288, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00037: val_auc improved from 0.82288 to 0.82338, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00038: val_auc improved from 0.82338 to 0.82403, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00039: val_auc improved from 0.82403 to 0.82460, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00040: val_auc improved from 0.82460 to 0.82544, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00041: val_auc improved from 0.82544 to 0.82597, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00042: val_auc improved from 0.82597 to 0.82646, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00043: val_auc improved from 0.82646 to 0.82716, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00044: val_auc improved from 0.82716 to 0.82741, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00045: val_auc improved from 0.82741 to 0.82812, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00046: val_auc improved from 0.82812 to 0.82859, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00047: val_auc improved from 0.82859 to 0.82908, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00048: val_auc improved from 0.82908 to 0.82968, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00049: val_auc improved from 0.82968 to 0.83007, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00050: val_auc improved from 0.83007 to 0.83025, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00051: val_auc improved from 0.83025 to 0.83118, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00052: val_auc improved from 0.83118 to 0.83161, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00053: val_auc improved from 0.83161 to 0.83247, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00054: val_auc did not improve from 0.83247\n",
            "\n",
            "Epoch 00055: val_auc improved from 0.83247 to 0.83292, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00056: val_auc improved from 0.83292 to 0.83323, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00057: val_auc improved from 0.83323 to 0.83394, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00058: val_auc improved from 0.83394 to 0.83443, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00059: val_auc improved from 0.83443 to 0.83451, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00060: val_auc improved from 0.83451 to 0.83516, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00061: val_auc improved from 0.83516 to 0.83581, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00062: val_auc improved from 0.83581 to 0.83586, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00063: val_auc improved from 0.83586 to 0.83693, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00064: val_auc did not improve from 0.83693\n",
            "\n",
            "Epoch 00065: val_auc improved from 0.83693 to 0.83752, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00066: val_auc improved from 0.83752 to 0.83811, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00067: val_auc did not improve from 0.83811\n",
            "\n",
            "Epoch 00068: val_auc improved from 0.83811 to 0.83833, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00069: val_auc improved from 0.83833 to 0.83873, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00070: val_auc improved from 0.83873 to 0.83915, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00071: val_auc improved from 0.83915 to 0.84001, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00072: val_auc improved from 0.84001 to 0.84039, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00073: val_auc did not improve from 0.84039\n",
            "\n",
            "Epoch 00074: val_auc did not improve from 0.84039\n",
            "\n",
            "Epoch 00075: val_auc improved from 0.84039 to 0.84064, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00076: val_auc improved from 0.84064 to 0.84087, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00077: val_auc improved from 0.84087 to 0.84158, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00078: val_auc improved from 0.84158 to 0.84198, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00079: val_auc improved from 0.84198 to 0.84219, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00080: val_auc improved from 0.84219 to 0.84289, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00081: val_auc did not improve from 0.84289\n",
            "\n",
            "Epoch 00082: val_auc improved from 0.84289 to 0.84289, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00083: val_auc improved from 0.84289 to 0.84295, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00084: val_auc improved from 0.84295 to 0.84390, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00085: val_auc improved from 0.84390 to 0.84430, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00086: val_auc improved from 0.84430 to 0.84458, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00087: val_auc improved from 0.84458 to 0.84513, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00088: val_auc did not improve from 0.84513\n",
            "\n",
            "Epoch 00089: val_auc did not improve from 0.84513\n",
            "\n",
            "Epoch 00090: val_auc did not improve from 0.84513\n",
            "\n",
            "Epoch 00091: val_auc improved from 0.84513 to 0.84537, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00092: val_auc improved from 0.84537 to 0.84574, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00093: val_auc improved from 0.84574 to 0.84588, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00094: val_auc improved from 0.84588 to 0.84628, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00095: val_auc improved from 0.84628 to 0.84630, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00096: val_auc improved from 0.84630 to 0.84683, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00097: val_auc did not improve from 0.84683\n",
            "\n",
            "Epoch 00098: val_auc improved from 0.84683 to 0.84714, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00099: val_auc improved from 0.84714 to 0.84772, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00100: val_auc did not improve from 0.84772\n",
            "\n",
            "Epoch 00101: val_auc did not improve from 0.84772\n",
            "\n",
            "Epoch 00102: val_auc did not improve from 0.84772\n",
            "\n",
            "Epoch 00103: val_auc improved from 0.84772 to 0.84836, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00104: val_auc improved from 0.84836 to 0.84871, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00105: val_auc did not improve from 0.84871\n",
            "\n",
            "Epoch 00106: val_auc did not improve from 0.84871\n",
            "\n",
            "Epoch 00107: val_auc did not improve from 0.84871\n",
            "\n",
            "Epoch 00108: val_auc improved from 0.84871 to 0.84899, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00109: val_auc improved from 0.84899 to 0.84922, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00110: val_auc did not improve from 0.84922\n",
            "\n",
            "Epoch 00111: val_auc did not improve from 0.84922\n",
            "\n",
            "Epoch 00112: val_auc did not improve from 0.84922\n",
            "\n",
            "Epoch 00113: val_auc improved from 0.84922 to 0.84994, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00114: val_auc did not improve from 0.84994\n",
            "\n",
            "Epoch 00115: val_auc improved from 0.84994 to 0.85006, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00116: val_auc did not improve from 0.85006\n",
            "\n",
            "Epoch 00117: val_auc improved from 0.85006 to 0.85049, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00118: val_auc improved from 0.85049 to 0.85063, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00119: val_auc did not improve from 0.85063\n",
            "\n",
            "Epoch 00120: val_auc improved from 0.85063 to 0.85076, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00121: val_auc improved from 0.85076 to 0.85078, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00122: val_auc improved from 0.85078 to 0.85091, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00123: val_auc improved from 0.85091 to 0.85112, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00124: val_auc improved from 0.85112 to 0.85163, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00125: val_auc did not improve from 0.85163\n",
            "\n",
            "Epoch 00126: val_auc did not improve from 0.85163\n",
            "\n",
            "Epoch 00127: val_auc did not improve from 0.85163\n",
            "\n",
            "Epoch 00128: val_auc improved from 0.85163 to 0.85227, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00129: val_auc did not improve from 0.85227\n",
            "\n",
            "Epoch 00130: val_auc did not improve from 0.85227\n",
            "\n",
            "Epoch 00131: val_auc improved from 0.85227 to 0.85263, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00132: val_auc did not improve from 0.85263\n",
            "\n",
            "Epoch 00133: val_auc did not improve from 0.85263\n",
            "\n",
            "Epoch 00134: val_auc did not improve from 0.85263\n",
            "\n",
            "Epoch 00135: val_auc did not improve from 0.85263\n",
            "\n",
            "Epoch 00136: val_auc improved from 0.85263 to 0.85293, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00137: val_auc did not improve from 0.85293\n",
            "\n",
            "Epoch 00138: val_auc improved from 0.85293 to 0.85299, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00139: val_auc improved from 0.85299 to 0.85333, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00140: val_auc did not improve from 0.85333\n",
            "\n",
            "Epoch 00141: val_auc improved from 0.85333 to 0.85350, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00142: val_auc did not improve from 0.85350\n",
            "\n",
            "Epoch 00143: val_auc did not improve from 0.85350\n",
            "\n",
            "Epoch 00144: val_auc did not improve from 0.85350\n",
            "\n",
            "Epoch 00145: val_auc improved from 0.85350 to 0.85381, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00146: val_auc improved from 0.85381 to 0.85399, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00147: val_auc improved from 0.85399 to 0.85401, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00148: val_auc improved from 0.85401 to 0.85433, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00149: val_auc improved from 0.85433 to 0.85483, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00150: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00151: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00152: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00153: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00154: val_auc did not improve from 0.85483\n",
            "\n",
            "Epoch 00155: val_auc improved from 0.85483 to 0.85505, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00156: val_auc improved from 0.85505 to 0.85524, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00157: val_auc did not improve from 0.85524\n",
            "\n",
            "Epoch 00158: val_auc improved from 0.85524 to 0.85532, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00159: val_auc did not improve from 0.85532\n",
            "\n",
            "Epoch 00160: val_auc improved from 0.85532 to 0.85558, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00161: val_auc did not improve from 0.85558\n",
            "\n",
            "Epoch 00162: val_auc did not improve from 0.85558\n",
            "\n",
            "Epoch 00163: val_auc did not improve from 0.85558\n",
            "\n",
            "Epoch 00164: val_auc improved from 0.85558 to 0.85586, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00165: val_auc did not improve from 0.85586\n",
            "\n",
            "Epoch 00166: val_auc did not improve from 0.85586\n",
            "\n",
            "Epoch 00167: val_auc improved from 0.85586 to 0.85588, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00168: val_auc improved from 0.85588 to 0.85592, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00169: val_auc improved from 0.85592 to 0.85601, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00170: val_auc did not improve from 0.85601\n",
            "\n",
            "Epoch 00171: val_auc improved from 0.85601 to 0.85639, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00172: val_auc did not improve from 0.85639\n",
            "\n",
            "Epoch 00173: val_auc improved from 0.85639 to 0.85641, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00174: val_auc did not improve from 0.85641\n",
            "\n",
            "Epoch 00175: val_auc improved from 0.85641 to 0.85653, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00176: val_auc improved from 0.85653 to 0.85653, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00177: val_auc improved from 0.85653 to 0.85691, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00178: val_auc improved from 0.85691 to 0.85724, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00179: val_auc did not improve from 0.85724\n",
            "\n",
            "Epoch 00180: val_auc improved from 0.85724 to 0.85727, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00181: val_auc did not improve from 0.85727\n",
            "\n",
            "Epoch 00182: val_auc improved from 0.85727 to 0.85754, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00183: val_auc did not improve from 0.85754\n",
            "\n",
            "Epoch 00184: val_auc did not improve from 0.85754\n",
            "\n",
            "Epoch 00185: val_auc did not improve from 0.85754\n",
            "\n",
            "Epoch 00186: val_auc improved from 0.85754 to 0.85756, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00187: val_auc improved from 0.85756 to 0.85766, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00188: val_auc did not improve from 0.85766\n",
            "\n",
            "Epoch 00189: val_auc did not improve from 0.85766\n",
            "\n",
            "Epoch 00190: val_auc improved from 0.85766 to 0.85769, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00191: val_auc did not improve from 0.85769\n",
            "\n",
            "Epoch 00192: val_auc improved from 0.85769 to 0.85791, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00193: val_auc did not improve from 0.85791\n",
            "\n",
            "Epoch 00194: val_auc improved from 0.85791 to 0.85811, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00195: val_auc did not improve from 0.85811\n",
            "\n",
            "Epoch 00196: val_auc did not improve from 0.85811\n",
            "\n",
            "Epoch 00197: val_auc improved from 0.85811 to 0.85883, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00198: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00199: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00200: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00201: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00202: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00203: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00204: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00205: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00206: val_auc did not improve from 0.85883\n",
            "\n",
            "Epoch 00207: val_auc improved from 0.85883 to 0.85911, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00208: val_auc did not improve from 0.85911\n",
            "\n",
            "Epoch 00209: val_auc did not improve from 0.85911\n",
            "\n",
            "Epoch 00210: val_auc did not improve from 0.85911\n",
            "\n",
            "Epoch 00211: val_auc improved from 0.85911 to 0.85923, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00212: val_auc improved from 0.85923 to 0.85937, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00213: val_auc improved from 0.85937 to 0.85939, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00214: val_auc did not improve from 0.85939\n",
            "\n",
            "Epoch 00215: val_auc did not improve from 0.85939\n",
            "\n",
            "Epoch 00216: val_auc did not improve from 0.85939\n",
            "\n",
            "Epoch 00217: val_auc improved from 0.85939 to 0.85950, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00218: val_auc improved from 0.85950 to 0.85985, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00219: val_auc did not improve from 0.85985\n",
            "\n",
            "Epoch 00220: val_auc improved from 0.85985 to 0.85994, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00221: val_auc did not improve from 0.85994\n",
            "\n",
            "Epoch 00222: val_auc did not improve from 0.85994\n",
            "\n",
            "Epoch 00223: val_auc did not improve from 0.85994\n",
            "\n",
            "Epoch 00224: val_auc improved from 0.85994 to 0.86014, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00225: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00226: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00227: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00228: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00229: val_auc did not improve from 0.86014\n",
            "\n",
            "Epoch 00230: val_auc improved from 0.86014 to 0.86072, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00231: val_auc did not improve from 0.86072\n",
            "\n",
            "Epoch 00232: val_auc improved from 0.86072 to 0.86081, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00233: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00234: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00235: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00236: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00237: val_auc did not improve from 0.86081\n",
            "\n",
            "Epoch 00238: val_auc improved from 0.86081 to 0.86097, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00239: val_auc improved from 0.86097 to 0.86103, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00240: val_auc did not improve from 0.86103\n",
            "\n",
            "Epoch 00241: val_auc improved from 0.86103 to 0.86111, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00242: val_auc did not improve from 0.86111\n",
            "\n",
            "Epoch 00243: val_auc did not improve from 0.86111\n",
            "\n",
            "Epoch 00244: val_auc improved from 0.86111 to 0.86112, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00245: val_auc did not improve from 0.86112\n",
            "\n",
            "Epoch 00246: val_auc did not improve from 0.86112\n",
            "\n",
            "Epoch 00247: val_auc improved from 0.86112 to 0.86115, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00248: val_auc improved from 0.86115 to 0.86153, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00249: val_auc did not improve from 0.86153\n",
            "\n",
            "Epoch 00250: val_auc improved from 0.86153 to 0.86154, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00251: val_auc did not improve from 0.86154\n",
            "\n",
            "Epoch 00252: val_auc improved from 0.86154 to 0.86166, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00253: val_auc improved from 0.86166 to 0.86169, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00254: val_auc improved from 0.86169 to 0.86187, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00255: val_auc did not improve from 0.86187\n",
            "\n",
            "Epoch 00256: val_auc improved from 0.86187 to 0.86192, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00257: val_auc improved from 0.86192 to 0.86195, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00258: val_auc improved from 0.86195 to 0.86223, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00259: val_auc did not improve from 0.86223\n",
            "\n",
            "Epoch 00260: val_auc improved from 0.86223 to 0.86227, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00261: val_auc did not improve from 0.86227\n",
            "\n",
            "Epoch 00262: val_auc improved from 0.86227 to 0.86245, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00263: val_auc did not improve from 0.86245\n",
            "\n",
            "Epoch 00264: val_auc did not improve from 0.86245\n",
            "\n",
            "Epoch 00265: val_auc improved from 0.86245 to 0.86264, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00266: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00267: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00268: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00269: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00270: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00271: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00272: val_auc did not improve from 0.86264\n",
            "\n",
            "Epoch 00273: val_auc improved from 0.86264 to 0.86292, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00274: val_auc did not improve from 0.86292\n",
            "\n",
            "Epoch 00275: val_auc improved from 0.86292 to 0.86305, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00276: val_auc did not improve from 0.86305\n",
            "\n",
            "Epoch 00277: val_auc improved from 0.86305 to 0.86316, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00278: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00279: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00280: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00281: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00282: val_auc did not improve from 0.86316\n",
            "\n",
            "Epoch 00283: val_auc improved from 0.86316 to 0.86340, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00284: val_auc did not improve from 0.86340\n",
            "\n",
            "Epoch 00285: val_auc did not improve from 0.86340\n",
            "\n",
            "Epoch 00286: val_auc improved from 0.86340 to 0.86353, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00287: val_auc improved from 0.86353 to 0.86386, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00288: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00289: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00290: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00291: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00292: val_auc did not improve from 0.86386\n",
            "\n",
            "Epoch 00293: val_auc improved from 0.86386 to 0.86412, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00294: val_auc did not improve from 0.86412\n",
            "\n",
            "Epoch 00295: val_auc did not improve from 0.86412\n",
            "\n",
            "Epoch 00296: val_auc improved from 0.86412 to 0.86424, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00297: val_auc improved from 0.86424 to 0.86427, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00298: val_auc did not improve from 0.86427\n",
            "\n",
            "Epoch 00299: val_auc improved from 0.86427 to 0.86457, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00300: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00301: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00302: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00303: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00304: val_auc did not improve from 0.86457\n",
            "\n",
            "Epoch 00305: val_auc improved from 0.86457 to 0.86478, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00306: val_auc did not improve from 0.86478\n",
            "\n",
            "Epoch 00307: val_auc improved from 0.86478 to 0.86481, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00308: val_auc improved from 0.86481 to 0.86496, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00309: val_auc improved from 0.86496 to 0.86506, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00310: val_auc did not improve from 0.86506\n",
            "\n",
            "Epoch 00311: val_auc did not improve from 0.86506\n",
            "\n",
            "Epoch 00312: val_auc did not improve from 0.86506\n",
            "\n",
            "Epoch 00313: val_auc did not improve from 0.86506\n",
            "\n",
            "Epoch 00314: val_auc improved from 0.86506 to 0.86524, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00315: val_auc improved from 0.86524 to 0.86530, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00316: val_auc did not improve from 0.86530\n",
            "\n",
            "Epoch 00317: val_auc did not improve from 0.86530\n",
            "\n",
            "Epoch 00318: val_auc improved from 0.86530 to 0.86537, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00319: val_auc did not improve from 0.86537\n",
            "\n",
            "Epoch 00320: val_auc improved from 0.86537 to 0.86574, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00321: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00322: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00323: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00324: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00325: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00326: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00327: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00328: val_auc did not improve from 0.86574\n",
            "\n",
            "Epoch 00329: val_auc improved from 0.86574 to 0.86585, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00330: val_auc did not improve from 0.86585\n",
            "\n",
            "Epoch 00331: val_auc improved from 0.86585 to 0.86624, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00332: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00333: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00334: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00335: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00336: val_auc did not improve from 0.86624\n",
            "\n",
            "Epoch 00337: val_auc improved from 0.86624 to 0.86635, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00338: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00339: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00340: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00341: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00342: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00343: val_auc did not improve from 0.86635\n",
            "\n",
            "Epoch 00344: val_auc improved from 0.86635 to 0.86657, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00345: val_auc did not improve from 0.86657\n",
            "\n",
            "Epoch 00346: val_auc did not improve from 0.86657\n",
            "\n",
            "Epoch 00347: val_auc did not improve from 0.86657\n",
            "\n",
            "Epoch 00348: val_auc improved from 0.86657 to 0.86679, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00349: val_auc improved from 0.86679 to 0.86683, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00350: val_auc did not improve from 0.86683\n",
            "\n",
            "Epoch 00351: val_auc did not improve from 0.86683\n",
            "\n",
            "Epoch 00352: val_auc did not improve from 0.86683\n",
            "\n",
            "Epoch 00353: val_auc improved from 0.86683 to 0.86713, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00354: val_auc did not improve from 0.86713\n",
            "\n",
            "Epoch 00355: val_auc did not improve from 0.86713\n",
            "\n",
            "Epoch 00356: val_auc improved from 0.86713 to 0.86723, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00357: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00358: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00359: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00360: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00361: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00362: val_auc did not improve from 0.86723\n",
            "\n",
            "Epoch 00363: val_auc improved from 0.86723 to 0.86740, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00364: val_auc did not improve from 0.86740\n",
            "\n",
            "Epoch 00365: val_auc did not improve from 0.86740\n",
            "\n",
            "Epoch 00366: val_auc did not improve from 0.86740\n",
            "\n",
            "Epoch 00367: val_auc improved from 0.86740 to 0.86772, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00368: val_auc did not improve from 0.86772\n",
            "\n",
            "Epoch 00369: val_auc did not improve from 0.86772\n",
            "\n",
            "Epoch 00370: val_auc improved from 0.86772 to 0.86778, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00371: val_auc did not improve from 0.86778\n",
            "\n",
            "Epoch 00372: val_auc did not improve from 0.86778\n",
            "\n",
            "Epoch 00373: val_auc did not improve from 0.86778\n",
            "\n",
            "Epoch 00374: val_auc improved from 0.86778 to 0.86786, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00375: val_auc did not improve from 0.86786\n",
            "\n",
            "Epoch 00376: val_auc did not improve from 0.86786\n",
            "\n",
            "Epoch 00377: val_auc improved from 0.86786 to 0.86793, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00378: val_auc improved from 0.86793 to 0.86821, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00379: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00380: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00381: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00382: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00383: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00384: val_auc did not improve from 0.86821\n",
            "\n",
            "Epoch 00385: val_auc improved from 0.86821 to 0.86884, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00386: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00387: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00388: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00389: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00390: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00391: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00392: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00393: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00394: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00395: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00396: val_auc did not improve from 0.86884\n",
            "\n",
            "Epoch 00397: val_auc improved from 0.86884 to 0.86885, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00398: val_auc improved from 0.86885 to 0.86890, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00399: val_auc did not improve from 0.86890\n",
            "\n",
            "Epoch 00400: val_auc did not improve from 0.86890\n",
            "\n",
            "Epoch 00401: val_auc improved from 0.86890 to 0.86904, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00402: val_auc improved from 0.86904 to 0.86904, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00403: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00404: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00405: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00406: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00407: val_auc did not improve from 0.86904\n",
            "\n",
            "Epoch 00408: val_auc improved from 0.86904 to 0.86909, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00409: val_auc did not improve from 0.86909\n",
            "\n",
            "Epoch 00410: val_auc improved from 0.86909 to 0.86941, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00411: val_auc did not improve from 0.86941\n",
            "\n",
            "Epoch 00412: val_auc did not improve from 0.86941\n",
            "\n",
            "Epoch 00413: val_auc improved from 0.86941 to 0.86963, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00414: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00415: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00416: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00417: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00418: val_auc did not improve from 0.86963\n",
            "\n",
            "Epoch 00419: val_auc improved from 0.86963 to 0.86989, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00420: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00421: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00422: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00423: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00424: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00425: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00426: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00427: val_auc did not improve from 0.86989\n",
            "\n",
            "Epoch 00428: val_auc improved from 0.86989 to 0.87014, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00429: val_auc did not improve from 0.87014\n",
            "\n",
            "Epoch 00430: val_auc did not improve from 0.87014\n",
            "\n",
            "Epoch 00431: val_auc improved from 0.87014 to 0.87014, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00432: val_auc did not improve from 0.87014\n",
            "\n",
            "Epoch 00433: val_auc improved from 0.87014 to 0.87034, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00434: val_auc improved from 0.87034 to 0.87064, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00435: val_auc did not improve from 0.87064\n",
            "\n",
            "Epoch 00436: val_auc improved from 0.87064 to 0.87069, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00437: val_auc did not improve from 0.87069\n",
            "\n",
            "Epoch 00438: val_auc did not improve from 0.87069\n",
            "\n",
            "Epoch 00439: val_auc improved from 0.87069 to 0.87070, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00440: val_auc improved from 0.87070 to 0.87089, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00441: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00442: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00443: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00444: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00445: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00446: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00447: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00448: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00449: val_auc did not improve from 0.87089\n",
            "\n",
            "Epoch 00450: val_auc improved from 0.87089 to 0.87098, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00451: val_auc did not improve from 0.87098\n",
            "\n",
            "Epoch 00452: val_auc improved from 0.87098 to 0.87132, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00453: val_auc did not improve from 0.87132\n",
            "\n",
            "Epoch 00454: val_auc did not improve from 0.87132\n",
            "\n",
            "Epoch 00455: val_auc did not improve from 0.87132\n",
            "\n",
            "Epoch 00456: val_auc did not improve from 0.87132\n",
            "\n",
            "Epoch 00457: val_auc improved from 0.87132 to 0.87145, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00458: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00459: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00460: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00461: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00462: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00463: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00464: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00465: val_auc did not improve from 0.87145\n",
            "\n",
            "Epoch 00466: val_auc improved from 0.87145 to 0.87151, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00467: val_auc did not improve from 0.87151\n",
            "\n",
            "Epoch 00468: val_auc improved from 0.87151 to 0.87164, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00469: val_auc did not improve from 0.87164\n",
            "\n",
            "Epoch 00470: val_auc did not improve from 0.87164\n",
            "\n",
            "Epoch 00471: val_auc improved from 0.87164 to 0.87173, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00472: val_auc improved from 0.87173 to 0.87201, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00473: val_auc did not improve from 0.87201\n",
            "\n",
            "Epoch 00474: val_auc did not improve from 0.87201\n",
            "\n",
            "Epoch 00475: val_auc improved from 0.87201 to 0.87208, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00476: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00477: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00478: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00479: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00480: val_auc did not improve from 0.87208\n",
            "\n",
            "Epoch 00481: val_auc improved from 0.87208 to 0.87217, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00482: val_auc improved from 0.87217 to 0.87218, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00483: val_auc did not improve from 0.87218\n",
            "\n",
            "Epoch 00484: val_auc did not improve from 0.87218\n",
            "\n",
            "Epoch 00485: val_auc did not improve from 0.87218\n",
            "\n",
            "Epoch 00486: val_auc improved from 0.87218 to 0.87228, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00487: val_auc did not improve from 0.87228\n",
            "\n",
            "Epoch 00488: val_auc did not improve from 0.87228\n",
            "\n",
            "Epoch 00489: val_auc improved from 0.87228 to 0.87251, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00490: val_auc improved from 0.87251 to 0.87290, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00491: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00492: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00493: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00494: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00495: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00496: val_auc did not improve from 0.87290\n",
            "\n",
            "Epoch 00497: val_auc improved from 0.87290 to 0.87312, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00498: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00499: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00500: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00501: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00502: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00503: val_auc did not improve from 0.87312\n",
            "\n",
            "Epoch 00504: val_auc improved from 0.87312 to 0.87319, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00505: val_auc did not improve from 0.87319\n",
            "\n",
            "Epoch 00506: val_auc improved from 0.87319 to 0.87369, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00507: val_auc did not improve from 0.87369\n",
            "\n",
            "Epoch 00508: val_auc improved from 0.87369 to 0.87381, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00509: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00510: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00511: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00512: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00513: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00514: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00515: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00516: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00517: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00518: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00519: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00520: val_auc did not improve from 0.87381\n",
            "\n",
            "Epoch 00521: val_auc improved from 0.87381 to 0.87400, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00522: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00523: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00524: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00525: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00526: val_auc improved from 0.87400 to 0.87400, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00527: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00528: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00529: val_auc did not improve from 0.87400\n",
            "\n",
            "Epoch 00530: val_auc improved from 0.87400 to 0.87414, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00531: val_auc did not improve from 0.87414\n",
            "\n",
            "Epoch 00532: val_auc did not improve from 0.87414\n",
            "\n",
            "Epoch 00533: val_auc did not improve from 0.87414\n",
            "\n",
            "Epoch 00534: val_auc improved from 0.87414 to 0.87452, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00535: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00536: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00537: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00538: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00539: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00540: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00541: val_auc did not improve from 0.87452\n",
            "\n",
            "Epoch 00542: val_auc improved from 0.87452 to 0.87469, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00543: val_auc did not improve from 0.87469\n",
            "\n",
            "Epoch 00544: val_auc did not improve from 0.87469\n",
            "\n",
            "Epoch 00545: val_auc improved from 0.87469 to 0.87480, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00546: val_auc did not improve from 0.87480\n",
            "\n",
            "Epoch 00547: val_auc improved from 0.87480 to 0.87499, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00548: val_auc did not improve from 0.87499\n",
            "\n",
            "Epoch 00549: val_auc improved from 0.87499 to 0.87518, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00550: val_auc did not improve from 0.87518\n",
            "\n",
            "Epoch 00551: val_auc did not improve from 0.87518\n",
            "\n",
            "Epoch 00552: val_auc improved from 0.87518 to 0.87538, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00553: val_auc did not improve from 0.87538\n",
            "\n",
            "Epoch 00554: val_auc did not improve from 0.87538\n",
            "\n",
            "Epoch 00555: val_auc did not improve from 0.87538\n",
            "\n",
            "Epoch 00556: val_auc did not improve from 0.87538\n",
            "\n",
            "Epoch 00557: val_auc improved from 0.87538 to 0.87542, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00558: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00559: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00560: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00561: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00562: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00563: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00564: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00565: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00566: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00567: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00568: val_auc did not improve from 0.87542\n",
            "\n",
            "Epoch 00569: val_auc improved from 0.87542 to 0.87572, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00570: val_auc did not improve from 0.87572\n",
            "\n",
            "Epoch 00571: val_auc improved from 0.87572 to 0.87573, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00572: val_auc did not improve from 0.87573\n",
            "\n",
            "Epoch 00573: val_auc did not improve from 0.87573\n",
            "\n",
            "Epoch 00574: val_auc did not improve from 0.87573\n",
            "\n",
            "Epoch 00575: val_auc did not improve from 0.87573\n",
            "\n",
            "Epoch 00576: val_auc improved from 0.87573 to 0.87614, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00577: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00578: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00579: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00580: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00581: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00582: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00583: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00584: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00585: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00586: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00587: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00588: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00589: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00590: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00591: val_auc did not improve from 0.87614\n",
            "\n",
            "Epoch 00592: val_auc improved from 0.87614 to 0.87620, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00593: val_auc improved from 0.87620 to 0.87650, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00594: val_auc did not improve from 0.87650\n",
            "\n",
            "Epoch 00595: val_auc improved from 0.87650 to 0.87674, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00596: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00597: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00598: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00599: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00600: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00601: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00602: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00603: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00604: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00605: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00606: val_auc did not improve from 0.87674\n",
            "\n",
            "Epoch 00607: val_auc improved from 0.87674 to 0.87710, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00608: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00609: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00610: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00611: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00612: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00613: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00614: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00615: val_auc did not improve from 0.87710\n",
            "\n",
            "Epoch 00616: val_auc improved from 0.87710 to 0.87724, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00617: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00618: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00619: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00620: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00621: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00622: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00623: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00624: val_auc did not improve from 0.87724\n",
            "\n",
            "Epoch 00625: val_auc improved from 0.87724 to 0.87724, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00626: val_auc improved from 0.87724 to 0.87741, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00627: val_auc did not improve from 0.87741\n",
            "\n",
            "Epoch 00628: val_auc improved from 0.87741 to 0.87765, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00629: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00630: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00631: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00632: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00633: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00634: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00635: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00636: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00637: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00638: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00639: val_auc did not improve from 0.87765\n",
            "\n",
            "Epoch 00640: val_auc improved from 0.87765 to 0.87799, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00641: val_auc did not improve from 0.87799\n",
            "\n",
            "Epoch 00642: val_auc improved from 0.87799 to 0.87814, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00643: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00644: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00645: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00646: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00647: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00648: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00649: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00650: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00651: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00652: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00653: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00654: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00655: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00656: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00657: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00658: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00659: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00660: val_auc improved from 0.87814 to 0.87814, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00661: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00662: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00663: val_auc did not improve from 0.87814\n",
            "\n",
            "Epoch 00664: val_auc improved from 0.87814 to 0.87820, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00665: val_auc did not improve from 0.87820\n",
            "\n",
            "Epoch 00666: val_auc improved from 0.87820 to 0.87826, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00667: val_auc did not improve from 0.87826\n",
            "\n",
            "Epoch 00668: val_auc did not improve from 0.87826\n",
            "\n",
            "Epoch 00669: val_auc improved from 0.87826 to 0.87827, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00670: val_auc improved from 0.87827 to 0.87849, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00671: val_auc improved from 0.87849 to 0.87919, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00672: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00673: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00674: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00675: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00676: val_auc did not improve from 0.87919\n",
            "\n",
            "Epoch 00677: val_auc improved from 0.87919 to 0.87941, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00678: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00679: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00680: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00681: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00682: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00683: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00684: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00685: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00686: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00687: val_auc did not improve from 0.87941\n",
            "\n",
            "Epoch 00688: val_auc improved from 0.87941 to 0.87942, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00689: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00690: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00691: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00692: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00693: val_auc did not improve from 0.87942\n",
            "\n",
            "Epoch 00694: val_auc improved from 0.87942 to 0.87950, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00695: val_auc did not improve from 0.87950\n",
            "\n",
            "Epoch 00696: val_auc improved from 0.87950 to 0.87950, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00697: val_auc did not improve from 0.87950\n",
            "\n",
            "Epoch 00698: val_auc improved from 0.87950 to 0.87956, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00699: val_auc did not improve from 0.87956\n",
            "\n",
            "Epoch 00700: val_auc improved from 0.87956 to 0.87964, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00701: val_auc did not improve from 0.87964\n",
            "\n",
            "Epoch 00702: val_auc did not improve from 0.87964\n",
            "\n",
            "Epoch 00703: val_auc improved from 0.87964 to 0.87978, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00704: val_auc did not improve from 0.87978\n",
            "\n",
            "Epoch 00705: val_auc did not improve from 0.87978\n",
            "\n",
            "Epoch 00706: val_auc did not improve from 0.87978\n",
            "\n",
            "Epoch 00707: val_auc improved from 0.87978 to 0.88005, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00708: val_auc did not improve from 0.88005\n",
            "\n",
            "Epoch 00709: val_auc did not improve from 0.88005\n",
            "\n",
            "Epoch 00710: val_auc improved from 0.88005 to 0.88028, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00711: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00712: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00713: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00714: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00715: val_auc did not improve from 0.88028\n",
            "\n",
            "Epoch 00716: val_auc improved from 0.88028 to 0.88069, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00717: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00718: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00719: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00720: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00721: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00722: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00723: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00724: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00725: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00726: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00727: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00728: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00729: val_auc did not improve from 0.88069\n",
            "\n",
            "Epoch 00730: val_auc improved from 0.88069 to 0.88075, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00731: val_auc did not improve from 0.88075\n",
            "\n",
            "Epoch 00732: val_auc improved from 0.88075 to 0.88079, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00733: val_auc did not improve from 0.88079\n",
            "\n",
            "Epoch 00734: val_auc did not improve from 0.88079\n",
            "\n",
            "Epoch 00735: val_auc did not improve from 0.88079\n",
            "\n",
            "Epoch 00736: val_auc did not improve from 0.88079\n",
            "\n",
            "Epoch 00737: val_auc improved from 0.88079 to 0.88087, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00738: val_auc did not improve from 0.88087\n",
            "\n",
            "Epoch 00739: val_auc improved from 0.88087 to 0.88106, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00740: val_auc did not improve from 0.88106\n",
            "\n",
            "Epoch 00741: val_auc did not improve from 0.88106\n",
            "\n",
            "Epoch 00742: val_auc did not improve from 0.88106\n",
            "\n",
            "Epoch 00743: val_auc improved from 0.88106 to 0.88125, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00744: val_auc did not improve from 0.88125\n",
            "\n",
            "Epoch 00745: val_auc did not improve from 0.88125\n",
            "\n",
            "Epoch 00746: val_auc did not improve from 0.88125\n",
            "\n",
            "Epoch 00747: val_auc did not improve from 0.88125\n",
            "\n",
            "Epoch 00748: val_auc improved from 0.88125 to 0.88130, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00749: val_auc improved from 0.88130 to 0.88183, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00750: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00751: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00752: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00753: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00754: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00755: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00756: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00757: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00758: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00759: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00760: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00761: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00762: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00763: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00764: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00765: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00766: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00767: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00768: val_auc did not improve from 0.88183\n",
            "\n",
            "Epoch 00769: val_auc improved from 0.88183 to 0.88199, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00770: val_auc did not improve from 0.88199\n",
            "\n",
            "Epoch 00771: val_auc did not improve from 0.88199\n",
            "\n",
            "Epoch 00772: val_auc did not improve from 0.88199\n",
            "\n",
            "Epoch 00773: val_auc did not improve from 0.88199\n",
            "\n",
            "Epoch 00774: val_auc improved from 0.88199 to 0.88234, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00775: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00776: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00777: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00778: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00779: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00780: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00781: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00782: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00783: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00784: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00785: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00786: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00787: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00788: val_auc did not improve from 0.88234\n",
            "\n",
            "Epoch 00789: val_auc improved from 0.88234 to 0.88247, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00790: val_auc did not improve from 0.88247\n",
            "\n",
            "Epoch 00791: val_auc did not improve from 0.88247\n",
            "\n",
            "Epoch 00792: val_auc did not improve from 0.88247\n",
            "\n",
            "Epoch 00793: val_auc improved from 0.88247 to 0.88274, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00794: val_auc did not improve from 0.88274\n",
            "\n",
            "Epoch 00795: val_auc did not improve from 0.88274\n",
            "\n",
            "Epoch 00796: val_auc did not improve from 0.88274\n",
            "\n",
            "Epoch 00797: val_auc improved from 0.88274 to 0.88280, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00798: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00799: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00800: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00801: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00802: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00803: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00804: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00805: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00806: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00807: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00808: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00809: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00810: val_auc did not improve from 0.88280\n",
            "\n",
            "Epoch 00811: val_auc improved from 0.88280 to 0.88295, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00812: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00813: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00814: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00815: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00816: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00817: val_auc did not improve from 0.88295\n",
            "\n",
            "Epoch 00818: val_auc improved from 0.88295 to 0.88336, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00819: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00820: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00821: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00822: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00823: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00824: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00825: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00826: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00827: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00828: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00829: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00830: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00831: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00832: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00833: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00834: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00835: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00836: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00837: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00838: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00839: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00840: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00841: val_auc did not improve from 0.88336\n",
            "\n",
            "Epoch 00842: val_auc improved from 0.88336 to 0.88399, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00843: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00844: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00845: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00846: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00847: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00848: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00849: val_auc did not improve from 0.88399\n",
            "\n",
            "Epoch 00850: val_auc improved from 0.88399 to 0.88408, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00851: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00852: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00853: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00854: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00855: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00856: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00857: val_auc did not improve from 0.88408\n",
            "\n",
            "Epoch 00858: val_auc improved from 0.88408 to 0.88409, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00859: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00860: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00861: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00862: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00863: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00864: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00865: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00866: val_auc did not improve from 0.88409\n",
            "\n",
            "Epoch 00867: val_auc improved from 0.88409 to 0.88434, saving model to ./best_model.h5\n",
            "\n",
            "Epoch 00868: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00869: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00870: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00871: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00872: val_auc did not improve from 0.88434\n",
            "\n",
            "Epoch 00873: val_auc did not improve from 0.88434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsIE6_stkBAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_metrics(history):\n",
        "  metrics =  ['loss', 'auc', 'precision', 'recall']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1) \n",
        "    plt.plot(history.epoch,  history.history[metric], color='b', label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color='b', linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "plot_metrics(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ9tGRoYmd4y",
        "colab_type": "text"
      },
      "source": [
        "**F1 validation (From https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKjbrzEe2ISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model weights to drive\n",
        "!cp -r best_model.h5 '/content/gdrive/My Drive/Kaggle/best_model_20200828_METRICS.h5'\n",
        "\n",
        "#new_model = tf.keras.models.load_model('./best_model.h5', custom_objects={'LeakyReLU': tf.keras.layers.LeakyReLU(alpha=0.3)})\n",
        "new_model = tf.keras.models.load_model('./best_model.h5')\n",
        "#new_model = tf.keras.models.load_model('/content/gdrive/My Drive/Kaggle/best_model_20200816_METRICS.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMQtd0IsFspQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision_cal(y_pred, y_ref):\n",
        "  pre = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    if true_pos == len(indices_positive):\n",
        "      false_pos = 0\n",
        "    else:\n",
        "      false_pos = len(indices_positive) - true_pos\n",
        "\n",
        "    pre = true_pos/(true_pos + false_pos)\n",
        "  return pre\n",
        "\n",
        "def recall_cal(y_pred, y_ref):\n",
        "  recall = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    fals_neg = np.sum(y_ref[np.argwhere(y_pred == 0)])\n",
        "       \n",
        "    recall = true_pos/(true_pos + fals_neg)\n",
        "\n",
        "  return recall\n",
        "\n",
        "def F1_score(model, X_test, y_ref, test_size, threshold=0.5):\n",
        "  test_size = test_size\n",
        "  y_pred = (model.predict(X_test, batch_size=128)>threshold).astype(int)\n",
        "  y_pred = np.squeeze(y_pred, axis=1)\n",
        " \n",
        "  precision = precision_cal(y_pred, y_ref)\n",
        "  recall = recall_cal(y_pred, y_ref)\n",
        "\n",
        "  return precision, recall, 2*precision*recall/(precision+recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIe0Q-5JmbVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre = []\n",
        "re = []\n",
        "f1 = []\n",
        "\n",
        "pre_train = []\n",
        "re_train = []\n",
        "f1_train = []\n",
        "\n",
        "threshold_value = []\n",
        "indices = np.random.randint(0, len(X_to_train), size=(len(Y_test),))\n",
        "\n",
        "for i in range(90):\n",
        "  threshold_value.append(0.1+i*0.01)\n",
        "  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_test, Y_test, test_size=len(Y_test), threshold=threshold_value[-1])\n",
        "  \n",
        "  pre.append(temp_pre)\n",
        "  re.append(temp_re)\n",
        "  f1.append(temp_f1)\n",
        "\n",
        "  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_to_train[indices], Y_to_train[indices], test_size=len(Y_to_train[indices]), threshold=threshold_value[-1])\n",
        "\n",
        "  pre_train.append(temp_pre)\n",
        "  re_train.append(temp_re)\n",
        "  f1_train.append(temp_f1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CP4zuNU6WUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "b60eda78-a2c3-4552-c6ba-42dbf9c9113a"
      },
      "source": [
        "plt.plot(threshold_value, f1, 'b')\n",
        "plt.plot(threshold_value, pre, 'r')\n",
        "plt.plot(threshold_value, re, 'g')\n",
        "\n",
        "plt.plot(threshold_value, f1_train, '--b')\n",
        "plt.plot(threshold_value, pre_train, '--r')\n",
        "plt.plot(threshold_value, re_train, '--g')\n",
        "\n",
        "max_f1_indices = np.where(f1==np.max(f1))[0][0]\n",
        "max_f1_train_indices = np.where(f1_train==np.max(f1_train))[0][0]\n",
        "print(f1[max_f1_indices], f1[max_f1_indices-1], f1[max_f1_indices+1], threshold_value[max_f1_indices])\n",
        "print(f1_train[max_f1_train_indices], f1_train[max_f1_train_indices-1], f1_train[max_f1_train_indices+1], threshold_value[max_f1_train_indices])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8190789473684211 0.8166259168704157 0.8129139072847682 0.28\n",
            "0.835978835978836 0.8344947735191638 0.8294849023090586 0.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhwhX0d2C_c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_cm(labels, predictions, p=0.5, display=True):\n",
        "  cm = confusion_matrix(labels, predictions > p)\n",
        "  if display:\n",
        "    plt.figure(figsize=(5,5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
        "    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
        "    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
        "    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
        "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n",
        "  pre = cm[1][1]/(cm[1][1] + cm[0][1])\n",
        "  recall = cm[1][1]/(cm[1][1] + cm[1][0])\n",
        "  f1_score = 2*pre*recall/(pre+recall)\n",
        "  return pre, recall, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2H3PvUGb8KX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "e5817feb-caae-46b0-f992-33e4ac7993e8"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "baseline_results = new_model.evaluate(X_test, Y_test,\n",
        "                                  batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(new_model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "predictions = new_model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
        "\n",
        "plot_cm(Y_test, predictions, p=threshold_value[max_f1_indices], display=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss :  0.5232799053192139\n",
            "tp :  432.0\n",
            "fp :  24.0\n",
            "tn :  2796.0\n",
            "fn :  218.0\n",
            "accuracy :  0.9302593469619751\n",
            "precision :  0.9473684430122375\n",
            "recall :  0.6646153926849365\n",
            "auc :  0.9595742225646973\n",
            "\n",
            "Legitimate Transactions Detected (True Negatives):  2752\n",
            "Legitimate Transactions Incorrectly Detected (False Positives):  68\n",
            "Fraudulent Transactions Missed (False Negatives):  152\n",
            "Fraudulent Transactions Detected (True Positives):  498\n",
            "Total Fraudulent Transactions:  650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8798586572438163, 0.7661538461538462, 0.8190789473684211)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A5VYg4_-NrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "c44f6f32-cdd9-4994-ec2e-c2d39605fc49"
      },
      "source": [
        "# Test with X_test_2 and Y_test_2, should all be 0\n",
        "predictions2 = new_model.predict(X_test_2, batch_size=BATCH_SIZE, verbose=0)\n",
        "\n",
        "plot_cm(Y_test_2, predictions2, p=threshold_value[max_f1_indices], display=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Legitimate Transactions Detected (True Negatives):  277545\n",
            "Legitimate Transactions Incorrectly Detected (False Positives):  7393\n",
            "Fraudulent Transactions Missed (False Negatives):  0\n",
            "Fraudulent Transactions Detected (True Positives):  0\n",
            "Total Fraudulent Transactions:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, nan, nan)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmUuAUMBb_9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a46a17be-fce1-448f-ea8b-fa35f32cf527"
      },
      "source": [
        "def plot_roc(name, labels, predictions, **kwargs):\n",
        "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
        "\n",
        "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
        "  plt.xlabel('False positives [%]')\n",
        "  plt.ylabel('True positives [%]')\n",
        "  plt.xlim([-0.5,30])\n",
        "  plt.ylim([70,100.5])\n",
        "  plt.grid(True)\n",
        "  ax = plt.gca()\n",
        "  ax.set_aspect('equal')\n",
        "\n",
        "indices = np.random.randint(0, len(X_to_train), size=(len(Y_test),))\n",
        "\n",
        "train_prediction = new_model.predict(X_to_train[indices], batch_size=BATCH_SIZE, verbose=0)\n",
        "plot_roc(\"Train Baseline\", Y_to_train[indices], train_prediction, color='b')\n",
        "plot_roc(\"Test Baseline\", Y_test, predictions, color='b', linestyle='--')\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6a1a063780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI3GaND0T5HF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a90dc24f-82e0-4d06-f1cf-1f5484350d2d"
      },
      "source": [
        "prediction = np.squeeze(predictions, axis=1)\n",
        "threshold = threshold_value[max_f1_indices]\n",
        "plt.subplot(211)\n",
        "plt.hist(Y_test, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist((prediction>threshold).astype('int'), bins=[0,1,2])\n",
        "\n",
        "fraud_predict = np.unique((prediction>threshold).astype('int'), return_counts=True)\n",
        "fraud_real = np.unique(Y_test, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_predict[1][1]/np.sum(fraud_predict[1])*100,2)) + \"% \" + str(round(fraud_real[1][1]/np.sum(fraud_real[1])*100,2)) + \"%\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 16.31% 18.73%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw9zr52D5agr",
        "colab_type": "text"
      },
      "source": [
        "# ***Output the result into a file for a validation with Kaggle***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tvlyv5V5fsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "3a8db689-c4e9-4db3-ee25-68f281db9b3b"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content\")\n",
        "test_transaction = pd.read_csv('test_transaction.csv')\n",
        "test_identity = pd.read_csv('test_identity.csv', names=saved_columns, header=0)\n",
        "test_identity.head(5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663586</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>280290.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3579.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Android 6.0.1</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1280x720</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>LGLS676 Build/MXB48T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663597</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>185210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>271.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie 11.0 for tablet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Trident/7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663601</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>252944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663602</td>\n",
              "      <td>-95.0</td>\n",
              "      <td>328680.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>567.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SM-G9650 Build/R16NW</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  id_01     id_02  ...  id_38  DeviceType                   DeviceInfo\n",
              "0        3663586  -45.0  280290.0  ...      F      mobile  MYA-L13 Build/HUAWEIMYA-L13\n",
              "1        3663588    0.0    3579.0  ...      T      mobile         LGLS676 Build/MXB48T\n",
              "2        3663597   -5.0  185210.0  ...      F     desktop                  Trident/7.0\n",
              "3        3663601  -45.0  252944.0  ...      F      mobile  MYA-L13 Build/HUAWEIMYA-L13\n",
              "4        3663602  -95.0  328680.0  ...      F      mobile         SM-G9650 Build/R16NW\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8CCDZ5bl8V6p",
        "colab": {}
      },
      "source": [
        "dataset_transaction = None\n",
        "to_remove_id = ['DeviceInfo', 'id_30', 'id_31', 'id_33']\n",
        "for column in to_remove_id:\n",
        "  a = test_identity.pop(column)\n",
        "  "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozVs1d5a_wMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a6d12536-7349-42a4-c9b3-391bfbb32307"
      },
      "source": [
        "test_identity.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663586</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>280290.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3579.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>24.0</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663597</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>185210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>271.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>desktop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663601</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>252944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663602</td>\n",
              "      <td>-95.0</td>\n",
              "      <td>328680.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>567.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  id_01     id_02  id_03  ...  id_36  id_37  id_38  DeviceType\n",
              "0        3663586  -45.0  280290.0    NaN  ...      F      T      F      mobile\n",
              "1        3663588    0.0    3579.0    0.0  ...      F      T      T      mobile\n",
              "2        3663597   -5.0  185210.0    NaN  ...      T      T      F     desktop\n",
              "3        3663601  -45.0  252944.0    0.0  ...      F      T      F      mobile\n",
              "4        3663602  -95.0  328680.0    NaN  ...      F      T      F      mobile\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybm-P5WqcRiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove the columns in to_remove_NaN_dataset_transaction and to_remove_NaN_dataset_identity\n",
        "#for column in to_remove_NaN_dataset_transaction:\n",
        "#  test_transaction.pop(column)\n",
        "\n",
        "#for column in to_remove_NaN_dataset_identity:\n",
        "#  test_identity.pop(column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "du0_nSm48V63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c087fbac-4280-4610-f727-6f1b16288973"
      },
      "source": [
        "merged_data = pd.merge(left=test_transaction, right=test_identity, how='left', left_on='TransactionID', right_on='TransactionID')\n",
        "\n",
        "TransactionID = merged_data.pop('TransactionID')\n",
        "test_transaction = None\n",
        "merged_data.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506691, 428)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkoViKsx6cZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd31a0ea-11b2-42c1-8f8c-8094a609653b"
      },
      "source": [
        "test_transaction = copy.copy(merged_data)\n",
        "merged_data = None\n",
        "float_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "int_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('int64'))].to_list()\n",
        "obj_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "print(len(float_columns_test), len(int_columns_test), len(obj_columns_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "399 2 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrzQZ6nR6wOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_normalization(X, indices, cache_min, cache_max, cache_mean, cache_median):\n",
        "  X_out = copy.copy(X)\n",
        "  #X_out[indices] = (X_out[indices] - cache_mean)/(cache_max - cache_min)\n",
        "  X_out[np.where(np.isnan(X_out))[0]] = cache_median\n",
        "  X_out = (X_out - cache_min)/(cache_max - cache_min)\n",
        "  #X_out[np.where(np.isnan(X_out))[0]] = 0.0\n",
        "  return X_out.astype('float16')  \n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXM75lh_6lhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in float_columns_test:\n",
        "  # Set to float 16\n",
        "  test_transaction[column].astype('float32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  # test_transaction[column + \"_NaN_Code\"] = np.isnan(test_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = test_transaction[column]\n",
        "  indices = np.where(np.isnan(test_transaction[column]) == False)[0]\n",
        "  test_transaction[column] = apply_normalization(X.to_numpy(), indices, cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], cache[column+'_median'])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjog0oM7p4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in int_columns_test:\n",
        "  # Set to int 32\n",
        "  test_transaction[column].astype('int32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  # test_transaction[column + \"_NaN_Code\"] = np.isnan(test_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = test_transaction[column]\n",
        "  indices = np.where(np.isnan(test_transaction[column]) == False)[0]\n",
        "  test_transaction[column] = apply_normalization(X.to_numpy(), indices, cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], cache[column+'_median'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egMTT8KB74NL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4076e76d-d895-46db-bcc4-6b0aea57e2d0"
      },
      "source": [
        "encoded_column = 0\n",
        "for column in obj_columns_test:\n",
        "  ohc = OneHotEncoder(handle_unknown='ignore')\n",
        "  ohc.fit(cache[column])\n",
        "  test_transaction.loc[np.where(test_transaction[column].isnull())[0], column] = 'Null'\n",
        "  encoded = ohc.transform(test_transaction[column].values.reshape(-1,1)).toarray()    \n",
        "  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(cache[column])))])\n",
        "  test_transaction = pd.concat([test_transaction, pd_encoded], axis=1)\n",
        "  encoded_column += len(pd_encoded.columns)\n",
        "\n",
        "print(\"Encoded columns: \" + str(encoded_column))\n",
        "\n",
        "\n",
        "for column in obj_columns_test:\n",
        "  try:\n",
        "    test_transaction.pop(column)\n",
        "  except KeyError:\n",
        "    pass\n",
        "\n",
        "#for column in to_remove:\n",
        "#  try:\n",
        "#    test_transaction.pop(column)\n",
        "#  except KeyError:\n",
        "#    pass\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded columns: 207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtnORuojLCUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "06baf7a8-a3c3-4bc0-e26e-d1488ed8a7c2"
      },
      "source": [
        "to_remove"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-afd9b5f27a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'to_remove' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC_OOqFi8HrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6907021-5fe4-46f7-cf92-1446bff748ce"
      },
      "source": [
        "# Check if we have the same shape with the X_train\n",
        "#print(test_transaction.shape, X_train.shape)\n",
        "print(test_transaction.shape, np.any(np.isnan(test_transaction)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506691, 608) False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTvYWAcGZEGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "c0b7c117-2d44-4808-cc34-56c564a97ee1"
      },
      "source": [
        "test_transaction.head(5)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>V1</th>\n",
              "      <th>...</th>\n",
              "      <th>id_15_0</th>\n",
              "      <th>id_15_1</th>\n",
              "      <th>id_15_2</th>\n",
              "      <th>id_15_3</th>\n",
              "      <th>id_16_0</th>\n",
              "      <th>id_16_1</th>\n",
              "      <th>id_16_2</th>\n",
              "      <th>id_23_0</th>\n",
              "      <th>id_23_1</th>\n",
              "      <th>id_23_2</th>\n",
              "      <th>id_23_3</th>\n",
              "      <th>id_27_0</th>\n",
              "      <th>id_27_1</th>\n",
              "      <th>id_27_2</th>\n",
              "      <th>id_28_0</th>\n",
              "      <th>id_28_1</th>\n",
              "      <th>id_28_2</th>\n",
              "      <th>id_29_0</th>\n",
              "      <th>id_29_1</th>\n",
              "      <th>id_29_2</th>\n",
              "      <th>id_34_0</th>\n",
              "      <th>id_34_1</th>\n",
              "      <th>id_34_2</th>\n",
              "      <th>id_34_3</th>\n",
              "      <th>id_34_4</th>\n",
              "      <th>id_35_0</th>\n",
              "      <th>id_35_1</th>\n",
              "      <th>id_35_2</th>\n",
              "      <th>id_36_0</th>\n",
              "      <th>id_36_1</th>\n",
              "      <th>id_36_2</th>\n",
              "      <th>id_37_0</th>\n",
              "      <th>id_37_1</th>\n",
              "      <th>id_37_2</th>\n",
              "      <th>id_38_0</th>\n",
              "      <th>id_38_1</th>\n",
              "      <th>id_38_2</th>\n",
              "      <th>DeviceType_0</th>\n",
              "      <th>DeviceType_1</th>\n",
              "      <th>DeviceType_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.000999</td>\n",
              "      <td>0.541016</td>\n",
              "      <td>0.022003</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.159058</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.001055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007980</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010490</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.039398</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.653809</td>\n",
              "      <td>0.653809</td>\n",
              "      <td>0.025085</td>\n",
              "      <td>0.428711</td>\n",
              "      <td>0.024811</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.383057</td>\n",
              "      <td>0.273438</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.419189</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.001534</td>\n",
              "      <td>0.188110</td>\n",
              "      <td>0.022003</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.452393</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.004112</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.232422</td>\n",
              "      <td>0.232422</td>\n",
              "      <td>0.006504</td>\n",
              "      <td>0.623047</td>\n",
              "      <td>0.006435</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.211792</td>\n",
              "      <td>0.733887</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.610840</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.005352</td>\n",
              "      <td>0.199829</td>\n",
              "      <td>0.948242</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.845215</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.256104</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006992</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007538</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.213745</td>\n",
              "      <td>0.213745</td>\n",
              "      <td>0.009293</td>\n",
              "      <td>0.180542</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.124634</td>\n",
              "      <td>0.201904</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.153320</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.008919</td>\n",
              "      <td>0.574219</td>\n",
              "      <td>0.520020</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.481689</td>\n",
              "      <td>0.238647</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.001653</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002659</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002399</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.065552</td>\n",
              "      <td>0.065552</td>\n",
              "      <td>0.038116</td>\n",
              "      <td>0.300049</td>\n",
              "      <td>0.037689</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.221802</td>\n",
              "      <td>0.315186</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.276855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.536621</td>\n",
              "      <td>0.002127</td>\n",
              "      <td>0.978027</td>\n",
              "      <td>0.704102</td>\n",
              "      <td>0.378906</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.372803</td>\n",
              "      <td>0.836914</td>\n",
              "      <td>0.000583</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.001055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005318</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004799</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.034332</td>\n",
              "      <td>0.034332</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>0.695801</td>\n",
              "      <td>0.020172</td>\n",
              "      <td>0.080139</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.089417</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 608 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionDT  TransactionAmt  ...  DeviceType_1  DeviceType_2\n",
              "0       0.536621        0.000999  ...             0             0\n",
              "1       0.536621        0.001534  ...             0             0\n",
              "2       0.536621        0.005352  ...             0             0\n",
              "3       0.536621        0.008919  ...             0             0\n",
              "4       0.536621        0.002127  ...             0             0\n",
              "\n",
              "[5 rows x 608 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY9vDvpDZdpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make the prediction and submit the output\n",
        "threshold = threshold_value[max_f1_indices]\n",
        "#threshold = 0.4\n",
        "#result = (new_model.predict(test_transaction, batch_size=BATCH_SIZE)>threshold).astype('int8')\n",
        "xgboost_used = True\n",
        "result = np.array([])\n",
        "\n",
        "if xgboost_used:\n",
        "  batch_size = 32768 #115200\n",
        "  evaluate_input = copy.copy(test_transaction).values.tolist()\n",
        "  subset = np.floor(len(evaluate_input)/batch_size).astype('int')\n",
        "  print(\"Batch_size and number of subset: \", batch_size, subset)\n",
        "\n",
        "  for i in range(subset+1):\n",
        "    print(\"Subset: \", i)\n",
        "    if i < subset + 1:\n",
        "      dvalid = xgboost.DMatrix(evaluate_input[batch_size*i:batch_size*(i+1)])\n",
        "    else:\n",
        "      dvalid = xgboost.DMatrix(evaluate_input[batch_size*i:len(evaluate_input)])\n",
        "\n",
        "    if i==0:\n",
        "      result = (new_model.predict(dvalid)>threshold).astype('int8')\n",
        "    else:\n",
        "      temp_result = (new_model.predict(dvalid)>threshold).astype('int8')\n",
        "      result = np.vstack((result, temp_result))\n",
        "else:\n",
        "  result = (new_model.predict(test_transaction, batch_size=BATCH_SIZE)>threshold).astype('int8')\n",
        "\n",
        "print(result.shape)\n",
        "result_pd = pd.DataFrame(result, columns=['isFraud'])\n",
        "data_to_file = pd.concat([TransactionID, result_pd], axis=1)\n",
        "data_to_file.head(5)\n",
        "data_to_file.to_csv(\"./submission.csv\", index=False)\n",
        "data_to_file.to_csv('/content/gdrive/My Drive/Kaggle/submission.csv', index=False)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dva2F6mLjpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb871706-8565-4fc7-d10f-1a5ffaef320d"
      },
      "source": [
        "print(test_transaction.shape, X_test.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506691, 608) (6319, 608)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9099XTi4s2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8ad85321-abda-4c80-895a-6da264e559d7"
      },
      "source": [
        "!kaggle competitions submit -c ieee-fraud-detection -f submission.csv -m \"New submission with model_20200828 with threshold {threshold}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 4.83M/4.83M [00:08<00:00, 567kB/s]\n",
            "Successfully submitted to IEEE-CIS Fraud Detection"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORvQlPDjMsaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try with a higher threshold\n",
        "threshold = 0.9\n",
        "result = (new_model.predict(test_transaction, batch_size=BATCH_SIZE)>threshold).astype('int8')\n",
        "result_pd = pd.DataFrame(result, columns=['isFraud'])\n",
        "data_to_file = pd.concat([TransactionID, result_pd], axis=1)\n",
        "data_to_file.head(5)\n",
        "data_to_file.to_csv(\"./submission.csv\", index=False)\n",
        "data_to_file.to_csv('/content/gdrive/My Drive/Kaggle/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE4PA454M2rh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "debddced-0178-4229-c763-5af26d899c09"
      },
      "source": [
        "!kaggle competitions submit -c ieee-fraud-detection -f submission.csv -m \"New submission with model_20200828 with threshold {threshold}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 4.83M/4.83M [00:13<00:00, 373kB/s]\n",
            "Successfully submitted to IEEE-CIS Fraud Detection"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGezGr2PkCbt",
        "colab_type": "text"
      },
      "source": [
        "# ***Debug zone***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gICp4sPm6brq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cabf1835-6318-410e-f196-4382a3037755"
      },
      "source": [
        "print(np.sum(result==[1]), np.sum(result==[1])/len(result)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53593 10.577057812355065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3e2nvzrHir4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fe4ae314-d9e2-483a-9baa-e8b9302f14bf"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohc = OneHotEncoder()\n",
        "a = {'a': ['Null', 'A', 'B', 'C', 'D']}\n",
        "df = pd.DataFrame(a)\n",
        "df\n",
        "encoded = ohc.fit_transform(df['a'].values.reshape(-1,1)).toarray()    \n",
        "pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[\"a\"+\"_\"+str(i) for i in range(len(np.unique(df['a'].astype('str'))))])\n",
        "pd_encoded\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a_0</th>\n",
              "      <th>a_1</th>\n",
              "      <th>a_2</th>\n",
              "      <th>a_3</th>\n",
              "      <th>a_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a_0  a_1  a_2  a_3  a_4\n",
              "0    0    0    0    0    1\n",
              "1    1    0    0    0    0\n",
              "2    0    1    0    0    0\n",
              "3    0    0    1    0    0\n",
              "4    0    0    0    1    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT1lZERzxxsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the similarity of the Object type columns\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "os.chdir(\"/content\")\n",
        "dataset_transaction = pd.read_csv('train_transaction.csv')\n",
        "testset_transaction = pd.read_csv('test_transaction.csv')\n",
        "#dataset_transaction = pd.read_csv('train_identity.csv')\n",
        "#saved_columns = dataset_transaction.columns.to_list()\n",
        "#testset_transaction = pd.read_csv('test_identity.csv', names=saved_columns, header=0)\n",
        "obj_columns_data = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "obj_columns_test = testset_transaction.columns[np.where(testset_transaction.dtypes == np.dtype('O'))].to_list()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3tGlBhr1L4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "8ba7acdc-f221-4e8c-8ed4-9f3cdb4aec71"
      },
      "source": [
        "testset_transaction.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663586</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>280290.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3579.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Android 6.0.1</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1280x720</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>LGLS676 Build/MXB48T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663597</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>185210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>271.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ie 11.0 for tablet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Trident/7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663601</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>252944.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>427.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663602</td>\n",
              "      <td>-95.0</td>\n",
              "      <td>328680.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>567.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome 67.0 for android</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SM-G9650 Build/R16NW</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  id_01     id_02  ...  id_38  DeviceType                   DeviceInfo\n",
              "0        3663586  -45.0  280290.0  ...      F      mobile  MYA-L13 Build/HUAWEIMYA-L13\n",
              "1        3663588    0.0    3579.0  ...      T      mobile         LGLS676 Build/MXB48T\n",
              "2        3663597   -5.0  185210.0  ...      F     desktop                  Trident/7.0\n",
              "3        3663601  -45.0  252944.0  ...      F      mobile  MYA-L13 Build/HUAWEIMYA-L13\n",
              "4        3663602  -95.0  328680.0  ...      F      mobile         SM-G9650 Build/R16NW\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y93MXNirztmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "64e681f4-bc1f-438d-e079-90615598fe5e"
      },
      "source": [
        "print(len(obj_columns_data), len(obj_columns_test), set(obj_columns_data) == set(obj_columns_test))\n",
        "print(obj_columns_data)\n",
        "print(obj_columns_test)\n",
        "ignore_columns = ['DeviceInfo', 'id_30', 'id_31', 'id_33']\n",
        "for column in obj_columns_data:\n",
        "  data = np.unique(dataset_transaction[column].to_list())\n",
        "  test = np.unique(testset_transaction[column].to_list())\n",
        "  if not (set(data)==set(test)):\n",
        "    print(column)\n",
        "    if column not in ignore_columns:\n",
        "      print(data, test)\n",
        "      for each_data in test:\n",
        "        if each_data not in data:\n",
        "          print(each_data)\n",
        "    else:\n",
        "      print(column in ignore_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14 14 True\n",
            "['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
            "['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
            "card6\n",
            "['charge card' 'credit' 'debit' 'debit or credit' 'nan'] ['charge card' 'credit' 'debit' 'nan']\n",
            "P_emaildomain\n",
            "['aim.com' 'anonymous.com' 'aol.com' 'att.net' 'bellsouth.net'\n",
            " 'cableone.net' 'centurylink.net' 'cfl.rr.com' 'charter.net' 'comcast.net'\n",
            " 'cox.net' 'earthlink.net' 'embarqmail.com' 'frontier.com'\n",
            " 'frontiernet.net' 'gmail' 'gmail.com' 'gmx.de' 'hotmail.co.uk'\n",
            " 'hotmail.com' 'hotmail.de' 'hotmail.es' 'hotmail.fr' 'icloud.com'\n",
            " 'juno.com' 'live.com' 'live.com.mx' 'live.fr' 'mac.com' 'mail.com'\n",
            " 'me.com' 'msn.com' 'nan' 'netzero.com' 'netzero.net' 'optonline.net'\n",
            " 'outlook.com' 'outlook.es' 'prodigy.net.mx' 'protonmail.com' 'ptd.net'\n",
            " 'q.com' 'roadrunner.com' 'rocketmail.com' 'sbcglobal.net' 'sc.rr.com'\n",
            " 'servicios-ta.com' 'suddenlink.net' 'twc.com' 'verizon.net' 'web.de'\n",
            " 'windstream.net' 'yahoo.co.jp' 'yahoo.co.uk' 'yahoo.com' 'yahoo.com.mx'\n",
            " 'yahoo.de' 'yahoo.es' 'yahoo.fr' 'ymail.com'] ['aim.com' 'anonymous.com' 'aol.com' 'att.net' 'bellsouth.net'\n",
            " 'cableone.net' 'centurylink.net' 'cfl.rr.com' 'charter.net' 'comcast.net'\n",
            " 'cox.net' 'earthlink.net' 'embarqmail.com' 'frontier.com'\n",
            " 'frontiernet.net' 'gmail' 'gmail.com' 'gmx.de' 'hotmail.co.uk'\n",
            " 'hotmail.com' 'hotmail.de' 'hotmail.es' 'hotmail.fr' 'icloud.com'\n",
            " 'juno.com' 'live.com' 'live.com.mx' 'live.fr' 'mac.com' 'mail.com'\n",
            " 'me.com' 'msn.com' 'nan' 'netzero.com' 'netzero.net' 'optonline.net'\n",
            " 'outlook.com' 'outlook.es' 'prodigy.net.mx' 'protonmail.com' 'ptd.net'\n",
            " 'q.com' 'roadrunner.com' 'rocketmail.com' 'sbcglobal.net' 'sc.rr.com'\n",
            " 'scranton.edu' 'servicios-ta.com' 'suddenlink.net' 'twc.com'\n",
            " 'verizon.net' 'web.de' 'windstream.net' 'yahoo.co.jp' 'yahoo.co.uk'\n",
            " 'yahoo.com' 'yahoo.com.mx' 'yahoo.de' 'yahoo.es' 'yahoo.fr' 'ymail.com']\n",
            "scranton.edu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3srvivP2Lap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af6d2251-e790-44fc-ce39-049663c1d3c4"
      },
      "source": [
        "np.where(testset_transaction['P_emaildomain'] == \"scranton.edu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([480814, 480819]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obkPTsTh-prG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4028c33b-0d20-4649-de29-2f82099dba3b"
      },
      "source": [
        "# Check the similarity of the Float columns\n",
        "float_columns_data = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "float_columns_test = testset_transaction.columns[np.where(testset_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "for column in float_columns_data:\n",
        "  if np.max(dataset_transaction[column]) < np.max(testset_transaction[column]):\n",
        "    print(column, np.max(dataset_transaction[column]), np.max(testset_transaction[column]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "card3 231.0 232.0\n",
            "C3 26.0 31.0\n",
            "C5 349.0 376.0\n",
            "C9 210.0 572.0\n",
            "D1 640.0 641.0\n",
            "D2 640.0 641.0\n",
            "D3 819.0 1076.0\n",
            "D4 869.0 1091.0\n",
            "D5 819.0 1088.0\n",
            "D6 873.0 1091.0\n",
            "D7 843.0 1088.0\n",
            "D8 1707.7916259765625 2029.5833740234373\n",
            "D10 876.0 1091.0\n",
            "D11 670.0 883.0\n",
            "D12 648.0 879.0\n",
            "D13 847.0 1066.0\n",
            "D14 878.0 1085.0\n",
            "D15 879.0 1091.0\n",
            "V2 8.0 11.0\n",
            "V3 9.0 11.0\n",
            "V4 6.0 10.0\n",
            "V5 6.0 10.0\n",
            "V6 9.0 13.0\n",
            "V7 9.0 13.0\n",
            "V8 8.0 11.0\n",
            "V9 8.0 11.0\n",
            "V10 4.0 5.0\n",
            "V11 5.0 7.0\n",
            "V12 3.0 4.0\n",
            "V15 7.0 13.0\n",
            "V16 15.0 25.0\n",
            "V19 7.0 13.0\n",
            "V20 15.0 25.0\n",
            "V23 13.0 15.0\n",
            "V24 13.0 29.0\n",
            "V25 7.0 13.0\n",
            "V26 13.0 25.0\n",
            "V27 4.0 7.0\n",
            "V28 4.0 7.0\n",
            "V31 7.0 13.0\n",
            "V32 15.0 25.0\n",
            "V33 7.0 13.0\n",
            "V34 13.0 25.0\n",
            "V35 3.0 4.0\n",
            "V36 5.0 6.0\n",
            "V39 15.0 30.0\n",
            "V40 24.0 31.0\n",
            "V43 8.0 11.0\n",
            "V45 48.0 69.0\n",
            "V46 6.0 8.0\n",
            "V49 5.0 7.0\n",
            "V50 5.0 7.0\n",
            "V51 6.0 8.0\n",
            "V54 6.0 7.0\n",
            "V55 17.0 49.0\n",
            "V60 16.0 17.0\n",
            "V63 7.0 8.0\n",
            "V64 7.0 10.0\n",
            "V66 7.0 8.0\n",
            "V67 8.0 10.0\n",
            "V68 2.0 7.0\n",
            "V70 6.0 8.0\n",
            "V73 7.0 8.0\n",
            "V74 8.0 10.0\n",
            "V75 4.0 5.0\n",
            "V76 6.0 7.0\n",
            "V77 30.0 80.0\n",
            "V78 31.0 80.0\n",
            "V84 7.0 10.0\n",
            "V85 7.0 10.0\n",
            "V86 30.0 80.0\n",
            "V87 30.0 80.0\n",
            "V89 2.0 7.0\n",
            "V91 6.0 8.0\n",
            "V100 28.0 30.0\n",
            "V104 15.0 59.0\n",
            "V106 55.0 80.0\n",
            "V108 7.0 8.0\n",
            "V109 7.0 8.0\n",
            "V110 7.0 8.0\n",
            "V114 6.0 9.0\n",
            "V115 6.0 9.0\n",
            "V116 6.0 9.0\n",
            "V120 3.0 4.0\n",
            "V121 3.0 4.0\n",
            "V122 3.0 4.0\n",
            "V126 160000.0 519038.5\n",
            "V127 160000.0 544500.0\n",
            "V128 160000.0 519038.5\n",
            "V129 55125.0 64800.0\n",
            "V130 55125.0 167200.0\n",
            "V131 55125.0 167200.0\n",
            "V132 93736.0 519038.5\n",
            "V133 133915.0 519038.5\n",
            "V134 98476.0 519038.5\n",
            "V135 90750.0 302500.0\n",
            "V136 90750.0 302500.0\n",
            "V137 90750.0 302500.0\n",
            "V140 33.0 59.0\n",
            "V141 5.0 6.0\n",
            "V142 9.0 11.0\n",
            "V144 62.0 85.0\n",
            "V151 57.0 58.0\n",
            "V159 55125.0 284129.8125\n",
            "V160 641511.4375 3867868.5\n",
            "V162 3300.0 4000.0\n",
            "V163 3300.0 4000.0\n",
            "V164 93736.0 928882.0\n",
            "V165 98476.0 928882.0\n",
            "V166 104060.0 453750.0\n",
            "V169 19.0 39.0\n",
            "V170 48.0 63.0\n",
            "V171 61.0 68.0\n",
            "V172 31.0 37.0\n",
            "V173 7.0 9.0\n",
            "V175 14.0 22.0\n",
            "V176 48.0 239.0\n",
            "V180 83.0 179.0\n",
            "V181 24.0 85.0\n",
            "V182 83.0 125.0\n",
            "V183 41.0 106.0\n",
            "V186 38.0 39.0\n",
            "V188 30.0 44.0\n",
            "V189 30.0 44.0\n",
            "V190 42.0 224.0\n",
            "V195 16.0 18.0\n",
            "V196 38.0 41.0\n",
            "V198 21.0 29.0\n",
            "V199 45.0 224.0\n",
            "V200 45.0 47.0\n",
            "V202 104060.0 1065496.5\n",
            "V203 139777.0 1065496.5\n",
            "V204 104060.0 1065496.5\n",
            "V205 55125.0 64800.0\n",
            "V206 55125.0 64800.0\n",
            "V207 55125.0 167200.0\n",
            "V208 3300.0 4000.0\n",
            "V209 8050.0 10000.0\n",
            "V210 3300.0 4000.0\n",
            "V211 92888.0 928882.0\n",
            "V212 129006.0 958320.0\n",
            "V213 97628.0 928882.0\n",
            "V214 104060.0 453750.0\n",
            "V215 104060.0 756250.0\n",
            "V216 104060.0 756250.0\n",
            "V220 25.0 47.0\n",
            "V225 51.0 58.0\n",
            "V226 242.0 870.0\n",
            "V228 54.0 239.0\n",
            "V229 176.0 262.0\n",
            "V230 65.0 262.0\n",
            "V234 121.0 322.0\n",
            "V236 45.0 57.0\n",
            "V242 20.0 27.0\n",
            "V244 22.0 33.0\n",
            "V246 45.0 224.0\n",
            "V257 48.0 224.0\n",
            "V258 66.0 269.0\n",
            "V260 8.0 14.0\n",
            "V261 49.0 89.0\n",
            "V262 20.0 34.0\n",
            "V263 153600.0 1065496.5\n",
            "V264 153600.0 1065496.5\n",
            "V265 153600.0 1065496.5\n",
            "V266 55125.0 64800.0\n",
            "V267 55125.0 64800.0\n",
            "V268 55125.0 64800.0\n",
            "V269 55125.0 64800.0\n",
            "V270 4000.0 10791.5703125\n",
            "V271 4000.0 10791.5703125\n",
            "V272 4000.0 10791.5703125\n",
            "V273 51200.0 928882.0\n",
            "V274 66000.0 928882.0\n",
            "V275 51200.0 928882.0\n",
            "V276 104060.0 453750.0\n",
            "V277 104060.0 756250.0\n",
            "V278 104060.0 756250.0\n",
            "V281 22.0 30.0\n",
            "V282 32.0 63.0\n",
            "V296 93.0 179.0\n",
            "V297 12.0 85.0\n",
            "V298 93.0 125.0\n",
            "V299 49.0 106.0\n",
            "V300 11.0 14.0\n",
            "V301 13.0 14.0\n",
            "V304 16.0 17.0\n",
            "V306 108800.0 718740.0\n",
            "V307 145765.0 958320.0\n",
            "V308 108800.0 718740.0\n",
            "V309 55125.0 64800.0\n",
            "V310 55125.0 167200.0\n",
            "V311 55125.0 64800.0\n",
            "V312 55125.0 167200.0\n",
            "V314 7519.8701171875 7539.75\n",
            "V316 93736.0 718740.0\n",
            "V317 134021.0 958320.0\n",
            "V318 98476.0 718740.0\n",
            "V319 104060.0 453750.0\n",
            "V320 104060.0 605000.0\n",
            "V321 104060.0 605000.0\n",
            "V327 18.0 31.0\n",
            "V328 15.0 85.0\n",
            "V329 99.0 125.0\n",
            "V330 55.0 106.0\n",
            "V331 160000.0 1040657.5\n",
            "V332 160000.0 1040657.5\n",
            "V333 160000.0 1040657.5\n",
            "V334 55125.0 64800.0\n",
            "V335 55125.0 64800.0\n",
            "V336 55125.0 64800.0\n",
            "V337 104060.0 375000.0\n",
            "V338 104060.0 612500.0\n",
            "V339 104060.0 612500.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNMYlhLE0XBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e2be45f-af44-477a-bc67-2c0ef26a7733"
      },
      "source": [
        "print(data, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['C' 'H' 'R' 'S' 'W'] ['C' 'H' 'R' 'S' 'W']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vsaGKlzMUlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "69213f3a-42cb-4edc-cbc8-5bc6c0bb5a7e"
      },
      "source": [
        "b = {'a': ['Null', 'A', 'B', 'C', 'E']}\n",
        "df_b = pd.DataFrame(b)\n",
        "ohc_b = OneHotEncoder(handle_unknown='ignore')\n",
        "ohc_b.fit(df['a'].values.reshape(-1,1))\n",
        "encoded_b = ohc_b.transform(df_b['a'].values.reshape(-1,1)).toarray()    \n",
        "pd_encoded_b = pd.DataFrame(encoded_b.astype('int8'), columns=[\"a\"+\"_\"+str(i) for i in range(len(np.unique(df['a'].astype('str'))))])\n",
        "pd_encoded_b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a_0</th>\n",
              "      <th>a_1</th>\n",
              "      <th>a_2</th>\n",
              "      <th>a_3</th>\n",
              "      <th>a_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a_0  a_1  a_2  a_3  a_4\n",
              "0    0    0    0    0    1\n",
              "1    1    0    0    0    0\n",
              "2    0    1    0    0    0\n",
              "3    0    0    1    0    0\n",
              "4    0    0    0    0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvykuaRPMpZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "20c01d2a-8a3b-41b6-a7ae-b6d7a36f327f"
      },
      "source": [
        "for column in obj_columns:\n",
        "  dataset_transaction.loc[np.where(dataset_transaction[column].isnull())[0], column] = 'Null'\n",
        "  print(column, len(np.unique(dataset_transaction[column].astype(\"str\"))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ProductCD 5\n",
            "card4 5\n",
            "card6 5\n",
            "P_emaildomain 60\n",
            "R_emaildomain 61\n",
            "M1 3\n",
            "M2 3\n",
            "M3 3\n",
            "M4 4\n",
            "M5 3\n",
            "M6 3\n",
            "M7 3\n",
            "M8 3\n",
            "M9 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj_RMIz3NTTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2e5b2844-8bdd-45ee-f5ec-83cd54c9cba7"
      },
      "source": [
        "for column in obj_columns_test:\n",
        "  test_transaction.loc[np.where(test_transaction[column].isnull())[0], column] = 'Null'\n",
        "  print(column, len(np.unique(test_transaction[column].astype(\"str\"))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ProductCD 5\n",
            "card4 5\n",
            "card6 4\n",
            "P_emaildomain 61\n",
            "R_emaildomain 61\n",
            "M1 3\n",
            "M2 3\n",
            "M3 3\n",
            "M4 4\n",
            "M5 3\n",
            "M6 3\n",
            "M7 3\n",
            "M8 3\n",
            "M9 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvnTtZ-WUmWS",
        "colab_type": "text"
      },
      "source": [
        "**Train val dataset**"
      ]
    }
  ]
}