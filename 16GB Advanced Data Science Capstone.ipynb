{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Overview\n- This notebook is the Watson Studio notebook for the Advanced Data Science Capstone project of Coursera.\n- The topic of this project is the \"IEEE-CIS Fraud Detection\" challenge from Kaggle, more information about the dataset and the competition can be found at https://www.kaggle.com/c/ieee-fraud-detection/\n- The Machine Learning model in this Notebook is developped using the tensorflow/keras integrated in the Watson Studio Notebook. In addition, other libraries are used for the data analysis, graph display, data preprocessing:\n    + numpy\n    + pandas\n    + scikit-learn\n    + matplotlib\n    + seaborn\n- This model is developped using only the data from the train_transaction.csv, meaning just have of the given data.\n- In order to evaluate the performance of the model, F1_score function is developped.\n- In order to optimize the training/testing, we have to update to tensorflow 2.\n- Updated the evaluation and METRICS using the tutorials of tensorflow at https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Update tensorflow 2 and other libraries"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: tensorflow==2.2.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (2.2.0)\nRequirement already satisfied: seaborn==0.10.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.10.1)\nRequirement already satisfied: numpy==1.18.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.18.5)\nRequirement already satisfied: tensorflow-addons in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.11.1)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.16.1)\nRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (2.10.0)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (0.7.0)\nRequirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (2.2.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.1.0)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.11.1)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (0.3.3)\nRequirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.12.0)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (0.32.3)\nRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.4.1)\nRequirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (2.2.2)\nRequirement already satisfied: protobuf>=3.8.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (3.11.2)\nRequirement already satisfied: google-pasta>=0.1.8 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (3.3.0)\nRequirement already satisfied: astunparse==1.6.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.6.3)\nRequirement already satisfied: matplotlib>=2.1.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from seaborn==0.10.1) (3.0.2)\nRequirement already satisfied: pandas>=0.22.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from seaborn==0.10.1) (0.24.1)\nRequirement already satisfied: typeguard>=2.7 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow-addons) (2.9.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.21.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.14.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (49.6.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.20.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn==0.10.1) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn==0.10.1) (1.0.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn==0.10.1) (2.3.1)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn==0.10.1) (2.7.5)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn==0.10.1) (2018.9)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.1)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/envs/Python36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n"
                }
            ],
            "source": "!pip install tensorflow==2.2.0 seaborn==0.10.1 numpy==1.18.5 tensorflow-addons"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Load the dataset from the Cloud Data Object"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>...</th>\n      <th>V330</th>\n      <th>V331</th>\n      <th>V332</th>\n      <th>V333</th>\n      <th>V334</th>\n      <th>V335</th>\n      <th>V336</th>\n      <th>V337</th>\n      <th>V338</th>\n      <th>V339</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2987000</td>\n      <td>0</td>\n      <td>86400</td>\n      <td>68.5</td>\n      <td>W</td>\n      <td>13926</td>\n      <td>NaN</td>\n      <td>150.0</td>\n      <td>discover</td>\n      <td>142.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2987001</td>\n      <td>0</td>\n      <td>86401</td>\n      <td>29.0</td>\n      <td>W</td>\n      <td>2755</td>\n      <td>404.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>102.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2987002</td>\n      <td>0</td>\n      <td>86469</td>\n      <td>59.0</td>\n      <td>W</td>\n      <td>4663</td>\n      <td>490.0</td>\n      <td>150.0</td>\n      <td>visa</td>\n      <td>166.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2987003</td>\n      <td>0</td>\n      <td>86499</td>\n      <td>50.0</td>\n      <td>W</td>\n      <td>18132</td>\n      <td>567.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>117.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2987004</td>\n      <td>0</td>\n      <td>86506</td>\n      <td>50.0</td>\n      <td>H</td>\n      <td>4497</td>\n      <td>514.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>102.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 394 columns</p>\n</div>",
                        "text/plain": "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n0        2987000        0          86400            68.5         W  13926   \n1        2987001        0          86401            29.0         W   2755   \n2        2987002        0          86469            59.0         W   4663   \n3        2987003        0          86499            50.0         W  18132   \n4        2987004        0          86506            50.0         H   4497   \n\n   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n\n  V336  V337  V338  V339  \n0  NaN   NaN   NaN   NaN  \n1  NaN   NaN   NaN   NaN  \n2  NaN   NaN   NaN   NaN  \n3  NaN   NaN   NaN   NaN  \n4  0.0   0.0   0.0   0.0  \n\n[5 rows x 394 columns]"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>id_01</th>\n      <th>id_02</th>\n      <th>id_03</th>\n      <th>id_04</th>\n      <th>id_05</th>\n      <th>id_06</th>\n      <th>id_07</th>\n      <th>id_08</th>\n      <th>id_09</th>\n      <th>...</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_35</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2987004</td>\n      <td>0.0</td>\n      <td>70787.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>samsung browser 6.2</td>\n      <td>32.0</td>\n      <td>2220x1080</td>\n      <td>match_status:2</td>\n      <td>T</td>\n      <td>F</td>\n      <td>T</td>\n      <td>T</td>\n      <td>mobile</td>\n      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2987008</td>\n      <td>-5.0</td>\n      <td>98945.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>-5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>mobile safari 11.0</td>\n      <td>32.0</td>\n      <td>1334x750</td>\n      <td>match_status:1</td>\n      <td>T</td>\n      <td>F</td>\n      <td>F</td>\n      <td>T</td>\n      <td>mobile</td>\n      <td>iOS Device</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2987010</td>\n      <td>-5.0</td>\n      <td>191631.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>chrome 62.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>F</td>\n      <td>F</td>\n      <td>T</td>\n      <td>T</td>\n      <td>desktop</td>\n      <td>Windows</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2987011</td>\n      <td>-5.0</td>\n      <td>221832.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>-6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>chrome 62.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>F</td>\n      <td>F</td>\n      <td>T</td>\n      <td>T</td>\n      <td>desktop</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2987016</td>\n      <td>0.0</td>\n      <td>7460.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>chrome 62.0</td>\n      <td>24.0</td>\n      <td>1280x800</td>\n      <td>match_status:2</td>\n      <td>T</td>\n      <td>F</td>\n      <td>T</td>\n      <td>T</td>\n      <td>desktop</td>\n      <td>MacOS</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 41 columns</p>\n</div>",
                        "text/plain": "   TransactionID  id_01     id_02  id_03  id_04  id_05  id_06  id_07  id_08  \\\n0        2987004    0.0   70787.0    NaN    NaN    NaN    NaN    NaN    NaN   \n1        2987008   -5.0   98945.0    NaN    NaN    0.0   -5.0    NaN    NaN   \n2        2987010   -5.0  191631.0    0.0    0.0    0.0    0.0    NaN    NaN   \n3        2987011   -5.0  221832.0    NaN    NaN    0.0   -6.0    NaN    NaN   \n4        2987016    0.0    7460.0    0.0    0.0    1.0    0.0    NaN    NaN   \n\n   id_09  ...                id_31  id_32      id_33           id_34  id_35  \\\n0    NaN  ...  samsung browser 6.2   32.0  2220x1080  match_status:2      T   \n1    NaN  ...   mobile safari 11.0   32.0   1334x750  match_status:1      T   \n2    0.0  ...          chrome 62.0    NaN        NaN             NaN      F   \n3    NaN  ...          chrome 62.0    NaN        NaN             NaN      F   \n4    0.0  ...          chrome 62.0   24.0   1280x800  match_status:2      T   \n\n  id_36 id_37  id_38  DeviceType                     DeviceInfo  \n0     F     T      T      mobile  SAMSUNG SM-G892A Build/NRD90M  \n1     F     F      T      mobile                     iOS Device  \n2     F     T      T     desktop                        Windows  \n3     F     T      T     desktop                            NaN  \n4     F     T      T     desktop                          MacOS  \n\n[5 rows x 41 columns]"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "body = client_a5b8370d070043a698d332a3da4f29ba.get_object(Bucket='advanceddatasciencecapstoneprojec-donotdelete-pr-sxgni1jmo8dtzj',Key='train_identity.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndataset_identity = pd.read_csv(body)\ndataset_identity.head(5)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Import the libraries"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport copy\nimport os\nimport tensorflow as tf"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Remove the features with too many NaN or with two many objects for the OneHotEncoding"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "No. of removed features: 167\n"
                }
            ],
            "source": "#Data transaction\nfloat_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\nto_remove_NaN_dataset_transaction = []\n\nfor column in float_columns:\n  count_NaN = np.sum(np.isnan(dataset_transaction[column].values))\n  if count_NaN/len(dataset_transaction[column].values) > 0.75:\n    to_remove_NaN_dataset_transaction.append(column)\n    dataset_transaction.pop(column)\n\nprint(\"No. of removed features: \" + str(len(to_remove_NaN_dataset_transaction)))"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "No. of removed features: 7\n"
                }
            ],
            "source": "# Dataset Identity\nfloat_columns = dataset_identity.columns[np.where(dataset_identity.dtypes == np.dtype('float64'))].to_list()\nto_remove_NaN_dataset_identity = []\n\nfor column in float_columns:\n  count_NaN = np.sum(np.isnan(dataset_identity[column].values))\n  if count_NaN/len(dataset_identity[column]) > 0.75:\n    to_remove_NaN_dataset_identity.append(column)\n    dataset_identity.pop(column)\n\nprint(\"No. of removed features: \" + str(len(to_remove_NaN_dataset_identity)))"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "to_remove_id = ['DeviceInfo', 'id_30', 'id_31', 'id_33']\nfor column in to_remove_id:\n  dataset_identity.pop(column)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Merge the dataframe, cleansing (using OneHotEncoding) and Normalize the data"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(590540, 256)"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "merged_data = pd.merge(left=dataset_transaction, right=dataset_identity, how='left', left_on='TransactionID', right_on='TransactionID')\n\ndataset_transaction = None\ndataset_identity = None\nmerged_data.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>...</th>\n      <th>id_27</th>\n      <th>id_28</th>\n      <th>id_29</th>\n      <th>id_32</th>\n      <th>id_34</th>\n      <th>id_35</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>590535</th>\n      <td>3577535</td>\n      <td>0</td>\n      <td>15811047</td>\n      <td>49.00</td>\n      <td>W</td>\n      <td>6550</td>\n      <td>NaN</td>\n      <td>150.0</td>\n      <td>visa</td>\n      <td>226.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>590536</th>\n      <td>3577536</td>\n      <td>0</td>\n      <td>15811049</td>\n      <td>39.50</td>\n      <td>W</td>\n      <td>10444</td>\n      <td>225.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>224.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>590537</th>\n      <td>3577537</td>\n      <td>0</td>\n      <td>15811079</td>\n      <td>30.95</td>\n      <td>W</td>\n      <td>12037</td>\n      <td>595.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>224.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>590538</th>\n      <td>3577538</td>\n      <td>0</td>\n      <td>15811088</td>\n      <td>117.00</td>\n      <td>W</td>\n      <td>7826</td>\n      <td>481.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>224.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>590539</th>\n      <td>3577539</td>\n      <td>0</td>\n      <td>15811131</td>\n      <td>279.95</td>\n      <td>W</td>\n      <td>15066</td>\n      <td>170.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>102.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 256 columns</p>\n</div>",
                        "text/plain": "        TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  \\\n590535        3577535        0       15811047           49.00         W   \n590536        3577536        0       15811049           39.50         W   \n590537        3577537        0       15811079           30.95         W   \n590538        3577538        0       15811088          117.00         W   \n590539        3577539        0       15811131          279.95         W   \n\n        card1  card2  card3       card4  card5  ... id_27  id_28  id_29  \\\n590535   6550    NaN  150.0        visa  226.0  ...   NaN    NaN    NaN   \n590536  10444  225.0  150.0  mastercard  224.0  ...   NaN    NaN    NaN   \n590537  12037  595.0  150.0  mastercard  224.0  ...   NaN    NaN    NaN   \n590538   7826  481.0  150.0  mastercard  224.0  ...   NaN    NaN    NaN   \n590539  15066  170.0  150.0  mastercard  102.0  ...   NaN    NaN    NaN   \n\n        id_32 id_34 id_35  id_36  id_37  id_38  DeviceType  \n590535    NaN   NaN   NaN    NaN    NaN    NaN         NaN  \n590536    NaN   NaN   NaN    NaN    NaN    NaN         NaN  \n590537    NaN   NaN   NaN    NaN    NaN    NaN         NaN  \n590538    NaN   NaN   NaN    NaN    NaN    NaN         NaN  \n590539    NaN   NaN   NaN    NaN    NaN    NaN         NaN  \n\n[5 rows x 256 columns]"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "merged_data.tail(5)"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "225 2 27\n"
                }
            ],
            "source": "dataset_transaction = copy.copy(merged_data)\nmerged_data = None\ndataset_identity = None\n\nfloat_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\nint_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('int64'))].to_list()\nobj_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('O'))].to_list()\n\nskip_int_columns = ['TransactionID', 'isFraud']\nfor column in skip_int_columns:\n  int_columns.remove(column)\n\ncache = dict()\nprint(len(float_columns), len(int_columns), len(obj_columns))"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": "def normalization_data(X, indices):\n  X_out = copy.copy(X)\n  X_temp = X[indices]\n  max_X = np.max(X_temp)\n  min_X = np.min(X_temp)\n  mean_X = np.mean(X_temp)\n  X_out.iloc[indices] = (X_temp - mean_X)/(max_X - min_X)\n  X_out.iloc[np.where(np.isnan(X_out))[0]] = 0.0\n\n  return min_X, max_X, mean_X, X_out.astype('float16')"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": "# Task 1: Detect the columns with NaN and code it with an extra features\n# Task 2: Apply normalizationn\n# Task 3: Remove the irrelevant columns\nfor column in float_columns:\n  # Set to float 16\n  dataset_transaction[column].astype('float32')\n\n  # Code the NaN column for every features\n  dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n  \n  # Normalization\n  X = dataset_transaction[column]\n  indices = np.where(np.isnan(dataset_transaction[column]) == False)[0]\n  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], dataset_transaction[column] = normalization_data(X, indices)\n  dataset_transaction[column].astype('float16')"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>...</th>\n      <th>id_09_NaN_Code</th>\n      <th>id_10_NaN_Code</th>\n      <th>id_11_NaN_Code</th>\n      <th>id_13_NaN_Code</th>\n      <th>id_14_NaN_Code</th>\n      <th>id_17_NaN_Code</th>\n      <th>id_18_NaN_Code</th>\n      <th>id_19_NaN_Code</th>\n      <th>id_20_NaN_Code</th>\n      <th>id_32_NaN_Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2987000</td>\n      <td>0</td>\n      <td>86400</td>\n      <td>-0.002083</td>\n      <td>W</td>\n      <td>13926</td>\n      <td>0.000000</td>\n      <td>-0.024384</td>\n      <td>discover</td>\n      <td>-0.418213</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2987001</td>\n      <td>0</td>\n      <td>86401</td>\n      <td>-0.003321</td>\n      <td>W</td>\n      <td>2755</td>\n      <td>0.082886</td>\n      <td>-0.024384</td>\n      <td>mastercard</td>\n      <td>-0.709961</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2987002</td>\n      <td>0</td>\n      <td>86469</td>\n      <td>-0.002380</td>\n      <td>W</td>\n      <td>4663</td>\n      <td>0.254883</td>\n      <td>-0.024384</td>\n      <td>visa</td>\n      <td>-0.242920</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2987003</td>\n      <td>0</td>\n      <td>86499</td>\n      <td>-0.002663</td>\n      <td>W</td>\n      <td>18132</td>\n      <td>0.408936</td>\n      <td>-0.024384</td>\n      <td>mastercard</td>\n      <td>-0.600586</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2987004</td>\n      <td>0</td>\n      <td>86506</td>\n      <td>-0.002663</td>\n      <td>H</td>\n      <td>4497</td>\n      <td>0.302979</td>\n      <td>-0.024384</td>\n      <td>mastercard</td>\n      <td>-0.709961</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 481 columns</p>\n</div>",
                        "text/plain": "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n0        2987000        0          86400       -0.002083         W  13926   \n1        2987001        0          86401       -0.003321         W   2755   \n2        2987002        0          86469       -0.002380         W   4663   \n3        2987003        0          86499       -0.002663         W  18132   \n4        2987004        0          86506       -0.002663         H   4497   \n\n      card2     card3       card4     card5  ... id_09_NaN_Code  \\\n0  0.000000 -0.024384    discover -0.418213  ...              1   \n1  0.082886 -0.024384  mastercard -0.709961  ...              1   \n2  0.254883 -0.024384        visa -0.242920  ...              1   \n3  0.408936 -0.024384  mastercard -0.600586  ...              1   \n4  0.302979 -0.024384  mastercard -0.709961  ...              1   \n\n   id_10_NaN_Code  id_11_NaN_Code  id_13_NaN_Code id_14_NaN_Code  \\\n0               1               1               1              1   \n1               1               1               1              1   \n2               1               1               1              1   \n3               1               1               1              1   \n4               1               0               1              0   \n\n  id_17_NaN_Code  id_18_NaN_Code  id_19_NaN_Code  id_20_NaN_Code  \\\n0              1               1               1               1   \n1              1               1               1               1   \n2              1               1               1               1   \n3              1               1               1               1   \n4              0               1               0               0   \n\n   id_32_NaN_Code  \n0               1  \n1               1  \n2               1  \n3               1  \n4               0  \n\n[5 rows x 481 columns]"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dataset_transaction.head(5)"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": "for column in int_columns:\n  # Set to int 32\n  dataset_transaction[column].astype('float32')\n\n  # Code the NaN feature\n  dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n  \n  # Normalization\n  X = dataset_transaction[column]\n  indices = np.where(np.isnan(dataset_transaction[column]) == False)[0]\n  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], dataset_transaction[column] = normalization_data(X, indices)"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>...</th>\n      <th>id_11_NaN_Code</th>\n      <th>id_13_NaN_Code</th>\n      <th>id_14_NaN_Code</th>\n      <th>id_17_NaN_Code</th>\n      <th>id_18_NaN_Code</th>\n      <th>id_19_NaN_Code</th>\n      <th>id_20_NaN_Code</th>\n      <th>id_32_NaN_Code</th>\n      <th>TransactionDT_NaN_Code</th>\n      <th>card1_NaN_Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2987000</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002083</td>\n      <td>W</td>\n      <td>0.231445</td>\n      <td>0.000000</td>\n      <td>-0.024384</td>\n      <td>discover</td>\n      <td>-0.418213</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2987001</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.003321</td>\n      <td>W</td>\n      <td>-0.410645</td>\n      <td>0.082886</td>\n      <td>-0.024384</td>\n      <td>mastercard</td>\n      <td>-0.709961</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2987002</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002380</td>\n      <td>W</td>\n      <td>-0.301025</td>\n      <td>0.254883</td>\n      <td>-0.024384</td>\n      <td>visa</td>\n      <td>-0.242920</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2987003</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002663</td>\n      <td>W</td>\n      <td>0.473389</td>\n      <td>0.408936</td>\n      <td>-0.024384</td>\n      <td>mastercard</td>\n      <td>-0.600586</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2987004</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002663</td>\n      <td>H</td>\n      <td>-0.310547</td>\n      <td>0.302979</td>\n      <td>-0.024384</td>\n      <td>mastercard</td>\n      <td>-0.709961</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 483 columns</p>\n</div>",
                        "text/plain": "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD     card1  \\\n0        2987000        0      -0.463379       -0.002083         W  0.231445   \n1        2987001        0      -0.463379       -0.003321         W -0.410645   \n2        2987002        0      -0.463379       -0.002380         W -0.301025   \n3        2987003        0      -0.463379       -0.002663         W  0.473389   \n4        2987004        0      -0.463379       -0.002663         H -0.310547   \n\n      card2     card3       card4     card5  ... id_11_NaN_Code  \\\n0  0.000000 -0.024384    discover -0.418213  ...              1   \n1  0.082886 -0.024384  mastercard -0.709961  ...              1   \n2  0.254883 -0.024384        visa -0.242920  ...              1   \n3  0.408936 -0.024384  mastercard -0.600586  ...              1   \n4  0.302979 -0.024384  mastercard -0.709961  ...              0   \n\n   id_13_NaN_Code  id_14_NaN_Code  id_17_NaN_Code id_18_NaN_Code  \\\n0               1               1               1              1   \n1               1               1               1              1   \n2               1               1               1              1   \n3               1               1               1              1   \n4               1               0               0              1   \n\n  id_19_NaN_Code  id_20_NaN_Code  id_32_NaN_Code  TransactionDT_NaN_Code  \\\n0              1               1               1                       0   \n1              1               1               1                       0   \n2              1               1               1                       0   \n3              1               1               1                       0   \n4              0               0               0                       0   \n\n   card1_NaN_Code  \n0               0  \n1               0  \n2               0  \n3               0  \n4               0  \n\n[5 rows x 483 columns]"
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dataset_transaction.head(5)"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Encoded columns: 207\n"
                }
            ],
            "source": "from sklearn.preprocessing import OneHotEncoder\n\nencoded_column = 0\nfor column in obj_columns:\n  ohc = OneHotEncoder()\n  dataset_transaction.loc[np.where(dataset_transaction[column].isnull())[0], column] = 'Null'\n  encoded = ohc.fit_transform(dataset_transaction[column].values.reshape(-1,1)).toarray()    \n  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(dataset_transaction[column].astype('str'))))])\n  dataset_transaction = pd.concat([dataset_transaction, pd_encoded], axis=1)\n  cache[column] = dataset_transaction[column].values.reshape(-1,1)\n  encoded_column += len(pd_encoded.columns)\n\nprint(\"Encoded columns: \" + str(encoded_column))\nfor column in obj_columns:\n  try:\n    dataset_transaction.pop(column)\n  except KeyError:\n    pass"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "False False\n"
                }
            ],
            "source": "# Double check again Null and Nan\nprint(np.any(np.isnan(dataset_transaction)), np.any(dataset_transaction.isnull()))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Apply Seaborn to analyze the processed data and detect removable features"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": "out = ['isFraud']\nfor column in dataset_transaction.columns:\n  if column.find('R_emaildomain') != -1:\n    out.append(column)\n  if column.find('P_emaildomain') != -1:\n    out.append(column)"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": "columns_to_analyze = out\nanalyzing_data = dataset_transaction[columns_to_analyze]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "corr = analyzing_data.corr()\n\n# Note: Switch this to True to see the heat map of the corr\n# Note: This step can also be done with other features, however, for the Capstone project, we will only remove the features generated by the OneHotEncoding step\nto_display = False\n\nif to_display:\n  mask = np.triu(np.ones_like(corr, dtype=np.bool))\n  # Set up the matplotlib figure\n  f, ax = plt.subplots(figsize=(11, 9))\n\n  # Generate a custom diverging colormap\n  cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n  # Draw the heatmap with the mask and correct aspect ratio\n  sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n              square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "99\n"
                },
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card5</th>\n      <th>addr1</th>\n      <th>addr2</th>\n      <th>...</th>\n      <th>id_36_2</th>\n      <th>id_37_0</th>\n      <th>id_37_1</th>\n      <th>id_37_2</th>\n      <th>id_38_0</th>\n      <th>id_38_1</th>\n      <th>id_38_2</th>\n      <th>DeviceType_0</th>\n      <th>DeviceType_1</th>\n      <th>DeviceType_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2987000</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002083</td>\n      <td>0.231445</td>\n      <td>0.000000</td>\n      <td>-0.024384</td>\n      <td>-0.418213</td>\n      <td>0.055145</td>\n      <td>0.002167</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2987001</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.003321</td>\n      <td>-0.410645</td>\n      <td>0.082886</td>\n      <td>-0.024384</td>\n      <td>-0.709961</td>\n      <td>0.077881</td>\n      <td>0.002167</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2987002</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002380</td>\n      <td>-0.301025</td>\n      <td>0.254883</td>\n      <td>-0.024384</td>\n      <td>-0.242920</td>\n      <td>0.089233</td>\n      <td>0.002167</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2987003</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002663</td>\n      <td>0.473389</td>\n      <td>0.408936</td>\n      <td>-0.024384</td>\n      <td>-0.600586</td>\n      <td>0.421143</td>\n      <td>0.002167</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2987004</td>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002663</td>\n      <td>-0.310547</td>\n      <td>0.302979</td>\n      <td>-0.024384</td>\n      <td>-0.709961</td>\n      <td>0.293701</td>\n      <td>0.002167</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 564 columns</p>\n</div>",
                        "text/plain": "   TransactionID  isFraud  TransactionDT  TransactionAmt     card1     card2  \\\n0        2987000        0      -0.463379       -0.002083  0.231445  0.000000   \n1        2987001        0      -0.463379       -0.003321 -0.410645  0.082886   \n2        2987002        0      -0.463379       -0.002380 -0.301025  0.254883   \n3        2987003        0      -0.463379       -0.002663  0.473389  0.408936   \n4        2987004        0      -0.463379       -0.002663 -0.310547  0.302979   \n\n      card3     card5     addr1     addr2  ...  id_36_2  id_37_0  id_37_1  \\\n0 -0.024384 -0.418213  0.055145  0.002167  ...        0        0        1   \n1 -0.024384 -0.709961  0.077881  0.002167  ...        0        0        1   \n2 -0.024384 -0.242920  0.089233  0.002167  ...        0        0        1   \n3 -0.024384 -0.600586  0.421143  0.002167  ...        0        0        1   \n4 -0.024384 -0.709961  0.293701  0.002167  ...        0        0        0   \n\n   id_37_2  id_38_0  id_38_1  id_38_2  DeviceType_0  DeviceType_1  \\\n0        0        0        1        0             1             0   \n1        0        0        1        0             1             0   \n2        0        0        1        0             1             0   \n3        0        0        1        0             1             0   \n4        1        0        0        1             0             0   \n\n   DeviceType_2  \n0             0  \n1             0  \n2             0  \n3             0  \n4             1  \n\n[5 rows x 564 columns]"
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Remove the weak correlation features created by the OneHotEncoding step\ncol = corr.columns\nis_fraud = np.where(col=='isFraud')[0][0]\ncol = col.to_list()\ncol.pop(is_fraud)\nto_remove = []\nfor each_col in col:\n  if abs(corr['isFraud'][each_col]) < 0.01: # Weak correlation\n    to_remove.append(each_col)\n    a = dataset_transaction.pop(each_col)\nprint(len(to_remove))\nanalyzing_data = None\n\ndataset_transaction.head(5)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Create the train/val dataset"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card5</th>\n      <th>addr1</th>\n      <th>addr2</th>\n      <th>dist1</th>\n      <th>...</th>\n      <th>id_36_2</th>\n      <th>id_37_0</th>\n      <th>id_37_1</th>\n      <th>id_37_2</th>\n      <th>id_38_0</th>\n      <th>id_38_1</th>\n      <th>id_38_2</th>\n      <th>DeviceType_0</th>\n      <th>DeviceType_1</th>\n      <th>DeviceType_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002083</td>\n      <td>0.231445</td>\n      <td>0.000000</td>\n      <td>-0.024384</td>\n      <td>-0.418213</td>\n      <td>0.055145</td>\n      <td>0.002167</td>\n      <td>-0.009674</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.003321</td>\n      <td>-0.410645</td>\n      <td>0.082886</td>\n      <td>-0.024384</td>\n      <td>-0.709961</td>\n      <td>0.077881</td>\n      <td>0.002167</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002380</td>\n      <td>-0.301025</td>\n      <td>0.254883</td>\n      <td>-0.024384</td>\n      <td>-0.242920</td>\n      <td>0.089233</td>\n      <td>0.002167</td>\n      <td>0.016388</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002663</td>\n      <td>0.473389</td>\n      <td>0.408936</td>\n      <td>-0.024384</td>\n      <td>-0.600586</td>\n      <td>0.421143</td>\n      <td>0.002167</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>-0.463379</td>\n      <td>-0.002663</td>\n      <td>-0.310547</td>\n      <td>0.302979</td>\n      <td>-0.024384</td>\n      <td>-0.709961</td>\n      <td>0.293701</td>\n      <td>0.002167</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 563 columns</p>\n</div>",
                        "text/plain": "   isFraud  TransactionDT  TransactionAmt     card1     card2     card3  \\\n0        0      -0.463379       -0.002083  0.231445  0.000000 -0.024384   \n1        0      -0.463379       -0.003321 -0.410645  0.082886 -0.024384   \n2        0      -0.463379       -0.002380 -0.301025  0.254883 -0.024384   \n3        0      -0.463379       -0.002663  0.473389  0.408936 -0.024384   \n4        0      -0.463379       -0.002663 -0.310547  0.302979 -0.024384   \n\n      card5     addr1     addr2     dist1  ...  id_36_2  id_37_0  id_37_1  \\\n0 -0.418213  0.055145  0.002167 -0.009674  ...        0        0        1   \n1 -0.709961  0.077881  0.002167  0.000000  ...        0        0        1   \n2 -0.242920  0.089233  0.002167  0.016388  ...        0        0        1   \n3 -0.600586  0.421143  0.002167  0.000000  ...        0        0        1   \n4 -0.709961  0.293701  0.002167  0.000000  ...        0        0        0   \n\n   id_37_2  id_38_0  id_38_1  id_38_2  DeviceType_0  DeviceType_1  \\\n0        0        0        1        0             1             0   \n1        0        0        1        0             1             0   \n2        0        0        1        0             1             0   \n3        0        0        1        0             1             0   \n4        1        0        0        1             0             0   \n\n   DeviceType_2  \n0             0  \n1             0  \n2             0  \n3             0  \n4             1  \n\n[5 rows x 563 columns]"
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dataset = copy.copy(dataset_transaction)\n\n# Remove the irrelevant columns\na = dataset.pop('TransactionID')\ndataset.head(5)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.model_selection import train_test_split\n\nY = dataset['isFraud']\ndataset.pop('isFraud')\nX = dataset\nX_train = X\nY_train = Y"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Percentage of Fraud: 3.5%\n"
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "# Check the imbalance\nplt.hist(Y_train, bins=[0,1,2])\n\nfraud_count = np.unique(Y_train, return_counts=True)\nprint(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Downsampling/Upsampling to minimize the imbalance "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(569877, 1)\n(789198, 562) (7972, 562)\n"
                }
            ],
            "source": "downsampling_factor = 1\nindices_1 = np.argwhere(np.array(Y_train)==1)\nindices_0_new = np.argwhere(np.array(Y_train)==0)\nindices = np.arange(0,len(indices_0_new),downsampling_factor)\nindices_0_new = indices_0_new[indices]\n\nprint(indices_0_new.shape)\n\nupsampling_factor = 10\nindices_1_new = indices_1\nfor i in range(upsampling_factor):\n  indices_1_new = np.concatenate((indices_1_new, indices_1), axis=0)\n\nindices_0_new = np.concatenate((indices_1_new, indices_0_new), axis=0)\n\nindices_0_new = tf.random.shuffle(indices_0_new)\n\nX_new = np.array(X_train)[indices_0_new]\nY_new = np.array(Y_train)[indices_0_new]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_new, Y_new, test_size=0.01)\n\nX_to_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[2]))\nY_to_train = np.squeeze(Y_train, axis=1)\n\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[2]))\nY_test = np.squeeze(Y_test, axis=1)\n\n\nprint(X_to_train.shape, X_test.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Percentage of Fraud: 28.51%\n"
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 2 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "X_new = None\nY_new = None\n\nplt.subplot(211)\nplt.hist(Y_to_train, bins=[0,1,2])\n\nplt.subplot(212)\nplt.hist(Y_test, bins=[0,1,2])\n\nX_train = None\nY_train = None\nX = None\nY = None\n\nfraud_count = np.unique(Y_to_train, return_counts=True)\nprint(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Create the model using NN"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.regularizers import l1, l2\nfrom tensorflow.keras.optimizers import Adam, SGD\nimport tensorflow_addons as tfa\nfrom tensorflow_addons.metrics import F1Score\n\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "METRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]\n\ndef create_model(dense1=128, dense2=64, dropout_rate=0.4, l1_rate=0.001, l2_rate=0.001, init_std=0.01, lr=0.001):\n  out_model = Sequential()\n  \n  out_model.add(Dense(dense1, activation='relu',\n                      input_shape=(X_to_train.shape[1],),\n                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n  out_model.add(Dropout(dropout_rate))\n  out_model.add(BatchNormalization())\n  out_model.add(Dense(dense1, activation='relu',\n                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n  out_model.add(Dropout(dropout_rate))\n  out_model.add(BatchNormalization())\n\n  out_model.add(Dense(dense2, activation='relu',\n                      kernel_regularizer=tf.keras.regularizers.l1(l1_rate),\n                      kernel_initializer=tf.keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n                      activity_regularizer=tf.keras.regularizers.l2(l2_rate)))\n  out_model.add(Dropout(dropout_rate))\n  out_model.add(BatchNormalization())\n\n  out_model.add(Dense(1, activation=\"sigmoid\"))\n\n  out_model.compile(\n            optimizer=Adam(learning_rate=lr),\n            loss='binary_crossentropy',\n            metrics=[METRICS])\n  \n  return out_model"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 256)               144128    \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 256)               1024      \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 256)               1024      \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 128)               512       \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 245,505\nTrainable params: 244,225\nNon-trainable params: 1,280\n_________________________________________________________________\n"
                }
            ],
            "source": "my_model = create_model(dense1=256, dense2=128, dropout_rate=0.4, l1_rate=1e-3, l2_rate=8e-4, init_std=0.01, lr=0.00002)\nmy_model.summary()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Perform the training and using the callbacks to optimize the performance of the final model"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nEpoch 00001: val_auc improved from -inf to 0.86599, saving model to ./best_model.h5\n\nEpoch 00002: val_auc improved from 0.86599 to 0.88267, saving model to ./best_model.h5\n\nEpoch 00003: val_auc improved from 0.88267 to 0.88956, saving model to ./best_model.h5\n\nEpoch 00004: val_auc improved from 0.88956 to 0.89523, saving model to ./best_model.h5\n\nEpoch 00005: val_auc improved from 0.89523 to 0.89771, saving model to ./best_model.h5\n\nEpoch 00006: val_auc improved from 0.89771 to 0.90285, saving model to ./best_model.h5\n\nEpoch 00007: val_auc improved from 0.90285 to 0.90344, saving model to ./best_model.h5\n\nEpoch 00008: val_auc improved from 0.90344 to 0.90672, saving model to ./best_model.h5\n\nEpoch 00009: val_auc improved from 0.90672 to 0.90960, saving model to ./best_model.h5\n\nEpoch 00010: val_auc improved from 0.90960 to 0.91082, saving model to ./best_model.h5\n\nEpoch 00011: val_auc improved from 0.91082 to 0.91285, saving model to ./best_model.h5\n\nEpoch 00012: val_auc improved from 0.91285 to 0.91396, saving model to ./best_model.h5\n\nEpoch 00013: val_auc improved from 0.91396 to 0.91591, saving model to ./best_model.h5\n\nEpoch 00014: val_auc did not improve from 0.91591\n\nEpoch 00015: val_auc improved from 0.91591 to 0.91836, saving model to ./best_model.h5\n\nEpoch 00016: val_auc improved from 0.91836 to 0.91928, saving model to ./best_model.h5\n\nEpoch 00017: val_auc improved from 0.91928 to 0.91939, saving model to ./best_model.h5\n\nEpoch 00018: val_auc improved from 0.91939 to 0.92086, saving model to ./best_model.h5\n\nEpoch 00019: val_auc did not improve from 0.92086\n\nEpoch 00020: val_auc improved from 0.92086 to 0.92275, saving model to ./best_model.h5\n\nEpoch 00021: val_auc improved from 0.92275 to 0.92347, saving model to ./best_model.h5\n\nEpoch 00022: val_auc improved from 0.92347 to 0.92567, saving model to ./best_model.h5\n\nEpoch 00023: val_auc did not improve from 0.92567\n\nEpoch 00024: val_auc did not improve from 0.92567\n\nEpoch 00025: val_auc did not improve from 0.92567\n\nEpoch 00026: val_auc improved from 0.92567 to 0.92581, saving model to ./best_model.h5\n\nEpoch 00027: val_auc improved from 0.92581 to 0.92614, saving model to ./best_model.h5\n\nEpoch 00028: val_auc did not improve from 0.92614\n\nEpoch 00029: val_auc did not improve from 0.92614\n\nEpoch 00030: val_auc did not improve from 0.92614\n\nEpoch 00031: val_auc improved from 0.92614 to 0.92779, saving model to ./best_model.h5\n\nEpoch 00032: val_auc did not improve from 0.92779\n"
                }
            ],
            "source": "BATCH_SIZE = 512\nNB_EPOCH = 2000\nPATIENCE = 20\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_auc', patience=PATIENCE, verbose=0, mode='max',\n    baseline=None)\n\nbest_model_hold = tf.keras.callbacks.ModelCheckpoint(\n    filepath='./best_model.h5', monitor='val_auc', verbose=1, save_best_only=True,\n    save_weights_only=False, mode='max')\n\nhistory = my_model.fit(X_to_train, Y_to_train, verbose=0,\n             batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n             validation_split=0.01, shuffle=True,\n             callbacks=[early_stop, best_model_hold])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# The lost and the training cuvre"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def plot_metrics(history):\n  metrics =  ['loss', 'auc', 'precision', 'recall']\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.subplot(2,2,n+1) \n    plt.plot(history.epoch,  history.history[metric], color='b', label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric],\n             color='b', linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    if metric == 'loss':\n      plt.ylim([0, plt.ylim()[1]])\n    elif metric == 'auc':\n      plt.ylim([0.8,1])\n    else:\n      plt.ylim([0,1])\n\n    plt.legend()\n\nplot_metrics(history)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# F1_score function and validate the test set"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "new_model = tf.keras.models.load_model('./best_weights.h5')\nnew_model.summary()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\ndef precision_cal(y_pred, y_ref):\n  pre = 0\n  if np.any(y_pred == 1):\n    indices_positive = np.argwhere(y_pred == 1)\n    true_pos = np.sum(y_ref[indices_positive])\n\n    if true_pos == len(indices_positive):\n      false_pos = 0\n    else:\n      false_pos = len(indices_positive) - true_pos\n\n    pre = true_pos/(true_pos + false_pos)\n  return pre\n\ndef recall_cal(y_pred, y_ref):\n  recall = 0\n  if np.any(y_pred == 1):\n    indices_positive = np.argwhere(y_pred == 1)\n    true_pos = np.sum(y_ref[indices_positive])\n\n    fals_neg = np.sum(y_ref[np.argwhere(y_pred == 0)])\n       \n    recall = true_pos/(true_pos + fals_neg)\n\n  return recall\n\ndef F1_score(model, X_test, y_ref, test_size, threshold=0.5):\n  test_size = test_size\n  y_pred = (model.predict(X_test, batch_size=128)>threshold).astype(int)\n  y_pred = np.squeeze(y_pred, axis=1)\n \n  precision = precision_cal(y_pred, y_ref)\n  recall = recall_cal(y_pred, y_ref)\n\n  return precision, recall, 2*precision*recall/(precision+recall)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pre = []\nre = []\nf1 = []\n\npre_train = []\nre_train = []\nf1_train = []\n\nthreshold_value = []\nindices = np.random.randint(0, len(X_to_train), size=(len(Y_test),))\n\nfor i in range(90):\n  threshold_value.append(0.1+i*0.01)\n  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_test, Y_test, test_size=len(Y_test), threshold=threshold_value[-1])\n  \n  pre.append(temp_pre)\n  re.append(temp_re)\n  f1.append(temp_f1)\n\n  temp_pre, temp_re, temp_f1 = F1_score(new_model, X_to_train[indices], Y_to_train[indices], test_size=len(Y_to_train[indices]), threshold=threshold_value[-1])\n\n  pre_train.append(temp_pre)\n  re_train.append(temp_re)\n  f1_train.append(temp_f1)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.plot(threshold_value, f1, 'b')\nplt.plot(threshold_value, pre, 'r')\nplt.plot(threshold_value, re, 'g')\n\nplt.plot(threshold_value, f1_train, '--b')\nplt.plot(threshold_value, pre_train, '--r')\nplt.plot(threshold_value, re_train, '--g')\n\nmax_f1_indices = np.where(f1==np.max(f1))[0][0]\nprint(\"Best F1 score is \" + str(f1[max_f1_indices]) + \" at threshold of \" + str(threshold_value[max_f1_indices]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def plot_cm(labels, predictions, p=0.5, display=True):\n  cm = confusion_matrix(labels, predictions > p)\n  if display:\n    plt.figure(figsize=(5,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\")\n    plt.title('Confusion matrix @{:.2f}'.format(p))\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n\n    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n    print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n  pre = cm[1][1]/(cm[1][1] + cm[0][1])\n  recall = cm[1][1]/(cm[1][1] + cm[1][0])\n  f1_score = 2*pre*recall/(pre+recall)\n  return pre, recall, f1_score"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "BATCH_SIZE = 256\nbaseline_results = new_model.evaluate(X_test, Y_test,\n                                  batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(new_model.metrics_names, baseline_results):\n  print(name, ': ', value)\nprint()\n\npredictions = new_model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n\nplot_cm(Y_test, predictions, p=threshold_value[max_f1_indices], display=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def plot_roc(name, labels, predictions, **kwargs):\n  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n\n  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n  plt.xlabel('False positives [%]')\n  plt.ylabel('True positives [%]')\n  plt.xlim([-0.5,30])\n  plt.ylim([70,100.5])\n  plt.grid(True)\n  ax = plt.gca()\n  ax.set_aspect('equal')\n\nindices = np.random.randint(0, len(X_to_train), size=(len(Y_test),))\n\ntrain_prediction = new_model.predict(X_to_train[indices], batch_size=BATCH_SIZE, verbose=0)\nplot_roc(\"Train Baseline\", Y_to_train[indices], train_prediction, color='b')\nplot_roc(\"Test Baseline\", Y_test, predictions, color='b', linestyle='--')\nplt.legend(loc='lower right')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "prediction = np.squeeze(predictions, axis=1)\nthreshold = threshold_value[max_f1_indices]\nplt.subplot(211)\nplt.hist(Y_test, bins=[0,1,2])\n\nplt.subplot(212)\nplt.hist((prediction>threshold).astype('int'), bins=[0,1,2])\n\nfraud_predict = np.unique((prediction>threshold).astype('int'), return_counts=True)\nfraud_real = np.unique(Y_test, return_counts=True)\nprint(\"Percentage of Fraud: \" + str(round(fraud_predict[1][1]/np.sum(fraud_predict[1])*100,2)) + \"% \" + str(round(fraud_real[1][1]/np.sum(fraud_real[1])*100,2)) + \"%\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Evaluate the performance of the model using the Kaggle tools"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "body = client_a5b8370d070043a698d332a3da4f29ba.get_object(Bucket='advanceddatasciencecapstoneprojec-donotdelete-pr-sxgni1jmo8dtzj',Key='test_transaction.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ntest_transaction = pd.read_csv(body)\ntest_transaction.head(5)\n\n# Remove transaction ID\nTransactionID = test_transaction.pop('TransactionID')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "body = client_a5b8370d070043a698d332a3da4f29ba.get_object(Bucket='advanceddatasciencecapstoneprojec-donotdelete-pr-sxgni1jmo8dtzj',Key='test_identity.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ntest_identity = pd.read_csv(body)\ntest_identity.head()\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "dataset_transaction = None\nto_remove_id = ['DeviceInfo', 'id_30', 'id_31', 'id_33']\nfor column in to_remove_id:\n  a = test_identity.pop(column)\n\n# Remove the columns in to_remove_NaN_dataset_transaction and to_remove_NaN_dataset_identity\nfor column in to_remove_NaN_dataset_transaction:\n  test_transaction.pop(column)\n\nfor column in to_remove_NaN_dataset_identity:\n  test_identity.pop(column)\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "merged_data = pd.merge(left=test_transaction, right=test_identity, how='left', left_on='TransactionID', right_on='TransactionID')\n\nTransactionID = merged_data.pop('TransactionID')\ntest_transaction = None\nmerged_data.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "merged_data.head(5)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "test_transaction = copy.copy(merged_data)\nmerged_data = None\nfloat_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('float64'))].to_list()\nint_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('int64'))].to_list()\nobj_columns_test = test_transaction.columns[np.where(test_transaction.dtypes == np.dtype('O'))].to_list()\n\nprint(len(float_columns_test), len(int_columns_test), len(obj_columns_test))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def apply_normalization(X, indices, cache_min, cache_max, cache_mean):\n  X_out = copy.copy(X)\n  X_out[indices] = (X_out[indices] - cache_mean)/(cache_max - cache_min)\n  X_out[np.where(np.isnan(X_out))[0]] = 0.0\n  return X_out.astype('float16')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "for column in float_columns_test:\n  # Set to float 16\n  test_transaction[column].astype('float32')\n\n  # Code the NaN feature\n  test_transaction[column + \"_NaN_Code\"] = np.isnan(test_transaction[column].values).astype('int8')\n  \n  # Normalization\n  X = test_transaction[column]\n  indices = np.where(np.isnan(test_transaction[column]) == False)[0]\n  test_transaction[column] = apply_normalization(X.to_numpy(), indices, cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "for column in int_columns_test:\n  # Set to int 32\n  test_transaction[column].astype('int32')\n\n  # Code the NaN feature\n  test_transaction[column + \"_NaN_Code\"] = np.isnan(test_transaction[column].values).astype('int8')\n  \n  # Normalization\n  X = test_transaction[column]\n  indices = np.where(np.isnan(test_transaction[column]) == False)[0]\n  test_transaction[column] = apply_normalization(X.to_numpy(), indices, cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "encoded_column = 0\nfor column in obj_columns_test:\n  ohc = OneHotEncoder(handle_unknown='ignore')\n  ohc.fit(cache[column])\n  test_transaction.loc[np.where(test_transaction[column].isnull())[0], column] = 'Null'\n  encoded = ohc.transform(test_transaction[column].values.reshape(-1,1)).toarray()    \n  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(cache[column])))])\n  test_transaction = pd.concat([test_transaction, pd_encoded], axis=1)\n  encoded_column += len(pd_encoded.columns)\n\nprint(\"Encoded columns: \" + str(encoded_column))\n\n\nfor column in obj_columns_test:\n  try:\n    test_transaction.pop(column)\n  except KeyError:\n    pass"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Check if we have the same shape with the X_train\nprint(test_transaction.shape, X_train.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Make the prediction and submit the output\nthreshold = threshold_value[max_f1_indices]\nresult = (new_model.predict(test_transaction)>threshold).astype('int8')\nresult_pd = pd.DataFrame(result, columns=['isFraud'])\ndata_to_file = pd.concat([TransactionID, result_pd], axis=1)\ndata_to_file.head(5)\ndata_to_file.to_csv(\"./submission.csv\", index=False)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!pip install kaggle"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!echo '{\"Your Kaggle information here\"}' > kaggle.json\nos.environ['KAGGLE_CONFIG_DIR'] = \"./\""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!kaggle competitions submit -c ieee-fraud-detection -f submission.csv -m \"Submission, {threshold}\""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# The model reached a public score of ~0.8 with a patience of 50 for the training, this can be improved by increasing the patience or having a better model"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}