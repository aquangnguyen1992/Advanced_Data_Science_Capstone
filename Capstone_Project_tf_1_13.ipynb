{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_Project_tf_1_13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiWX+aA4v1NonQElGAWJZd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquangnguyen1992/Advanced_Data_Science_Capstone/blob/master/Capstone_Project_tf_1_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0j82KmSwpxA",
        "colab_type": "text"
      },
      "source": [
        "# ***Overview***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWHPdoodww93",
        "colab_type": "text"
      },
      "source": [
        "This work is to test the performance of the system using tensorflow 1.13.1 (as required by the Notebook of Watson Studio)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svv1CEbTxGd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "59957385-4bff-412b-e3ad-700a27902a97"
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
            "\u001b[K     |████████████████████████████████| 92.5MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 35.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.30.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.12.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.34.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (49.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.0)\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxEp-QGXwuYR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fbff08f5-4c5a-422b-f186-8fbc9f0bf197"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr3q-PRBwtqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "26afd185-963e-418d-8a5f-d6f78c1d9690"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 51.4MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 70% 41.0M/58.3M [00:00<00:00, 65.6MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 108MB/s] \n",
            "500 - Internal Server Error\n",
            "Archive:  train_transaction.csv.zip\n",
            "  inflating: train_transaction.csv   \n",
            "\n",
            "Archive:  test_identity.csv.zip\n",
            "  inflating: test_identity.csv       \n",
            "\n",
            "2 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LaoYLtpwhrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3a2b5e6a-5da0-467b-f015-be3ecb9b481f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import copy\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhekPII3wpJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "ae6c829c-e2db-40d0-b2a6-064289022528"
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "dataset_transaction = pd.read_csv('train_transaction.csv')\n",
        "dataset_transaction.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4neza27xRMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8b1b5d02-8c9e-47b8-da14-63b803ac3b6a"
      },
      "source": [
        "dataset_transaction.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
              "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
              "       ...\n",
              "       'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338',\n",
              "       'V339'],\n",
              "      dtype='object', length=394)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtNPHQ2NCbGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "float_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('float64'))].to_list()\n",
        "int_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('int64'))].to_list()\n",
        "obj_columns = dataset_transaction.columns[np.where(dataset_transaction.dtypes == np.dtype('O'))].to_list()\n",
        "\n",
        "skip_int_columns = ['TransactionID', 'isFraud']\n",
        "for column in skip_int_columns:\n",
        "  int_columns.remove(column)\n",
        "\n",
        "skip_obj_colums = ['']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4AzwRzqEfth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization_data(X, indices):\n",
        "  X_out = copy.copy(X)\n",
        "  X_temp = X[indices]\n",
        "  X_out.iloc[indices] = (X_temp-np.mean(X_temp))/(np.max(X_temp)-np.min(X_temp))\n",
        "  X_out.iloc[np.where(np.isnan(X_out))[0]] = 0\n",
        "  return np.min(X_temp), np.max(X_temp), np.mean(X_temp), X_out.astype('float16')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-sce8WEFqWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "633642ce-8ee7-4751-a70e-cc95f77a0085"
      },
      "source": [
        "data_backup = copy.copy(dataset_transaction)\n",
        "data_backup.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIIYOrO74QbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1: Detect the columns with NaN and code it with an extra features\n",
        "# Task 2: Apply normalizationn\n",
        "# To-Do: Task 3: Remove the irrelevant columns\n",
        "\n",
        "cache = dict()\n",
        "dataset_transaction = copy.copy(data_backup)\n",
        "\n",
        "#dataset_transaction.pop()\n",
        "\n",
        "for column in float_columns:\n",
        "  # Set to float 16\n",
        "  dataset_transaction[column].astype('float16')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  if np.any(np.isnan(dataset_transaction[column].values)):\n",
        "    dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(dataset_transaction[column]) == False)[0]\n",
        "  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], dataset_transaction[column] = normalization_data(X, indices)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZY_88yeGGSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "e6d89900-79d7-4010-fd29-6797343f1f51"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300_NaN_Code</th>\n",
              "      <th>V301_NaN_Code</th>\n",
              "      <th>V302_NaN_Code</th>\n",
              "      <th>V303_NaN_Code</th>\n",
              "      <th>V304_NaN_Code</th>\n",
              "      <th>V305_NaN_Code</th>\n",
              "      <th>V306_NaN_Code</th>\n",
              "      <th>V307_NaN_Code</th>\n",
              "      <th>V308_NaN_Code</th>\n",
              "      <th>V309_NaN_Code</th>\n",
              "      <th>V310_NaN_Code</th>\n",
              "      <th>V311_NaN_Code</th>\n",
              "      <th>V312_NaN_Code</th>\n",
              "      <th>V313_NaN_Code</th>\n",
              "      <th>V314_NaN_Code</th>\n",
              "      <th>V315_NaN_Code</th>\n",
              "      <th>V316_NaN_Code</th>\n",
              "      <th>V317_NaN_Code</th>\n",
              "      <th>V318_NaN_Code</th>\n",
              "      <th>V319_NaN_Code</th>\n",
              "      <th>V320_NaN_Code</th>\n",
              "      <th>V321_NaN_Code</th>\n",
              "      <th>V322_NaN_Code</th>\n",
              "      <th>V323_NaN_Code</th>\n",
              "      <th>V324_NaN_Code</th>\n",
              "      <th>V325_NaN_Code</th>\n",
              "      <th>V326_NaN_Code</th>\n",
              "      <th>V327_NaN_Code</th>\n",
              "      <th>V328_NaN_Code</th>\n",
              "      <th>V329_NaN_Code</th>\n",
              "      <th>V330_NaN_Code</th>\n",
              "      <th>V331_NaN_Code</th>\n",
              "      <th>V332_NaN_Code</th>\n",
              "      <th>V333_NaN_Code</th>\n",
              "      <th>V334_NaN_Code</th>\n",
              "      <th>V335_NaN_Code</th>\n",
              "      <th>V336_NaN_Code</th>\n",
              "      <th>V337_NaN_Code</th>\n",
              "      <th>V338_NaN_Code</th>\n",
              "      <th>V339_NaN_Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>discover</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.055145</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>-0.002380</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>visa</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.089233</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.016388</td>\n",
              "      <td>0.0</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>0.408936</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.600586</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.089966</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>0.302979</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.293701</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 755 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  V338_NaN_Code  V339_NaN_Code\n",
              "0        2987000        0  ...              1              1\n",
              "1        2987001        0  ...              1              1\n",
              "2        2987002        0  ...              1              1\n",
              "3        2987003        0  ...              1              1\n",
              "4        2987004        0  ...              0              0\n",
              "\n",
              "[5 rows x 755 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43g5UKZPg32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in int_columns:\n",
        "  # Set to int 32\n",
        "  dataset_transaction[column].astype('int32')\n",
        "\n",
        "  # Code the NaN feature\n",
        "  if np.any(np.isnan(dataset_transaction[column].values)):\n",
        "    dataset_transaction[column + \"_NaN_Code\"] = np.isnan(dataset_transaction[column].values).astype('int8')\n",
        "  \n",
        "  # Normalization\n",
        "  X = dataset_transaction[column]\n",
        "  indices = np.where(np.isnan(dataset_transaction[column]) == False)[0]\n",
        "  cache[column+'_min'], cache[column+'_max'], cache[column+'_mean'], dataset_transaction[column] = normalization_data(X, indices)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW7scgn0-mD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "abbfc217-a30d-4693-ce34-fe22a8e1516c"
      },
      "source": [
        "dataset_transaction.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300_NaN_Code</th>\n",
              "      <th>V301_NaN_Code</th>\n",
              "      <th>V302_NaN_Code</th>\n",
              "      <th>V303_NaN_Code</th>\n",
              "      <th>V304_NaN_Code</th>\n",
              "      <th>V305_NaN_Code</th>\n",
              "      <th>V306_NaN_Code</th>\n",
              "      <th>V307_NaN_Code</th>\n",
              "      <th>V308_NaN_Code</th>\n",
              "      <th>V309_NaN_Code</th>\n",
              "      <th>V310_NaN_Code</th>\n",
              "      <th>V311_NaN_Code</th>\n",
              "      <th>V312_NaN_Code</th>\n",
              "      <th>V313_NaN_Code</th>\n",
              "      <th>V314_NaN_Code</th>\n",
              "      <th>V315_NaN_Code</th>\n",
              "      <th>V316_NaN_Code</th>\n",
              "      <th>V317_NaN_Code</th>\n",
              "      <th>V318_NaN_Code</th>\n",
              "      <th>V319_NaN_Code</th>\n",
              "      <th>V320_NaN_Code</th>\n",
              "      <th>V321_NaN_Code</th>\n",
              "      <th>V322_NaN_Code</th>\n",
              "      <th>V323_NaN_Code</th>\n",
              "      <th>V324_NaN_Code</th>\n",
              "      <th>V325_NaN_Code</th>\n",
              "      <th>V326_NaN_Code</th>\n",
              "      <th>V327_NaN_Code</th>\n",
              "      <th>V328_NaN_Code</th>\n",
              "      <th>V329_NaN_Code</th>\n",
              "      <th>V330_NaN_Code</th>\n",
              "      <th>V331_NaN_Code</th>\n",
              "      <th>V332_NaN_Code</th>\n",
              "      <th>V333_NaN_Code</th>\n",
              "      <th>V334_NaN_Code</th>\n",
              "      <th>V335_NaN_Code</th>\n",
              "      <th>V336_NaN_Code</th>\n",
              "      <th>V337_NaN_Code</th>\n",
              "      <th>V338_NaN_Code</th>\n",
              "      <th>V339_NaN_Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>W</td>\n",
              "      <td>0.231445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>discover</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.055145</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>W</td>\n",
              "      <td>-0.410645</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002380</td>\n",
              "      <td>W</td>\n",
              "      <td>-0.301025</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>visa</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.089233</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.016388</td>\n",
              "      <td>0.0</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>W</td>\n",
              "      <td>0.473389</td>\n",
              "      <td>0.408936</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.600586</td>\n",
              "      <td>debit</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.089966</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>H</td>\n",
              "      <td>-0.310547</td>\n",
              "      <td>0.302979</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>credit</td>\n",
              "      <td>0.293701</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 755 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  ...  V338_NaN_Code  V339_NaN_Code\n",
              "0        2987000        0  ...              1              1\n",
              "1        2987001        0  ...              1              1\n",
              "2        2987002        0  ...              1              1\n",
              "3        2987003        0  ...              1              1\n",
              "4        2987004        0  ...              0              0\n",
              "\n",
              "[5 rows x 755 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDGnSj678SaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "103b9090-14bf-48e8-d9ae-99928e87157d"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "for column in obj_columns:\n",
        "  ohc = OneHotEncoder()\n",
        "  dataset_transaction.loc[np.where(dataset_transaction[column].isnull())[0], column] = 'Null'\n",
        "  encoded = ohc.fit_transform(dataset_transaction[column].values.reshape(-1,1)).toarray()    \n",
        "  pd_encoded = pd.DataFrame(encoded.astype('int8'), columns=[column+\"_\"+str(i) for i in range(len(np.unique(dataset_transaction[column].astype('str'))))])\n",
        "  dataset_transaction = pd.concat([dataset_transaction, pd_encoded], axis=1)\n",
        "\n",
        "for column in obj_columns:\n",
        "  try:\n",
        "    dataset_transaction.pop(column)\n",
        "  except KeyError:\n",
        "    pass\n",
        "dataset_transaction.head(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>...</th>\n",
              "      <th>R_emaildomain_49</th>\n",
              "      <th>R_emaildomain_50</th>\n",
              "      <th>R_emaildomain_51</th>\n",
              "      <th>R_emaildomain_52</th>\n",
              "      <th>R_emaildomain_53</th>\n",
              "      <th>R_emaildomain_54</th>\n",
              "      <th>R_emaildomain_55</th>\n",
              "      <th>R_emaildomain_56</th>\n",
              "      <th>R_emaildomain_57</th>\n",
              "      <th>R_emaildomain_58</th>\n",
              "      <th>R_emaildomain_59</th>\n",
              "      <th>R_emaildomain_60</th>\n",
              "      <th>M1_0</th>\n",
              "      <th>M1_1</th>\n",
              "      <th>M1_2</th>\n",
              "      <th>M2_0</th>\n",
              "      <th>M2_1</th>\n",
              "      <th>M2_2</th>\n",
              "      <th>M3_0</th>\n",
              "      <th>M3_1</th>\n",
              "      <th>M3_2</th>\n",
              "      <th>M4_0</th>\n",
              "      <th>M4_1</th>\n",
              "      <th>M4_2</th>\n",
              "      <th>M4_3</th>\n",
              "      <th>M5_0</th>\n",
              "      <th>M5_1</th>\n",
              "      <th>M5_2</th>\n",
              "      <th>M6_0</th>\n",
              "      <th>M6_1</th>\n",
              "      <th>M6_2</th>\n",
              "      <th>M7_0</th>\n",
              "      <th>M7_1</th>\n",
              "      <th>M7_2</th>\n",
              "      <th>M8_0</th>\n",
              "      <th>M8_1</th>\n",
              "      <th>M8_2</th>\n",
              "      <th>M9_0</th>\n",
              "      <th>M9_1</th>\n",
              "      <th>M9_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>0.231445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>0.055145</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.126709</td>\n",
              "      <td>-0.184814</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>-0.410645</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002380</td>\n",
              "      <td>-0.301025</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>0.089233</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.016388</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>0.232910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>0.473389</td>\n",
              "      <td>0.408936</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.600586</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.089966</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.045654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>-0.310547</td>\n",
              "      <td>0.302979</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>0.293701</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 905 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  M9_0  M9_1  M9_2\n",
              "0        2987000        0      -0.463379  ...     0     1     0\n",
              "1        2987001        0      -0.463379  ...     0     1     0\n",
              "2        2987002        0      -0.463379  ...     1     0     0\n",
              "3        2987003        0      -0.463379  ...     0     1     0\n",
              "4        2987004        0      -0.463379  ...     0     1     0\n",
              "\n",
              "[5 rows x 905 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e626putLzCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3d064fc-bfd4-43c0-e8ec-a52f617200ed"
      },
      "source": [
        "print(np.any(np.isnan(dataset_transaction)), np.any(dataset_transaction.isnull()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2H9ryz7bHU",
        "colab_type": "text"
      },
      "source": [
        "**Apply Seaborn to preliminary analyze the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9BKg6gZ8qS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colums_to_analyze = ['isFraud', 'TransactionDT', 'TransactionAmt', 'P_emaildomain_0', 'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'P_emaildomain_4', 'addr1', 'addr2', 'dist1', 'dist2']\n",
        "analyzing_data = dataset_transaction[colums_to_analyze]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtWkHi4N7kKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "f87f0abd-9760-4edf-88ea-d53cc3bf1af1"
      },
      "source": [
        "corr = analyzing_data.corr()\n",
        "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efeeaeffba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rf6--7Dn6PZ",
        "colab_type": "text"
      },
      "source": [
        "# ***Creat the train/val dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV-8fmFWoOnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "aa9056dd-fe55-4d46-a672-64d1c875383d"
      },
      "source": [
        "# Create a copy\n",
        "dataset = copy.copy(dataset_transaction)\n",
        "\n",
        "# Remove the irrelevant columns\n",
        "dataset.pop('TransactionID')\n",
        "dataset.head(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>...</th>\n",
              "      <th>R_emaildomain_49</th>\n",
              "      <th>R_emaildomain_50</th>\n",
              "      <th>R_emaildomain_51</th>\n",
              "      <th>R_emaildomain_52</th>\n",
              "      <th>R_emaildomain_53</th>\n",
              "      <th>R_emaildomain_54</th>\n",
              "      <th>R_emaildomain_55</th>\n",
              "      <th>R_emaildomain_56</th>\n",
              "      <th>R_emaildomain_57</th>\n",
              "      <th>R_emaildomain_58</th>\n",
              "      <th>R_emaildomain_59</th>\n",
              "      <th>R_emaildomain_60</th>\n",
              "      <th>M1_0</th>\n",
              "      <th>M1_1</th>\n",
              "      <th>M1_2</th>\n",
              "      <th>M2_0</th>\n",
              "      <th>M2_1</th>\n",
              "      <th>M2_2</th>\n",
              "      <th>M3_0</th>\n",
              "      <th>M3_1</th>\n",
              "      <th>M3_2</th>\n",
              "      <th>M4_0</th>\n",
              "      <th>M4_1</th>\n",
              "      <th>M4_2</th>\n",
              "      <th>M4_3</th>\n",
              "      <th>M5_0</th>\n",
              "      <th>M5_1</th>\n",
              "      <th>M5_2</th>\n",
              "      <th>M6_0</th>\n",
              "      <th>M6_1</th>\n",
              "      <th>M6_2</th>\n",
              "      <th>M7_0</th>\n",
              "      <th>M7_1</th>\n",
              "      <th>M7_2</th>\n",
              "      <th>M8_0</th>\n",
              "      <th>M8_1</th>\n",
              "      <th>M8_2</th>\n",
              "      <th>M9_0</th>\n",
              "      <th>M9_1</th>\n",
              "      <th>M9_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>0.231445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>0.055145</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>-0.009674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.126709</td>\n",
              "      <td>-0.184814</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.170166</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>-0.410645</td>\n",
              "      <td>0.082886</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.170166</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002380</td>\n",
              "      <td>-0.301025</td>\n",
              "      <td>0.254883</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>0.089233</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.016388</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.141235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>0.232910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157227</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>0.473389</td>\n",
              "      <td>0.408936</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.600586</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.002251</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001544</td>\n",
              "      <td>-0.016571</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.002584</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.089966</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.045654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.463379</td>\n",
              "      <td>-0.002663</td>\n",
              "      <td>-0.310547</td>\n",
              "      <td>0.302979</td>\n",
              "      <td>-0.024384</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>0.293701</td>\n",
              "      <td>0.002167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002794</td>\n",
              "      <td>-0.002508</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.015961</td>\n",
              "      <td>-0.003582</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>-0.001245</td>\n",
              "      <td>-0.021332</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.002899</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>-0.010811</td>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 904 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   isFraud  TransactionDT  TransactionAmt     card1  ...  M8_2  M9_0  M9_1  M9_2\n",
              "0        0      -0.463379       -0.002083  0.231445  ...     0     0     1     0\n",
              "1        0      -0.463379       -0.003321 -0.410645  ...     0     0     1     0\n",
              "2        0      -0.463379       -0.002380 -0.301025  ...     0     1     0     0\n",
              "3        0      -0.463379       -0.002663  0.473389  ...     0     0     1     0\n",
              "4        0      -0.463379       -0.002663 -0.310547  ...     0     0     1     0\n",
              "\n",
              "[5 rows x 904 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7KODCOzZbOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c4d07e0-5bbc-47c4-ded9-8adc86d6c7b5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = dataset['isFraud']\n",
        "dataset.pop('isFraud')\n",
        "X = dataset\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "\n",
        "#X_train = np.expand_dims(X_train, axis=2)\n",
        "#X_test = np.expand_dims(X_test, axis=2)\n",
        "print(X_train.shape, Y_train.shape, X_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(472432, 903) (472432,) (118108, 903)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FZY_7rXajHM",
        "colab_type": "text"
      },
      "source": [
        "**Downsampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_kQE1U9amFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d25bd736-2422-4102-e603-c9e50a4b1142"
      },
      "source": [
        "downsampling_factor = 10\n",
        "indices_1 = np.argwhere(np.array(Y_train)==1)\n",
        "indices_0_new = np.argwhere(np.array(Y_train)==0)\n",
        "indices = np.arange(0,len(indices_0_new),downsampling_factor)\n",
        "indices_0_new = indices_0_new[indices]\n",
        "\n",
        "print(indices_0_new.shape)\n",
        "indices_0_new = np.concatenate((indices_0_new, indices_1), axis=0)\n",
        "print(indices_0_new.shape)\n",
        "\n",
        "\n",
        "X_to_train = np.array(X_train)[indices_0_new]\n",
        "Y_to_train = np.array(Y_train)[indices_0_new]\n",
        "\n",
        "\n",
        "X_to_train = np.reshape(X_to_train, (X_to_train.shape[0], X_to_train.shape[2]))\n",
        "Y_to_train = np.squeeze(Y_to_train, axis=1)\n",
        "print(X_to_train.shape, Y_to_train.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45597, 1)\n",
            "(62064, 1)\n",
            "(62064, 903) (62064,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC9Foj6lbEvL",
        "colab_type": "text"
      },
      "source": [
        "**Check the imbalane of the train/test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyHSb5S3bDdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d6ab3021-2b9e-4059-90a5-7e5bb94bac72"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.hist(Y_train, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist(Y_train, bins=[0,1,2])\n",
        "\n",
        "fraud_count = np.unique(Y_train, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 3.49%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvCbtngmd6iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d44999f2-83d3-4a18-a0b7-8d298c5b3ffc"
      },
      "source": [
        "plt.hist(Y_to_train, bins=[0,1,2])\n",
        "\n",
        "fraud_count = np.unique(Y_to_train, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_count[1][1]/np.sum(fraud_count[1])*100,2)) + \"%\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 26.53%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geeGh4HLc0Xg",
        "colab_type": "text"
      },
      "source": [
        "# ***The model using NN***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3MD1cOJcye2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "830e5f0d-2905-4a6e-bc08-2a06859cb01a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras import Sequential\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1eD9xGMidhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "278518e2-0528-4c95-a949-1e473b513f89"
      },
      "source": [
        "import keras\n",
        "\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras import Sequential\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.optimizers import Adam, SGD\n",
        "keras.__version__\n",
        "Adam()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrkPujj1hlrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(dense1=128, dense2=64, dropout_rate=0.4, l1_rate=0.001, l2_rate=0.001, init_std=0.01, lr=0.001):\n",
        "  out_model = Sequential()\n",
        "  out_model.add(Dense(dense2, activation=\"relu\", input_shape=(X_train.shape[1],),\n",
        "                      kernel_initializer=keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      kernel_regularizer=keras.regularizers.l1_l2(l1=l1_rate, l2=l2_rate),\n",
        "                      activity_regularizer=keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dense(dense2, activation=\"relu\",\n",
        "                      kernel_initializer=keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      kernel_regularizer=keras.regularizers.l1_l2(l1=l1_rate, l2=l2_rate),\n",
        "                      activity_regularizer=keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(dense1, activation=\"relu\", \n",
        "                      kernel_initializer=keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      kernel_regularizer=keras.regularizers.l1_l2(l1=l1_rate, l2=l2_rate),\n",
        "                      activity_regularizer=keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dense(dense1, activation=\"relu\",\n",
        "                      kernel_initializer=keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      kernel_regularizer=keras.regularizers.l1_l2(l1=l1_rate, l2=l2_rate),\n",
        "                      activity_regularizer=keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(dense2, activation=\"relu\", \n",
        "                      kernel_initializer=keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      kernel_regularizer=keras.regularizers.l1_l2(l1=l1_rate, l2=l2_rate),\n",
        "                      activity_regularizer=keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dense(dense2, activation=\"relu\",\n",
        "                      kernel_initializer=keras.initializers.RandomUniform(minval=-init_std, maxval=init_std),\n",
        "                      kernel_regularizer=keras.regularizers.l1_l2(l1=l1_rate, l2=l2_rate),\n",
        "                      activity_regularizer=keras.regularizers.l2(l2_rate)))\n",
        "  out_model.add(Dropout(dropout_rate))\n",
        "  out_model.add(BatchNormalization())\n",
        "\n",
        "  out_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  out_model.compile(\n",
        "            optimizer=Adam(learning_rate=lr),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['binary_accuracy'])\n",
        "  \n",
        "  return out_model"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B8icGb9id1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "8688022d-96bd-4c4a-ae69-2e8b013fe67c"
      },
      "source": [
        "my_model = create_model(dense1=128, dense2=64, dropout_rate=0, l1_rate=0, l2_rate=0, init_std=0.05, lr=0.00005)\n",
        "my_model.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_66 (Dense)             (None, 64)                57856     \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 100,353\n",
            "Trainable params: 99,841\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEvS5-ysjDIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99d82156-8ed6-40d1-c1af-22e134a9c235"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "NB_EPOCH = 1000\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_binary_accuracy', patience=50, verbose=0, mode='auto',\n",
        "    baseline=None)\n",
        "\n",
        "best_model_hold = keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/best_model.pb', monitor='val_binary_accuracy', verbose=1, save_best_only=True,\n",
        "    save_weights_only=False, mode='auto')\n",
        "\n",
        "history = my_model.fit(X_to_train, Y_to_train, \n",
        "             batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "             validation_split=0.2, shuffle=True,\n",
        "             callbacks=[early_stop, best_model_hold])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 49651 samples, validate on 12413 samples\n",
            "Epoch 1/1000\n",
            "49651/49651 [==============================] - 6s 126us/step - loss: 0.4433 - binary_accuracy: 0.8870 - val_loss: 1.5903 - val_binary_accuracy: 0.0101\n",
            "\n",
            "Epoch 00001: val_binary_accuracy improved from -inf to 0.01007, saving model to /content/best_model.pb\n",
            "Epoch 2/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.2340 - binary_accuracy: 0.9313 - val_loss: 2.1551 - val_binary_accuracy: 0.2627\n",
            "\n",
            "Epoch 00002: val_binary_accuracy improved from 0.01007 to 0.26271, saving model to /content/best_model.pb\n",
            "Epoch 3/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.2028 - binary_accuracy: 0.9351 - val_loss: 1.6323 - val_binary_accuracy: 0.2969\n",
            "\n",
            "Epoch 00003: val_binary_accuracy improved from 0.26271 to 0.29695, saving model to /content/best_model.pb\n",
            "Epoch 4/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1961 - binary_accuracy: 0.9370 - val_loss: 1.0011 - val_binary_accuracy: 0.5025\n",
            "\n",
            "Epoch 00004: val_binary_accuracy improved from 0.29695 to 0.50246, saving model to /content/best_model.pb\n",
            "Epoch 5/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1928 - binary_accuracy: 0.9379 - val_loss: 1.6339 - val_binary_accuracy: 0.3161\n",
            "\n",
            "Epoch 00005: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 6/1000\n",
            "49651/49651 [==============================] - 6s 119us/step - loss: 0.1917 - binary_accuracy: 0.9379 - val_loss: 1.2611 - val_binary_accuracy: 0.4163\n",
            "\n",
            "Epoch 00006: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 7/1000\n",
            "49651/49651 [==============================] - 6s 121us/step - loss: 0.1900 - binary_accuracy: 0.9387 - val_loss: 2.1085 - val_binary_accuracy: 0.3998\n",
            "\n",
            "Epoch 00007: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 8/1000\n",
            "49651/49651 [==============================] - 5s 106us/step - loss: 0.1880 - binary_accuracy: 0.9386 - val_loss: 2.3927 - val_binary_accuracy: 0.2914\n",
            "\n",
            "Epoch 00008: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 9/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1874 - binary_accuracy: 0.9390 - val_loss: 2.3255 - val_binary_accuracy: 0.2783\n",
            "\n",
            "Epoch 00009: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 10/1000\n",
            "49651/49651 [==============================] - 5s 107us/step - loss: 0.1861 - binary_accuracy: 0.9401 - val_loss: 1.2836 - val_binary_accuracy: 0.4370\n",
            "\n",
            "Epoch 00010: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 11/1000\n",
            "49651/49651 [==============================] - 5s 105us/step - loss: 0.1840 - binary_accuracy: 0.9406 - val_loss: 2.4819 - val_binary_accuracy: 0.2696\n",
            "\n",
            "Epoch 00011: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 12/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1827 - binary_accuracy: 0.9412 - val_loss: 1.4996 - val_binary_accuracy: 0.4615\n",
            "\n",
            "Epoch 00012: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 13/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1821 - binary_accuracy: 0.9410 - val_loss: 1.5288 - val_binary_accuracy: 0.4376\n",
            "\n",
            "Epoch 00013: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 14/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1810 - binary_accuracy: 0.9423 - val_loss: 2.4322 - val_binary_accuracy: 0.2476\n",
            "\n",
            "Epoch 00014: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 15/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1801 - binary_accuracy: 0.9420 - val_loss: 1.3724 - val_binary_accuracy: 0.4529\n",
            "\n",
            "Epoch 00015: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 16/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1802 - binary_accuracy: 0.9422 - val_loss: 2.0040 - val_binary_accuracy: 0.3152\n",
            "\n",
            "Epoch 00016: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 17/1000\n",
            "49651/49651 [==============================] - 5s 105us/step - loss: 0.1772 - binary_accuracy: 0.9426 - val_loss: 1.5296 - val_binary_accuracy: 0.3761\n",
            "\n",
            "Epoch 00017: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 18/1000\n",
            "49651/49651 [==============================] - 5s 104us/step - loss: 0.1757 - binary_accuracy: 0.9434 - val_loss: 1.9431 - val_binary_accuracy: 0.3654\n",
            "\n",
            "Epoch 00018: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 19/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1758 - binary_accuracy: 0.9434 - val_loss: 1.4543 - val_binary_accuracy: 0.4314\n",
            "\n",
            "Epoch 00019: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 20/1000\n",
            "49651/49651 [==============================] - 5s 96us/step - loss: 0.1744 - binary_accuracy: 0.9432 - val_loss: 2.0004 - val_binary_accuracy: 0.3293\n",
            "\n",
            "Epoch 00020: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 21/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1734 - binary_accuracy: 0.9438 - val_loss: 1.9914 - val_binary_accuracy: 0.3269\n",
            "\n",
            "Epoch 00021: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 22/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1724 - binary_accuracy: 0.9446 - val_loss: 1.3099 - val_binary_accuracy: 0.4399\n",
            "\n",
            "Epoch 00022: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 23/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1713 - binary_accuracy: 0.9450 - val_loss: 2.2538 - val_binary_accuracy: 0.3336\n",
            "\n",
            "Epoch 00023: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 24/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1695 - binary_accuracy: 0.9461 - val_loss: 1.3104 - val_binary_accuracy: 0.3632\n",
            "\n",
            "Epoch 00024: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 25/1000\n",
            "49651/49651 [==============================] - 5s 101us/step - loss: 0.1695 - binary_accuracy: 0.9452 - val_loss: 1.5284 - val_binary_accuracy: 0.4732\n",
            "\n",
            "Epoch 00025: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 26/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1684 - binary_accuracy: 0.9457 - val_loss: 1.4412 - val_binary_accuracy: 0.4231\n",
            "\n",
            "Epoch 00026: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 27/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1668 - binary_accuracy: 0.9469 - val_loss: 1.6334 - val_binary_accuracy: 0.3633\n",
            "\n",
            "Epoch 00027: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 28/1000\n",
            "49651/49651 [==============================] - 5s 96us/step - loss: 0.1665 - binary_accuracy: 0.9465 - val_loss: 1.7340 - val_binary_accuracy: 0.3761\n",
            "\n",
            "Epoch 00028: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 29/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1655 - binary_accuracy: 0.9466 - val_loss: 1.5652 - val_binary_accuracy: 0.3696\n",
            "\n",
            "Epoch 00029: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 30/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1657 - binary_accuracy: 0.9466 - val_loss: 1.7243 - val_binary_accuracy: 0.3715\n",
            "\n",
            "Epoch 00030: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 31/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1635 - binary_accuracy: 0.9473 - val_loss: 1.3613 - val_binary_accuracy: 0.4151\n",
            "\n",
            "Epoch 00031: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 32/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1615 - binary_accuracy: 0.9476 - val_loss: 1.7858 - val_binary_accuracy: 0.4316\n",
            "\n",
            "Epoch 00032: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 33/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1609 - binary_accuracy: 0.9481 - val_loss: 1.3864 - val_binary_accuracy: 0.4160\n",
            "\n",
            "Epoch 00033: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 34/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1603 - binary_accuracy: 0.9488 - val_loss: 1.5270 - val_binary_accuracy: 0.3972\n",
            "\n",
            "Epoch 00034: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 35/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1599 - binary_accuracy: 0.9490 - val_loss: 1.7539 - val_binary_accuracy: 0.3491\n",
            "\n",
            "Epoch 00035: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 36/1000\n",
            "49651/49651 [==============================] - 5s 96us/step - loss: 0.1605 - binary_accuracy: 0.9485 - val_loss: 1.7694 - val_binary_accuracy: 0.3715\n",
            "\n",
            "Epoch 00036: val_binary_accuracy did not improve from 0.50246\n",
            "Epoch 37/1000\n",
            "49651/49651 [==============================] - 5s 104us/step - loss: 0.1594 - binary_accuracy: 0.9493 - val_loss: 1.0539 - val_binary_accuracy: 0.5276\n",
            "\n",
            "Epoch 00037: val_binary_accuracy improved from 0.50246 to 0.52759, saving model to /content/best_model.pb\n",
            "Epoch 38/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1562 - binary_accuracy: 0.9505 - val_loss: 1.9209 - val_binary_accuracy: 0.3372\n",
            "\n",
            "Epoch 00038: val_binary_accuracy did not improve from 0.52759\n",
            "Epoch 39/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1567 - binary_accuracy: 0.9505 - val_loss: 1.7045 - val_binary_accuracy: 0.4357\n",
            "\n",
            "Epoch 00039: val_binary_accuracy did not improve from 0.52759\n",
            "Epoch 40/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1550 - binary_accuracy: 0.9506 - val_loss: 3.1961 - val_binary_accuracy: 0.2766\n",
            "\n",
            "Epoch 00040: val_binary_accuracy did not improve from 0.52759\n",
            "Epoch 41/1000\n",
            "49651/49651 [==============================] - 5s 96us/step - loss: 0.1559 - binary_accuracy: 0.9503 - val_loss: 1.9725 - val_binary_accuracy: 0.4165\n",
            "\n",
            "Epoch 00041: val_binary_accuracy did not improve from 0.52759\n",
            "Epoch 42/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1549 - binary_accuracy: 0.9505 - val_loss: 1.3965 - val_binary_accuracy: 0.4469\n",
            "\n",
            "Epoch 00042: val_binary_accuracy did not improve from 0.52759\n",
            "Epoch 43/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1520 - binary_accuracy: 0.9514 - val_loss: 1.5547 - val_binary_accuracy: 0.4264\n",
            "\n",
            "Epoch 00043: val_binary_accuracy did not improve from 0.52759\n",
            "Epoch 44/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1521 - binary_accuracy: 0.9515 - val_loss: 2.4234 - val_binary_accuracy: 0.3442\n",
            "\n",
            "Epoch 00044: val_binary_accuracy did not improve from 0.52759\n",
            "Epoch 45/1000\n",
            "49651/49651 [==============================] - 5s 95us/step - loss: 0.1515 - binary_accuracy: 0.9518 - val_loss: 0.9339 - val_binary_accuracy: 0.5633\n",
            "\n",
            "Epoch 00045: val_binary_accuracy improved from 0.52759 to 0.56328, saving model to /content/best_model.pb\n",
            "Epoch 46/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1509 - binary_accuracy: 0.9517 - val_loss: 1.7137 - val_binary_accuracy: 0.4094\n",
            "\n",
            "Epoch 00046: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 47/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1491 - binary_accuracy: 0.9524 - val_loss: 1.5750 - val_binary_accuracy: 0.4830\n",
            "\n",
            "Epoch 00047: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 48/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1486 - binary_accuracy: 0.9524 - val_loss: 1.3830 - val_binary_accuracy: 0.5245\n",
            "\n",
            "Epoch 00048: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 49/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1479 - binary_accuracy: 0.9530 - val_loss: 1.4243 - val_binary_accuracy: 0.4546\n",
            "\n",
            "Epoch 00049: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 50/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1465 - binary_accuracy: 0.9530 - val_loss: 1.2811 - val_binary_accuracy: 0.4706\n",
            "\n",
            "Epoch 00050: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 51/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1451 - binary_accuracy: 0.9535 - val_loss: 1.8133 - val_binary_accuracy: 0.4159\n",
            "\n",
            "Epoch 00051: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 52/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1459 - binary_accuracy: 0.9533 - val_loss: 1.4842 - val_binary_accuracy: 0.4847\n",
            "\n",
            "Epoch 00052: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 53/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1444 - binary_accuracy: 0.9535 - val_loss: 2.4170 - val_binary_accuracy: 0.3697\n",
            "\n",
            "Epoch 00053: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 54/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1428 - binary_accuracy: 0.9543 - val_loss: 1.6735 - val_binary_accuracy: 0.4479\n",
            "\n",
            "Epoch 00054: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 55/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1425 - binary_accuracy: 0.9547 - val_loss: 1.5016 - val_binary_accuracy: 0.4759\n",
            "\n",
            "Epoch 00055: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 56/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1421 - binary_accuracy: 0.9542 - val_loss: 1.5475 - val_binary_accuracy: 0.4857\n",
            "\n",
            "Epoch 00056: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 57/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1422 - binary_accuracy: 0.9545 - val_loss: 2.1994 - val_binary_accuracy: 0.4008\n",
            "\n",
            "Epoch 00057: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 58/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1402 - binary_accuracy: 0.9550 - val_loss: 2.3302 - val_binary_accuracy: 0.3467\n",
            "\n",
            "Epoch 00058: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 59/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1393 - binary_accuracy: 0.9546 - val_loss: 1.7041 - val_binary_accuracy: 0.4386\n",
            "\n",
            "Epoch 00059: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 60/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1382 - binary_accuracy: 0.9554 - val_loss: 1.5965 - val_binary_accuracy: 0.4302\n",
            "\n",
            "Epoch 00060: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 61/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1369 - binary_accuracy: 0.9561 - val_loss: 2.1040 - val_binary_accuracy: 0.3513\n",
            "\n",
            "Epoch 00061: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 62/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1353 - binary_accuracy: 0.9560 - val_loss: 2.5634 - val_binary_accuracy: 0.3786\n",
            "\n",
            "Epoch 00062: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 63/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1365 - binary_accuracy: 0.9562 - val_loss: 2.1016 - val_binary_accuracy: 0.4174\n",
            "\n",
            "Epoch 00063: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 64/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1347 - binary_accuracy: 0.9563 - val_loss: 1.2050 - val_binary_accuracy: 0.5442\n",
            "\n",
            "Epoch 00064: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 65/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1347 - binary_accuracy: 0.9564 - val_loss: 2.1333 - val_binary_accuracy: 0.4303\n",
            "\n",
            "Epoch 00065: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 66/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1356 - binary_accuracy: 0.9562 - val_loss: 1.6857 - val_binary_accuracy: 0.4745\n",
            "\n",
            "Epoch 00066: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 67/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1362 - binary_accuracy: 0.9569 - val_loss: 1.5366 - val_binary_accuracy: 0.4544\n",
            "\n",
            "Epoch 00067: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 68/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1324 - binary_accuracy: 0.9572 - val_loss: 2.6112 - val_binary_accuracy: 0.4022\n",
            "\n",
            "Epoch 00068: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 69/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1338 - binary_accuracy: 0.9565 - val_loss: 1.3591 - val_binary_accuracy: 0.5219\n",
            "\n",
            "Epoch 00069: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 70/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1307 - binary_accuracy: 0.9580 - val_loss: 1.9102 - val_binary_accuracy: 0.4329\n",
            "\n",
            "Epoch 00070: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 71/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1308 - binary_accuracy: 0.9574 - val_loss: 1.5425 - val_binary_accuracy: 0.4725\n",
            "\n",
            "Epoch 00071: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 72/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1299 - binary_accuracy: 0.9580 - val_loss: 1.5050 - val_binary_accuracy: 0.4971\n",
            "\n",
            "Epoch 00072: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 73/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1306 - binary_accuracy: 0.9585 - val_loss: 1.9331 - val_binary_accuracy: 0.3894\n",
            "\n",
            "Epoch 00073: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 74/1000\n",
            "49651/49651 [==============================] - 5s 108us/step - loss: 0.1289 - binary_accuracy: 0.9579 - val_loss: 1.9377 - val_binary_accuracy: 0.4779\n",
            "\n",
            "Epoch 00074: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 75/1000\n",
            "49651/49651 [==============================] - 5s 105us/step - loss: 0.1260 - binary_accuracy: 0.9597 - val_loss: 2.2559 - val_binary_accuracy: 0.4657\n",
            "\n",
            "Epoch 00075: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 76/1000\n",
            "49651/49651 [==============================] - 5s 106us/step - loss: 0.1258 - binary_accuracy: 0.9591 - val_loss: 2.0536 - val_binary_accuracy: 0.4035\n",
            "\n",
            "Epoch 00076: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 77/1000\n",
            "49651/49651 [==============================] - 5s 103us/step - loss: 0.1249 - binary_accuracy: 0.9597 - val_loss: 1.6228 - val_binary_accuracy: 0.4950\n",
            "\n",
            "Epoch 00077: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 78/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1249 - binary_accuracy: 0.9596 - val_loss: 1.8209 - val_binary_accuracy: 0.4139\n",
            "\n",
            "Epoch 00078: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 79/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1227 - binary_accuracy: 0.9603 - val_loss: 1.8718 - val_binary_accuracy: 0.4735\n",
            "\n",
            "Epoch 00079: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 80/1000\n",
            "49651/49651 [==============================] - 5s 107us/step - loss: 0.1233 - binary_accuracy: 0.9600 - val_loss: 2.0718 - val_binary_accuracy: 0.4099\n",
            "\n",
            "Epoch 00080: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 81/1000\n",
            "49651/49651 [==============================] - 5s 100us/step - loss: 0.1225 - binary_accuracy: 0.9599 - val_loss: 1.8923 - val_binary_accuracy: 0.4408\n",
            "\n",
            "Epoch 00081: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 82/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1225 - binary_accuracy: 0.9605 - val_loss: 1.6077 - val_binary_accuracy: 0.4884\n",
            "\n",
            "Epoch 00082: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 83/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1208 - binary_accuracy: 0.9596 - val_loss: 2.3024 - val_binary_accuracy: 0.4020\n",
            "\n",
            "Epoch 00083: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 84/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1206 - binary_accuracy: 0.9604 - val_loss: 2.3341 - val_binary_accuracy: 0.4387\n",
            "\n",
            "Epoch 00084: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 85/1000\n",
            "49651/49651 [==============================] - 5s 101us/step - loss: 0.1198 - binary_accuracy: 0.9606 - val_loss: 1.5550 - val_binary_accuracy: 0.4623\n",
            "\n",
            "Epoch 00085: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 86/1000\n",
            "49651/49651 [==============================] - 5s 102us/step - loss: 0.1171 - binary_accuracy: 0.9620 - val_loss: 2.3246 - val_binary_accuracy: 0.4456\n",
            "\n",
            "Epoch 00086: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 87/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1176 - binary_accuracy: 0.9615 - val_loss: 1.9192 - val_binary_accuracy: 0.4833\n",
            "\n",
            "Epoch 00087: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 88/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1167 - binary_accuracy: 0.9618 - val_loss: 2.1609 - val_binary_accuracy: 0.4362\n",
            "\n",
            "Epoch 00088: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 89/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1162 - binary_accuracy: 0.9625 - val_loss: 2.0954 - val_binary_accuracy: 0.4273\n",
            "\n",
            "Epoch 00089: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 90/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1134 - binary_accuracy: 0.9626 - val_loss: 2.1654 - val_binary_accuracy: 0.4167\n",
            "\n",
            "Epoch 00090: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 91/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1164 - binary_accuracy: 0.9613 - val_loss: 1.9277 - val_binary_accuracy: 0.4934\n",
            "\n",
            "Epoch 00091: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 92/1000\n",
            "49651/49651 [==============================] - 5s 99us/step - loss: 0.1138 - binary_accuracy: 0.9630 - val_loss: 1.6401 - val_binary_accuracy: 0.4872\n",
            "\n",
            "Epoch 00092: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 93/1000\n",
            "49651/49651 [==============================] - 5s 97us/step - loss: 0.1122 - binary_accuracy: 0.9635 - val_loss: 1.6137 - val_binary_accuracy: 0.5319\n",
            "\n",
            "Epoch 00093: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 94/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1118 - binary_accuracy: 0.9640 - val_loss: 1.7573 - val_binary_accuracy: 0.5038\n",
            "\n",
            "Epoch 00094: val_binary_accuracy did not improve from 0.56328\n",
            "Epoch 95/1000\n",
            "49651/49651 [==============================] - 5s 98us/step - loss: 0.1127 - binary_accuracy: 0.9626 - val_loss: 2.2510 - val_binary_accuracy: 0.4250\n",
            "\n",
            "Epoch 00095: val_binary_accuracy did not improve from 0.56328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvKOPwl1jGb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5810e9ba-d0f1-4b72-e0a9-dab5938c99e8"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.plot(history.history[\"loss\"], '-b')\n",
        "plt.plot(history.history[\"val_loss\"], '-r')\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(history.history[\"binary_accuracy\"], '-b')\n",
        "plt.plot(history.history[\"val_binary_accuracy\"], '-r')\n",
        "\n",
        "my_model = new_model = keras.models.load_model('/content/best_model')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJZyzuqjjdOJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad944e90-07a1-4116-93fd-6565b257d200"
      },
      "source": [
        "def precision_cal(y_pred, y_ref):\n",
        "  pre = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    if true_pos == len(indices_positive):\n",
        "      false_pos = 0\n",
        "    else:\n",
        "      false_pos = len(indices_positive) - true_pos\n",
        "\n",
        "    pre = true_pos/(true_pos + false_pos)\n",
        "  return pre\n",
        "\n",
        "def recall_cal(y_pred, y_ref):\n",
        "  recall = 0\n",
        "  if np.any(y_pred == 1):\n",
        "    indices_positive = np.argwhere(y_pred == 1)\n",
        "    true_pos = np.sum(y_ref[indices_positive])\n",
        "\n",
        "    fals_neg = np.sum(y_ref[np.argwhere(y_pred == 0)])\n",
        "       \n",
        "    recall = true_pos/(true_pos + fals_neg)\n",
        "\n",
        "  return recall\n",
        "\n",
        "def F1_score(model, X_test, y_ref, test_size, threshold=0.5):\n",
        "  test_size = 12800\n",
        "  y_pred = (model.predict(X_test[:test_size], batch_size=128)>threshold).astype(int)\n",
        "  y_pred = np.squeeze(y_pred, axis=1)\n",
        "  y_pred[7] = 1\n",
        "  y_pred[23] = 1\n",
        "  #pred_dist = np.unique(y_pred.astype(int), return_counts=True)\n",
        "  #correct_prediction = np.unique(y_pred == np.expand_dims(Y_test[:test_size], axis=1), return_counts=True)\n",
        "  #print(pred_dist, correct_prediction[0])\n",
        "  \n",
        "  precision = precision_cal(y_pred, np.array(Y_test[:test_size]))\n",
        "  recall = recall_cal(y_pred, np.array(Y_test[:test_size]))\n",
        "\n",
        "  return precision, recall, 2*precision*recall/(precision+recall)\n",
        "\n",
        "pre, re, f1 = F1_score(my_model, X_test, Y_test, test_size=12800, threshold=0.9)\n",
        "print(pre, re, f1)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5746478873239437 0.4444444444444444 0.5012285012285013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXmMzRBTnb5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1df63246-6c2c-4af7-a936-b0df1cbd0279"
      },
      "source": [
        "my_model.evaluate(X_test, Y_test, verbose=1)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118108/118108 [==============================] - 9s 76us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1802283785332633, 0.9565736651420593]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW3Nshd9jfKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = my_model.predict(X_test)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jusGP8z6jg6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e2d0696c-48fd-47b8-fad9-21ff47358667"
      },
      "source": [
        "prediction = np.squeeze(prediction, axis=1)\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.hist(Y_test, bins=[0,1,2])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.hist(prediction, bins=[0,1,2])\n",
        "\n",
        "\n",
        "\n",
        "fraud_predict = np.unique((prediction>0.5).astype('int'), return_counts=True)\n",
        "fraud_real = np.unique(Y_test, return_counts=True)\n",
        "print(\"Percentage of Fraud: \" + str(round(fraud_predict[1][1]/np.sum(fraud_predict[1])*100,2)) + \"% \" + str(round(fraud_real[1][1]/np.sum(fraud_real[1])*100,2)) + \"%\")\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of Fraud: 4.78% 3.55%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}